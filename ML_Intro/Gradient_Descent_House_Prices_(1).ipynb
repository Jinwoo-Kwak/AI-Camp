{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tvFf0vzaTu2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as p\n",
        "#np.experimental_enable_numpy_behavior()\n",
        "#tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Qr4Ni5zVaqE4",
        "outputId": "28e1cd68-a4a1-4852-e6cf-65c967f9a6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1459\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d1392d1-ad18-4092-a2e1-21b451fdb54a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d1392d1-ad18-4092-a2e1-21b451fdb54a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d1392d1-ad18-4092-a2e1-21b451fdb54a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d1392d1-ad18-4092-a2e1-21b451fdb54a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal   208500.0  \n",
              "1   2007        WD         Normal   181500.0  \n",
              "2   2008        WD         Normal   223500.0  \n",
              "3   2006        WD        Abnorml   140000.0  \n",
              "4   2008        WD         Normal   250000.0  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "split_index = train_df.iloc[-1].Id\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(len(test_df))\n",
        "df = pd.concat((train_df, test_df), sort=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qLxK_DPed5v",
        "outputId": "f0d040b0-e49e-45f2-feb6-918e8d07b594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSZoning: 4 / 2919 Null\n",
            "LotFrontage: 486 / 2919 Null\n",
            "Alley: 2721 / 2919 Null\n",
            "Utilities: 2 / 2919 Null\n",
            "Exterior1st: 1 / 2919 Null\n",
            "Exterior2nd: 1 / 2919 Null\n",
            "MasVnrType: 24 / 2919 Null\n",
            "MasVnrArea: 23 / 2919 Null\n",
            "BsmtQual: 81 / 2919 Null\n",
            "BsmtCond: 82 / 2919 Null\n",
            "BsmtExposure: 82 / 2919 Null\n",
            "BsmtFinType1: 79 / 2919 Null\n",
            "BsmtFinSF1: 1 / 2919 Null\n",
            "BsmtFinType2: 80 / 2919 Null\n",
            "BsmtFinSF2: 1 / 2919 Null\n",
            "BsmtUnfSF: 1 / 2919 Null\n",
            "TotalBsmtSF: 1 / 2919 Null\n",
            "Electrical: 1 / 2919 Null\n",
            "BsmtFullBath: 2 / 2919 Null\n",
            "BsmtHalfBath: 2 / 2919 Null\n",
            "KitchenQual: 1 / 2919 Null\n",
            "Functional: 2 / 2919 Null\n",
            "FireplaceQu: 1420 / 2919 Null\n",
            "GarageType: 157 / 2919 Null\n",
            "GarageYrBlt: 159 / 2919 Null\n",
            "GarageFinish: 159 / 2919 Null\n",
            "GarageCars: 1 / 2919 Null\n",
            "GarageArea: 1 / 2919 Null\n",
            "GarageQual: 159 / 2919 Null\n",
            "GarageCond: 159 / 2919 Null\n",
            "PoolQC: 2909 / 2919 Null\n",
            "Fence: 2348 / 2919 Null\n",
            "MiscFeature: 2814 / 2919 Null\n",
            "SaleType: 1 / 2919 Null\n",
            "SalePrice: 1459 / 2919 Null\n"
          ]
        }
      ],
      "source": [
        "for column in df.columns:\n",
        "  nnull = df[column].isnull().sum()\n",
        "  \n",
        "  if nnull > 0:\n",
        "    print(column + ':', nnull, '/', len(df[column]), 'Null')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLeX_N8egS7v"
      },
      "outputs": [],
      "source": [
        "# Replace NaN values with 'NA' in columns where NaN is a category\n",
        "df.Alley.fillna('NA', inplace=True)\n",
        "df.BsmtQual.fillna('NA', inplace=True)\n",
        "df.BsmtCond.fillna('NA', inplace=True)\n",
        "df.BsmtExposure.fillna('NA', inplace=True)\n",
        "df.BsmtFinType1.fillna('NA', inplace=True)\n",
        "df.BsmtFinType2.fillna('NA', inplace=True)\n",
        "df.FireplaceQu.fillna('NA', inplace=True)\n",
        "df.GarageType.fillna('NA', inplace=True)\n",
        "df.GarageFinish.fillna('NA', inplace=True)\n",
        "df.GarageQual.fillna('NA', inplace=True)\n",
        "df.GarageCond.fillna('NA', inplace=True)\n",
        "df.PoolQC.fillna('NA', inplace=True)\n",
        "df.Fence.fillna('NA', inplace=True)\n",
        "df.MiscFeature.fillna('NA', inplace=True)\n",
        "\n",
        "'''df.MSZoning.fillna('A', inplace=True)\n",
        "df.LotFrontage.fillna(df.LotFrontage.mean(), inplace=True)\n",
        "df.Utilities.fillna('AllPub', inplace=True)\n",
        "df.Exterior1st.fillna('Other', inplace=True)\n",
        "df.Exterior2nd.fillna('Other', inplace=True)\n",
        "df.MasVnrType.fillna('BrkCmn', inplace=True)\n",
        "df.MasVnrArea.fillna(df.MasVnrArea.mean(), inplace=True)\n",
        "df.BsmtFinSF1.fillna(df.BsmtFinSF1.mean(), inplace=True)'''\n",
        "\n",
        "for column in df.columns:\n",
        "  if df[column].dtype == 'object':\n",
        "    df[column] = df[column].fillna(df[column].mode(dropna=True).values[0])\n",
        "  else:\n",
        "    df[column] = df[column].fillna(df[column].mean())\n",
        "\n",
        "for column in df.columns:\n",
        "  nnull = df[column].isna().sum()\n",
        "  \n",
        "  if nnull > 0:\n",
        "    print(column + ':', nnull, '/', len(df[column]), 'Null')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DEZdvDjisAY"
      },
      "outputs": [],
      "source": [
        "df.LotFrontage.fillna(df.LotFrontage.mean(), inplace=True)\n",
        "df.GarageYrBlt.fillna(df.GarageYrBlt.mode(), inplace=True)\n",
        "df.SalePrice.fillna(0, inplace=True)\n",
        "#df.dropna(axis='rows', inplace=True)\n",
        "\n",
        "for column in df.columns:\n",
        "  nnull = df[column].isnull().sum()\n",
        "  \n",
        "  if nnull > 0:\n",
        "    print(column + ':', nnull, '/', len(df[column]), 'Null')\n",
        "\n",
        "# Should be no NaNs past this point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apocFCxbjdYs"
      },
      "outputs": [],
      "source": [
        "# Define a function to help with converting columns to one-hot categorical\n",
        "\n",
        "def col_to_categorical(df, col):\n",
        "  categorical = pd.get_dummies(df[col])\n",
        "\n",
        "  for value in categorical.columns:\n",
        "    df[col + '_' + value] = categorical[value]\n",
        "  \n",
        "  df.drop(col, axis='columns', inplace=True)\n",
        "\n",
        "# Define a convenience function for converting multiple columns to one-hot categorical\n",
        "\n",
        "def cols_to_categorical(df, cols):\n",
        "  for col in cols:\n",
        "    col_to_categorical(df, col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T5IvjxHkMzY"
      },
      "outputs": [],
      "source": [
        "categorical_cols = [\n",
        "  'MSZoning',\n",
        "  'Street',\n",
        "  'Alley',\n",
        "  'LotShape',\n",
        "  'LandContour',\n",
        "  'Utilities',\n",
        "  'LotConfig',\n",
        "  'LandSlope',\n",
        "  'Neighborhood',\n",
        "  'Condition1',\n",
        "  'Condition2',\n",
        "  'BldgType',\n",
        "  'HouseStyle',\n",
        "  'RoofStyle',\n",
        "  'RoofMatl',\n",
        "  'Exterior1st',\n",
        "  'Exterior2nd',\n",
        "  'MasVnrType',\n",
        "  'ExterQual',\n",
        "  'ExterCond',\n",
        "  'Foundation',\n",
        "  'BsmtQual',\n",
        "  'BsmtCond',\n",
        "  'BsmtExposure',\n",
        "  'BsmtFinType1',\n",
        "  'BsmtFinType2',\n",
        "  'Heating',\n",
        "  'HeatingQC',\n",
        "  'CentralAir',\n",
        "  'Electrical',\n",
        "  'KitchenQual',\n",
        "  'Functional',\n",
        "  'FireplaceQu',\n",
        "  'GarageType',\n",
        "  'GarageFinish',\n",
        "  'GarageQual',\n",
        "  'GarageCond',\n",
        "  'PavedDrive',\n",
        "  'PoolQC',\n",
        "  'Fence',\n",
        "  'MiscFeature',\n",
        "  'SaleType',\n",
        "  'SaleCondition'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhcSE8gdmNAt",
        "outputId": "7f6910ad-6753-4dba-bb35-95c5d64b541b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
              "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
              "       ...\n",
              "       'SaleType_ConLw', 'SaleType_New', 'SaleType_Oth', 'SaleType_WD',\n",
              "       'SaleCondition_Abnorml', 'SaleCondition_AdjLand',\n",
              "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
              "       'SaleCondition_Partial'],\n",
              "      dtype='object', length=304)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cols_to_categorical(df, categorical_cols)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UeTQF2rAc1J"
      },
      "outputs": [],
      "source": [
        "df.set_index('Id', drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pka1GPUBm8IY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "# Scale all columns\n",
        "for column in df.columns:\n",
        "  if column != 'SalePrice':\n",
        "    df[column] = pd.Series(minmax_scale(df[column]), index=df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UzjWVw7GYxD"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "target_col = df.loc[:split_index].SalePrice\n",
        "target_scaler = MinMaxScaler()\n",
        "Y = np.array(target_col.to_numpy())\n",
        "Y = Y.reshape(Y.size, 1)\n",
        "target_scaler.fit(Y)\n",
        "Y = target_scaler.transform(Y)\n",
        "Y = Y.reshape(Y.size)\n",
        "df.drop('SalePrice', axis='columns', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "0fzvMqygrHEC",
        "outputId": "552590c0-b195-445d-efe5-36eeec9af075"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a165b12d-e1b6-467a-96e8-9a44715b2078\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_Abnorml</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.033420</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.949275</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>0.12250</td>\n",
              "      <td>0.125089</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.202055</td>\n",
              "      <td>0.038795</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.753623</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.173281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.160959</td>\n",
              "      <td>0.046507</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.934783</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.10125</td>\n",
              "      <td>0.086109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.133562</td>\n",
              "      <td>0.038561</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.311594</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.038271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.215753</td>\n",
              "      <td>0.060576</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.927536</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.21875</td>\n",
              "      <td>0.116052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 302 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a165b12d-e1b6-467a-96e8-9a44715b2078')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a165b12d-e1b6-467a-96e8-9a44715b2078 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a165b12d-e1b6-467a-96e8-9a44715b2078');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "Id                                                                           \n",
              "1     0.235294     0.150685  0.033420     0.666667        0.500   0.949275   \n",
              "2     0.000000     0.202055  0.038795     0.555556        0.875   0.753623   \n",
              "3     0.235294     0.160959  0.046507     0.666667        0.500   0.934783   \n",
              "4     0.294118     0.133562  0.038561     0.666667        0.500   0.311594   \n",
              "5     0.235294     0.215753  0.060576     0.777778        0.500   0.927536   \n",
              "\n",
              "    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
              "Id                                                    ...                   \n",
              "1       0.883333     0.12250    0.125089         0.0  ...             0.0   \n",
              "2       0.433333     0.00000    0.173281         0.0  ...             0.0   \n",
              "3       0.866667     0.10125    0.086109         0.0  ...             0.0   \n",
              "4       0.333333     0.00000    0.038271         0.0  ...             0.0   \n",
              "5       0.833333     0.21875    0.116052         0.0  ...             0.0   \n",
              "\n",
              "    SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
              "Id                                                                   \n",
              "1            0.0           0.0          1.0                    0.0   \n",
              "2            0.0           0.0          1.0                    0.0   \n",
              "3            0.0           0.0          1.0                    0.0   \n",
              "4            0.0           0.0          1.0                    1.0   \n",
              "5            0.0           0.0          1.0                    0.0   \n",
              "\n",
              "    SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
              "Id                                                                      \n",
              "1                     0.0                   0.0                   0.0   \n",
              "2                     0.0                   0.0                   0.0   \n",
              "3                     0.0                   0.0                   0.0   \n",
              "4                     0.0                   0.0                   0.0   \n",
              "5                     0.0                   0.0                   0.0   \n",
              "\n",
              "    SaleCondition_Normal  SaleCondition_Partial  \n",
              "Id                                               \n",
              "1                    1.0                    0.0  \n",
              "2                    1.0                    0.0  \n",
              "3                    1.0                    0.0  \n",
              "4                    0.0                    0.0  \n",
              "5                    1.0                    0.0  \n",
              "\n",
              "[5 rows x 302 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = df.loc[:split_index]\n",
        "\n",
        "for i in range(split_index + 1, split_index + 100):\n",
        "  if i in df.index:\n",
        "    test_df = df.loc[i:]\n",
        "    break\n",
        "\n",
        "train_df.to_csv('train_out.csv')\n",
        "test_df.to_csv('test_out.csv')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGjY4XRsBN5C",
        "outputId": "94f3329c-8c53-4654-a640-9069cb2175eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 302) (1459, 302) (1460,)\n"
          ]
        }
      ],
      "source": [
        "print(train_df.shape, test_df.shape, target_col.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOQLdXjsGhn0",
        "outputId": "665e4a26-4dd6-458a-c04e-e60c03f560b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 302) (1460,)\n"
          ]
        }
      ],
      "source": [
        "X_train = np.array(train_df.to_numpy())\n",
        "print(X_train.shape, Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "tj1QrQThWTtA",
        "outputId": "b3dad4f3-35bd-4ac2-972f-2a2cd6e05f38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5490f167-7db3-4147-852b-b2259494df77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_Abnorml</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.150685</td>\n",
              "      <td>0.033420</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.949275</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>0.12250</td>\n",
              "      <td>0.125089</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.202055</td>\n",
              "      <td>0.038795</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.753623</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.173281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.160959</td>\n",
              "      <td>0.046507</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.934783</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.10125</td>\n",
              "      <td>0.086109</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.133562</td>\n",
              "      <td>0.038561</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.311594</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.038271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.215753</td>\n",
              "      <td>0.060576</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.927536</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.21875</td>\n",
              "      <td>0.116052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 302 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5490f167-7db3-4147-852b-b2259494df77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5490f167-7db3-4147-852b-b2259494df77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5490f167-7db3-4147-852b-b2259494df77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "Id                                                                           \n",
              "1     0.235294     0.150685  0.033420     0.666667        0.500   0.949275   \n",
              "2     0.000000     0.202055  0.038795     0.555556        0.875   0.753623   \n",
              "3     0.235294     0.160959  0.046507     0.666667        0.500   0.934783   \n",
              "4     0.294118     0.133562  0.038561     0.666667        0.500   0.311594   \n",
              "5     0.235294     0.215753  0.060576     0.777778        0.500   0.927536   \n",
              "\n",
              "    YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLw  \\\n",
              "Id                                                    ...                   \n",
              "1       0.883333     0.12250    0.125089         0.0  ...             0.0   \n",
              "2       0.433333     0.00000    0.173281         0.0  ...             0.0   \n",
              "3       0.866667     0.10125    0.086109         0.0  ...             0.0   \n",
              "4       0.333333     0.00000    0.038271         0.0  ...             0.0   \n",
              "5       0.833333     0.21875    0.116052         0.0  ...             0.0   \n",
              "\n",
              "    SaleType_New  SaleType_Oth  SaleType_WD  SaleCondition_Abnorml  \\\n",
              "Id                                                                   \n",
              "1            0.0           0.0          1.0                    0.0   \n",
              "2            0.0           0.0          1.0                    0.0   \n",
              "3            0.0           0.0          1.0                    0.0   \n",
              "4            0.0           0.0          1.0                    1.0   \n",
              "5            0.0           0.0          1.0                    0.0   \n",
              "\n",
              "    SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
              "Id                                                                      \n",
              "1                     0.0                   0.0                   0.0   \n",
              "2                     0.0                   0.0                   0.0   \n",
              "3                     0.0                   0.0                   0.0   \n",
              "4                     0.0                   0.0                   0.0   \n",
              "5                     0.0                   0.0                   0.0   \n",
              "\n",
              "    SaleCondition_Normal  SaleCondition_Partial  \n",
              "Id                                               \n",
              "1                    1.0                    0.0  \n",
              "2                    1.0                    0.0  \n",
              "3                    1.0                    0.0  \n",
              "4                    0.0                    0.0  \n",
              "5                    1.0                    0.0  \n",
              "\n",
              "[5 rows x 302 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AVqGmr0Gvc8"
      },
      "outputs": [],
      "source": [
        "def mse(X, Y):\n",
        "  return ((X - Y) ** 2).mean() / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "574nRrRrHQXa",
        "outputId": "f371258b-b653-4747-92cf-33aae4b42a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "def linear_regression(x, w, b):\n",
        "  return np.dot(x, w) + b\n",
        "\n",
        "print(linear_regression([2], [3], 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTi2x6DTH0Wh"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X, Y, w, _b, learning_rate, iterations):\n",
        "  b = _b\n",
        "  double_len_X = len(X) * 2\n",
        "  X_transpose = X.transpose()\n",
        "\n",
        "  for _ in range(iterations):\n",
        "    #linear_regressions = np.array([linear_regression(x, w, b) for x in X])\n",
        "    linear_regressions = linear_regression(X, w, b)\n",
        "    differences = (linear_regressions - Y)\n",
        "\n",
        "    '''for i in range(len(w)):\n",
        "      w_change = (differences * X[:, i]).mean()\n",
        "\n",
        "      #for j in range(len(X)):\n",
        "      #  w_change += differences[j] * X[j][i]\n",
        "      \n",
        "      w[i] -= learning_rate * w_change / 2'''\n",
        "    \n",
        "    w -= learning_rate * np.dot(X_transpose, differences) / double_len_X\n",
        "    b_change = differences.mean()\n",
        "\n",
        "    '''for j in range(len(X)):\n",
        "      b_change += (linear_regressions[j] - Y[j])'''\n",
        "    \n",
        "    b -= learning_rate * b_change / 2\n",
        "\n",
        "    if _ % 10000 == 0:\n",
        "      print('Iteration: ' + str(_) + ', Loss: ' + str(mse(linear_regressions, Y)))\n",
        "  \n",
        "  return b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjMq_uXwKB3c",
        "outputId": "9d9a172d-3d4d-4907-bf50-cbd503008996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 0, Loss: 0.026640919287270397\n",
            "Iteration: 10000, Loss: 0.0007303041545136871\n",
            "Iteration: 20000, Loss: 0.0006544633281726532\n",
            "Iteration: 30000, Loss: 0.0006205399799965043\n",
            "Iteration: 40000, Loss: 0.0005986382461302093\n",
            "Iteration: 50000, Loss: 0.0005823097158760736\n",
            "Iteration: 60000, Loss: 0.0005692169563439769\n",
            "Iteration: 70000, Loss: 0.0005582630400169426\n",
            "Iteration: 80000, Loss: 0.0005488493856648091\n",
            "Iteration: 90000, Loss: 0.0005406124155676453\n",
            "Iteration: 100000, Loss: 0.0005333120930508169\n",
            "Iteration: 110000, Loss: 0.0005267792345851116\n",
            "Iteration: 120000, Loss: 0.0005208884325325942\n",
            "Iteration: 130000, Loss: 0.0005155431038470399\n",
            "Iteration: 140000, Loss: 0.0005106666836288471\n",
            "Iteration: 150000, Loss: 0.0005061971276748949\n",
            "Iteration: 160000, Loss: 0.0005020832998496652\n",
            "Iteration: 170000, Loss: 0.0004982824903056738\n",
            "Iteration: 180000, Loss: 0.0004947586451236534\n",
            "Iteration: 190000, Loss: 0.0004914810629337307\n",
            "Iteration: 200000, Loss: 0.0004884234097656525\n",
            "Iteration: 210000, Loss: 0.00048556295794875394\n",
            "Iteration: 220000, Loss: 0.0004828799872633009\n",
            "Iteration: 230000, Loss: 0.0004803573064773994\n",
            "Iteration: 240000, Loss: 0.0004779798660932206\n",
            "Iteration: 250000, Loss: 0.00047573444145505167\n",
            "Iteration: 260000, Loss: 0.0004736093709902965\n",
            "Iteration: 270000, Loss: 0.000471594338239403\n",
            "Iteration: 280000, Loss: 0.00046968018907686364\n",
            "Iteration: 290000, Loss: 0.0004678587775056915\n",
            "Iteration: 300000, Loss: 0.000466122834861659\n",
            "Iteration: 310000, Loss: 0.0004644658583485535\n",
            "Iteration: 320000, Loss: 0.00046288201564744473\n",
            "Iteration: 330000, Loss: 0.00046136606297380017\n",
            "Iteration: 340000, Loss: 0.0004599132744465514\n",
            "Iteration: 350000, Loss: 0.0004585193810184775\n",
            "Iteration: 360000, Loss: 0.00045718051752318653\n",
            "Iteration: 370000, Loss: 0.0004558931766390116\n",
            "Iteration: 380000, Loss: 0.0004546541687682064\n",
            "Iteration: 390000, Loss: 0.0004534605869909588\n",
            "Iteration: 400000, Loss: 0.0004523097763859038\n",
            "Iteration: 410000, Loss: 0.0004511993071177434\n",
            "Iteration: 420000, Loss: 0.0004501269507829422\n",
            "Iteration: 430000, Loss: 0.0004490906595797689\n",
            "Iteration: 440000, Loss: 0.0004480885479320035\n",
            "Iteration: 450000, Loss: 0.00044711887624861895\n",
            "Iteration: 460000, Loss: 0.00044618003654649685\n",
            "Iteration: 470000, Loss: 0.00044527053970108644\n",
            "Iteration: 480000, Loss: 0.0004443890041221029\n",
            "Iteration: 490000, Loss: 0.0004435341456787562\n",
            "Iteration: 500000, Loss: 0.00044270476872240277\n",
            "Iteration: 510000, Loss: 0.0004418997580745736\n",
            "Iteration: 520000, Loss: 0.0004411180718655005\n",
            "Iteration: 530000, Loss: 0.0004403587351230838\n",
            "Iteration: 540000, Loss: 0.00043962083402496226\n",
            "Iteration: 550000, Loss: 0.00043890351073737604\n",
            "Iteration: 560000, Loss: 0.0004382059587740096\n",
            "Iteration: 570000, Loss: 0.0004375274188162654\n",
            "Iteration: 580000, Loss: 0.00043686717494355255\n",
            "Iteration: 590000, Loss: 0.0004362245512284206\n",
            "Iteration: 600000, Loss: 0.00043559890865676706\n",
            "Iteration: 610000, Loss: 0.00043498964233805774\n",
            "Iteration: 620000, Loss: 0.0004343961789746333\n",
            "Iteration: 630000, Loss: 0.00043381797456277745\n",
            "Iteration: 640000, Loss: 0.00043325451230135075\n",
            "Iteration: 650000, Loss: 0.00043270530068658145\n",
            "Iteration: 660000, Loss: 0.0004321698717740147\n",
            "Iteration: 670000, Loss: 0.00043164777959074543\n",
            "Iteration: 680000, Loss: 0.0004311385986829508\n",
            "Iteration: 690000, Loss: 0.00043064192278535486\n",
            "Iteration: 700000, Loss: 0.0004301573636007621\n",
            "Iteration: 710000, Loss: 0.0004296845496790126\n",
            "Iteration: 720000, Loss: 0.0004292231253859095\n",
            "Iteration: 730000, Loss: 0.00042877274995363674\n",
            "Iteration: 740000, Loss: 0.0004283330966050691\n",
            "Iteration: 750000, Loss: 0.0004279038517451933\n",
            "Iteration: 760000, Loss: 0.00042748471421352686\n",
            "Iteration: 770000, Loss: 0.000427075394592065\n",
            "Iteration: 780000, Loss: 0.00042667561456382003\n",
            "Iteration: 790000, Loss: 0.00042628510631752443\n",
            "Iteration: 800000, Loss: 0.00042590361199450004\n",
            "Iteration: 810000, Loss: 0.0004255308831740812\n",
            "Iteration: 820000, Loss: 0.00042516668039435223\n",
            "Iteration: 830000, Loss: 0.0004248107727052263\n",
            "Iteration: 840000, Loss: 0.0004244629372512328\n",
            "Iteration: 850000, Loss: 0.0004241229588815773\n",
            "Iteration: 860000, Loss: 0.00042379062978529125\n",
            "Iteration: 870000, Loss: 0.00042346574914948695\n",
            "Iteration: 880000, Loss: 0.0004231481228389002\n",
            "Iteration: 890000, Loss: 0.00042283756309508967\n",
            "Iteration: 900000, Loss: 0.00042253388825378346\n",
            "Iteration: 910000, Loss: 0.0004222369224790191\n",
            "Iteration: 920000, Loss: 0.0004219464955128167\n",
            "Iteration: 930000, Loss: 0.0004216624424392642\n",
            "Iteration: 940000, Loss: 0.00042138460346195826\n",
            "Iteration: 950000, Loss: 0.00042111282369385565\n",
            "Iteration: 960000, Loss: 0.00042084695295866126\n",
            "Iteration: 970000, Loss: 0.0004205868456029525\n",
            "Iteration: 980000, Loss: 0.0004203323603182977\n",
            "Iteration: 990000, Loss: 0.0004200833599727083\n",
            "Iteration: 1000000, Loss: 0.0004198397114507822\n",
            "Iteration: 1010000, Loss: 0.0004196012855019852\n",
            "Iteration: 1020000, Loss: 0.00041936795659652977\n",
            "Iteration: 1030000, Loss: 0.00041913960278837196\n",
            "Iteration: 1040000, Loss: 0.0004189161055848756\n",
            "Iteration: 1050000, Loss: 0.0004186973498227241\n",
            "Iteration: 1060000, Loss: 0.0004184832235497003\n",
            "Iteration: 1070000, Loss: 0.00041827361791197645\n",
            "Iteration: 1080000, Loss: 0.0004180684270465913\n",
            "Iteration: 1090000, Loss: 0.00041786754797879075\n",
            "Iteration: 1100000, Loss: 0.0004176708805239723\n",
            "Iteration: 1110000, Loss: 0.0004174783271939469\n",
            "Iteration: 1120000, Loss: 0.00041728979310729034\n",
            "Iteration: 1130000, Loss: 0.0004171051859035435\n",
            "Iteration: 1140000, Loss: 0.0004169244156610571\n",
            "Iteration: 1150000, Loss: 0.00041674739481827483\n",
            "Iteration: 1160000, Loss: 0.0004165740380982763\n",
            "Iteration: 1170000, Loss: 0.0004164042624364054\n",
            "Iteration: 1180000, Loss: 0.0004162379869108174\n",
            "Iteration: 1190000, Loss: 0.00041607513267580086\n",
            "Iteration: 1200000, Loss: 0.00041591562289772834\n",
            "Iteration: 1210000, Loss: 0.0004157593826935034\n",
            "Iteration: 1220000, Loss: 0.0004156063390713804\n",
            "Iteration: 1230000, Loss: 0.00041545642087404344\n",
            "Iteration: 1240000, Loss: 0.0004153095587238256\n",
            "Iteration: 1250000, Loss: 0.0004151656849699769\n",
            "Iteration: 1260000, Loss: 0.0004150247336378771\n",
            "Iteration: 1270000, Loss: 0.0004148866403801031\n",
            "Iteration: 1280000, Loss: 0.0004147513424292636\n",
            "Iteration: 1290000, Loss: 0.0004146187785525296\n",
            "Iteration: 1300000, Loss: 0.0004144888890077664\n",
            "Iteration: 1310000, Loss: 0.0004143616155012143\n",
            "Iteration: 1320000, Loss: 0.000414236901146635\n",
            "Iteration: 1330000, Loss: 0.00041411469042587206\n",
            "Iteration: 1340000, Loss: 0.00041399492915075134\n",
            "Iteration: 1350000, Loss: 0.0004138775644262728\n",
            "Iteration: 1360000, Loss: 0.0004137625446150406\n",
            "Iteration: 1370000, Loss: 0.00041364981930286994\n",
            "Iteration: 1380000, Loss: 0.000413539339265533\n",
            "Iteration: 1390000, Loss: 0.00041343105643658725\n",
            "Iteration: 1400000, Loss: 0.0004133249238762543\n",
            "Iteration: 1410000, Loss: 0.00041322089574129223\n",
            "Iteration: 1420000, Loss: 0.0004131189272558349\n",
            "Iteration: 1430000, Loss: 0.00041301897468315414\n",
            "Iteration: 1440000, Loss: 0.00041292099529830796\n",
            "Iteration: 1450000, Loss: 0.0004128249473616436\n",
            "Iteration: 1460000, Loss: 0.0004127307900931227\n",
            "Iteration: 1470000, Loss: 0.00041263848364743287\n",
            "Iteration: 1480000, Loss: 0.00041254798908986283\n",
            "Iteration: 1490000, Loss: 0.00041245926837290794\n",
            "Iteration: 1500000, Loss: 0.0004123722843135808\n",
            "Iteration: 1510000, Loss: 0.0004122870005713999\n",
            "Iteration: 1520000, Loss: 0.00041220338162703557\n",
            "Iteration: 1530000, Loss: 0.0004121213927615829\n",
            "Iteration: 1540000, Loss: 0.0004120410000364474\n",
            "Iteration: 1550000, Loss: 0.0004119621702738139\n",
            "Iteration: 1560000, Loss: 0.00041188487103768426\n",
            "Iteration: 1570000, Loss: 0.0004118090706154618\n",
            "Iteration: 1580000, Loss: 0.00041173473800006376\n",
            "Iteration: 1590000, Loss: 0.0004116618428725388\n",
            "Iteration: 1600000, Loss: 0.0004115903555851846\n",
            "Iteration: 1610000, Loss: 0.0004115202471451357\n",
            "Iteration: 1620000, Loss: 0.00041145148919841427\n",
            "Iteration: 1630000, Loss: 0.00041138405401442384\n",
            "Iteration: 1640000, Loss: 0.00041131791447087247\n",
            "Iteration: 1650000, Loss: 0.0004112530440391139\n",
            "Iteration: 1660000, Loss: 0.00041118941676989134\n",
            "Iteration: 1670000, Loss: 0.0004111270072794645\n",
            "Iteration: 1680000, Loss: 0.00041106579073612416\n",
            "Iteration: 1690000, Loss: 0.00041100574284706076\n",
            "Iteration: 1700000, Loss: 0.00041094683984559376\n",
            "Iteration: 1710000, Loss: 0.00041088905847873965\n",
            "Iteration: 1720000, Loss: 0.0004108323759951102\n",
            "Iteration: 1730000, Loss: 0.00041077677013313723\n",
            "Iteration: 1740000, Loss: 0.0004107222191096031\n",
            "Iteration: 1750000, Loss: 0.0004106687016084736\n",
            "Iteration: 1760000, Loss: 0.00041061619677002756\n",
            "Iteration: 1770000, Loss: 0.00041056468418026505\n",
            "Iteration: 1780000, Loss: 0.0004105141438605927\n",
            "Iteration: 1790000, Loss: 0.00041046455625777604\n",
            "Iteration: 1800000, Loss: 0.0004104159022341483\n",
            "Iteration: 1810000, Loss: 0.0004103681630580766\n",
            "Iteration: 1820000, Loss: 0.00041032132039466263\n",
            "Iteration: 1830000, Loss: 0.00041027535629668685\n",
            "Iteration: 1840000, Loss: 0.0004102302531957806\n",
            "Iteration: 1850000, Loss: 0.0004101859938938195\n",
            "Iteration: 1860000, Loss: 0.00041014256155453476\n",
            "Iteration: 1870000, Loss: 0.000410099939695336\n",
            "Iteration: 1880000, Loss: 0.0004100581121793357\n",
            "Iteration: 1890000, Loss: 0.00041001706320757306\n",
            "Iteration: 1900000, Loss: 0.00040997677731143304\n",
            "Iteration: 1910000, Loss: 0.00040993723934524905\n",
            "Iteration: 1920000, Loss: 0.0004098984344790894\n",
            "Iteration: 1930000, Loss: 0.0004098603481917226\n",
            "Iteration: 1940000, Loss: 0.0004098229662637521\n",
            "Iteration: 1950000, Loss: 0.0004097862747709194\n",
            "Iteration: 1960000, Loss: 0.000409750260077569\n",
            "Iteration: 1970000, Loss: 0.00040971490883027724\n",
            "Iteration: 1980000, Loss: 0.00040968020795162374\n",
            "Iteration: 1990000, Loss: 0.0004096461446341261\n",
            "Iteration: 2000000, Loss: 0.0004096127063343086\n",
            "Iteration: 2010000, Loss: 0.00040957988076692074\n",
            "Iteration: 2020000, Loss: 0.0004095476558992906\n",
            "Iteration: 2030000, Loss: 0.0004095160199458122\n",
            "Iteration: 2040000, Loss: 0.000409484961362562\n",
            "Iteration: 2050000, Loss: 0.00040945446884205146\n",
            "Iteration: 2060000, Loss: 0.00040942453130808805\n",
            "Iteration: 2070000, Loss: 0.0004093951379107736\n",
            "Iteration: 2080000, Loss: 0.0004093662780216087\n",
            "Iteration: 2090000, Loss: 0.00040933794122871434\n",
            "Iteration: 2100000, Loss: 0.0004093101173321665\n",
            "Iteration: 2110000, Loss: 0.00040928279633944373\n",
            "Iteration: 2120000, Loss: 0.0004092559684609657\n",
            "Iteration: 2130000, Loss: 0.0004092296241057531\n",
            "Iteration: 2140000, Loss: 0.00040920375387717257\n",
            "Iteration: 2150000, Loss: 0.0004091783485687938\n",
            "Iteration: 2160000, Loss: 0.0004091533991603258\n",
            "Iteration: 2170000, Loss: 0.0004091288968136623\n",
            "Iteration: 2180000, Loss: 0.0004091048328690062\n",
            "Iteration: 2190000, Loss: 0.00040908119884108427\n",
            "Iteration: 2200000, Loss: 0.0004090579864154556\n",
            "Iteration: 2210000, Loss: 0.00040903518744489405\n",
            "Iteration: 2220000, Loss: 0.0004090127939458563\n",
            "Iteration: 2230000, Loss: 0.00040899079809503366\n",
            "Iteration: 2240000, Loss: 0.0004089691922259753\n",
            "Iteration: 2250000, Loss: 0.00040894796882578983\n",
            "Iteration: 2260000, Loss: 0.0004089271205319247\n",
            "Iteration: 2270000, Loss: 0.00040890664012901105\n",
            "Iteration: 2280000, Loss: 0.0004088865205457832\n",
            "Iteration: 2290000, Loss: 0.00040886675485206803\n",
            "Iteration: 2300000, Loss: 0.00040884733625583573\n",
            "Iteration: 2310000, Loss: 0.00040882825810032396\n",
            "Iteration: 2320000, Loss: 0.00040880951386121757\n",
            "Iteration: 2330000, Loss: 0.00040879109714389843\n",
            "Iteration: 2340000, Loss: 0.0004087730016807487\n",
            "Iteration: 2350000, Loss: 0.00040875522132851965\n",
            "Iteration: 2360000, Loss: 0.00040873775006575484\n",
            "Iteration: 2370000, Loss: 0.00040872058199026984\n",
            "Iteration: 2380000, Loss: 0.0004087037113166894\n",
            "Iteration: 2390000, Loss: 0.00040868713237403786\n",
            "Iteration: 2400000, Loss: 0.00040867083960337877\n",
            "Iteration: 2410000, Loss: 0.00040865482755551234\n",
            "Iteration: 2420000, Loss: 0.0004086390908887156\n",
            "Iteration: 2430000, Loss: 0.0004086236243665379\n",
            "Iteration: 2440000, Loss: 0.0004086084228556411\n",
            "Iteration: 2450000, Loss: 0.0004085934813236867\n",
            "Iteration: 2460000, Loss: 0.0004085787948372687\n",
            "Iteration: 2470000, Loss: 0.00040856435855989167\n",
            "Iteration: 2480000, Loss: 0.0004085501677499934\n",
            "Iteration: 2490000, Loss: 0.0004085362177590047\n",
            "Iteration: 2500000, Loss: 0.00040852250402946007\n",
            "Iteration: 2510000, Loss: 0.0004085090220931395\n",
            "Iteration: 2520000, Loss: 0.0004084957675692546\n",
            "Iteration: 2530000, Loss: 0.00040848273616267585\n",
            "Iteration: 2540000, Loss: 0.00040846992366219123\n",
            "Iteration: 2550000, Loss: 0.0004084573259388073\n",
            "Iteration: 2560000, Loss: 0.00040844493894408486\n",
            "Iteration: 2570000, Loss: 0.0004084327587085079\n",
            "Iteration: 2580000, Loss: 0.00040842078133989117\n",
            "Iteration: 2590000, Loss: 0.0004084090030218175\n",
            "Iteration: 2600000, Loss: 0.000408397420012111\n",
            "Iteration: 2610000, Loss: 0.00040838602864133985\n",
            "Iteration: 2620000, Loss: 0.00040837482531135374\n",
            "Iteration: 2630000, Loss: 0.0004083638064938505\n",
            "Iteration: 2640000, Loss: 0.0004083529687289704\n",
            "Iteration: 2650000, Loss: 0.00040834230862392586\n",
            "Iteration: 2660000, Loss: 0.00040833182285165287\n",
            "Iteration: 2670000, Loss: 0.00040832150814949813\n",
            "Iteration: 2680000, Loss: 0.0004083113613179278\n",
            "Iteration: 2690000, Loss: 0.0004083013792192626\n",
            "Iteration: 2700000, Loss: 0.00040829155877644766\n",
            "Iteration: 2710000, Loss: 0.0004082818969718363\n",
            "Iteration: 2720000, Loss: 0.0004082723908460092\n",
            "Iteration: 2730000, Loss: 0.000408263037496612\n",
            "Iteration: 2740000, Loss: 0.00040825383407721856\n",
            "Iteration: 2750000, Loss: 0.00040824477779621897\n",
            "Iteration: 2760000, Loss: 0.0004082358659157314\n",
            "Iteration: 2770000, Loss: 0.00040822709575053076\n",
            "Iteration: 2780000, Loss: 0.0004082184646670081\n",
            "Iteration: 2790000, Loss: 0.00040820997008214323\n",
            "Iteration: 2800000, Loss: 0.0004082016094625037\n",
            "Iteration: 2810000, Loss: 0.00040819338032326426\n",
            "Iteration: 2820000, Loss: 0.00040818528022724395\n",
            "Iteration: 2830000, Loss: 0.00040817730678396273\n",
            "Iteration: 2840000, Loss: 0.000408169457648722\n",
            "Iteration: 2850000, Loss: 0.00040816173052169775\n",
            "Iteration: 2860000, Loss: 0.00040815412314705785\n",
            "Iteration: 2870000, Loss: 0.0004081466333120938\n",
            "Iteration: 2880000, Loss: 0.00040813925884637165\n",
            "Iteration: 2890000, Loss: 0.00040813199762089936\n",
            "Iteration: 2900000, Loss: 0.0004081248475473136\n",
            "Iteration: 2910000, Loss: 0.00040811780657707856\n",
            "Iteration: 2920000, Loss: 0.00040811087270070624\n",
            "Iteration: 2930000, Loss: 0.0004081040439469882\n",
            "Iteration: 2940000, Loss: 0.00040809731838224684\n",
            "Iteration: 2950000, Loss: 0.00040809069410959847\n",
            "Iteration: 2960000, Loss: 0.00040808416926823264\n",
            "Iteration: 2970000, Loss: 0.0004080777420327082\n",
            "Iteration: 2980000, Loss: 0.0004080714106122576\n",
            "Iteration: 2990000, Loss: 0.00040806517325011357\n",
            "Iteration: 3000000, Loss: 0.00040805902822284274\n",
            "Iteration: 3010000, Loss: 0.0004080529738396952\n",
            "Iteration: 3020000, Loss: 0.0004080470084419668\n",
            "Iteration: 3030000, Loss: 0.0004080411304023768\n",
            "Iteration: 3040000, Loss: 0.00040803533812445184\n",
            "Iteration: 3050000, Loss: 0.00040802963004192946\n",
            "Iteration: 3060000, Loss: 0.00040802400461816793\n",
            "Iteration: 3070000, Loss: 0.0004080184603455742\n",
            "Iteration: 3080000, Loss: 0.00040801299574503354\n",
            "Iteration: 3090000, Loss: 0.0004080076093653634\n",
            "Iteration: 3100000, Loss: 0.00040800229978276483\n",
            "Iteration: 3110000, Loss: 0.00040799706560029533\n",
            "Iteration: 3120000, Loss: 0.00040799190544734917\n",
            "Iteration: 3130000, Loss: 0.00040798681797914204\n",
            "Iteration: 3140000, Loss: 0.00040798180187621855\n",
            "Iteration: 3150000, Loss: 0.0004079768558439558\n",
            "Iteration: 3160000, Loss: 0.00040797197861208663\n",
            "Iteration: 3170000, Loss: 0.00040796716893422703\n",
            "Iteration: 3180000, Loss: 0.0004079624255874175\n",
            "Iteration: 3190000, Loss: 0.0004079577473716676\n",
            "Iteration: 3200000, Loss: 0.0004079531331095161\n",
            "Iteration: 3210000, Loss: 0.0004079485816455945\n",
            "Iteration: 3220000, Loss: 0.00040794409184620277\n",
            "Iteration: 3230000, Loss: 0.0004079396625988896\n",
            "Iteration: 3240000, Loss: 0.00040793529281204653\n",
            "Iteration: 3250000, Loss: 0.000407930981414506\n",
            "Iteration: 3260000, Loss: 0.0004079267273551472\n",
            "Iteration: 3270000, Loss: 0.00040792252960251144\n",
            "Iteration: 3280000, Loss: 0.0004079183871444259\n",
            "Iteration: 3290000, Loss: 0.00040791429898763245\n",
            "Iteration: 3300000, Loss: 0.0004079102641574246\n",
            "Iteration: 3310000, Loss: 0.00040790628169729156\n",
            "Iteration: 3320000, Loss: 0.0004079023506685712\n",
            "Iteration: 3330000, Loss: 0.0004078984701501065\n",
            "Iteration: 3340000, Loss: 0.0004078946392379114\n",
            "Iteration: 3350000, Loss: 0.0004078908570448425\n",
            "Iteration: 3360000, Loss: 0.0004078871227002753\n",
            "Iteration: 3370000, Loss: 0.00040788343534979256\n",
            "Iteration: 3380000, Loss: 0.0004078797941548685\n",
            "Iteration: 3390000, Loss: 0.000407876198292572\n",
            "Iteration: 3400000, Loss: 0.00040787264695526463\n",
            "Iteration: 3410000, Loss: 0.00040786913935031064\n",
            "Iteration: 3420000, Loss: 0.0004078656746997908\n",
            "Iteration: 3430000, Loss: 0.000407862252240223\n",
            "Iteration: 3440000, Loss: 0.00040785887122228473\n",
            "Iteration: 3450000, Loss: 0.0004078555309105467\n",
            "Iteration: 3460000, Loss: 0.00040785223058320644\n",
            "Iteration: 3470000, Loss: 0.0004078489695318314\n",
            "Iteration: 3480000, Loss: 0.0004078457470611007\n",
            "Iteration: 3490000, Loss: 0.0004078425624885613\n",
            "Iteration: 3500000, Loss: 0.000407839415144382\n",
            "Iteration: 3510000, Loss: 0.0004078363043711103\n",
            "Iteration: 3520000, Loss: 0.0004078332295234429\n",
            "Iteration: 3530000, Loss: 0.00040783018996799254\n",
            "Iteration: 3540000, Loss: 0.0004078271850830633\n",
            "Iteration: 3550000, Loss: 0.00040782421425842854\n",
            "Iteration: 3560000, Loss: 0.00040782127689511404\n",
            "Iteration: 3570000, Loss: 0.00040781837240518476\n",
            "Iteration: 3580000, Loss: 0.00040781550021153735\n",
            "Iteration: 3590000, Loss: 0.0004078126597476949\n",
            "Iteration: 3600000, Loss: 0.0004078098504576051\n",
            "Iteration: 3610000, Loss: 0.0004078070717954441\n",
            "Iteration: 3620000, Loss: 0.00040780432322542516\n",
            "Iteration: 3630000, Loss: 0.00040780160422160597\n",
            "Iteration: 3640000, Loss: 0.000407798914267706\n",
            "Iteration: 3650000, Loss: 0.0004077962528569234\n",
            "Iteration: 3660000, Loss: 0.0004077936194917567\n",
            "Iteration: 3670000, Loss: 0.0004077910136838278\n",
            "Iteration: 3680000, Loss: 0.0004077884349537135\n",
            "Iteration: 3690000, Loss: 0.0004077858828307755\n",
            "Iteration: 3700000, Loss: 0.0004077833568529944\n",
            "Iteration: 3710000, Loss: 0.0004077808565668092\n",
            "Iteration: 3720000, Loss: 0.0004077783815269568\n",
            "Iteration: 3730000, Loss: 0.00040777593129631977\n",
            "Iteration: 3740000, Loss: 0.00040777350544576706\n",
            "Iteration: 3750000, Loss: 0.0004077711035540118\n",
            "Iteration: 3760000, Loss: 0.00040776872520745906\n",
            "Iteration: 3770000, Loss: 0.00040776637000006254\n",
            "Iteration: 3780000, Loss: 0.0004077640375331855\n",
            "Iteration: 3790000, Loss: 0.00040776172741545825\n",
            "Iteration: 3800000, Loss: 0.000407759439262647\n",
            "Iteration: 3810000, Loss: 0.00040775717269751527\n",
            "Iteration: 3820000, Loss: 0.0004077549273496968\n",
            "Iteration: 3830000, Loss: 0.00040775270285556617\n",
            "Iteration: 3840000, Loss: 0.0004077504988581119\n",
            "Iteration: 3850000, Loss: 0.00040774831500681364\n",
            "Iteration: 3860000, Loss: 0.00040774615095752167\n",
            "Iteration: 3870000, Loss: 0.0004077440063723378\n",
            "Iteration: 3880000, Loss: 0.00040774188091949624\n",
            "Iteration: 3890000, Loss: 0.00040773977427325506\n",
            "Iteration: 3900000, Loss: 0.00040773768611377775\n",
            "Iteration: 3910000, Loss: 0.0004077356161270278\n",
            "Iteration: 3920000, Loss: 0.00040773356400465767\n",
            "Iteration: 3930000, Loss: 0.0004077315294439043\n",
            "Iteration: 3940000, Loss: 0.0004077295121474872\n",
            "Iteration: 3950000, Loss: 0.000407727511823502\n",
            "Iteration: 3960000, Loss: 0.0004077255281853255\n",
            "Iteration: 3970000, Loss: 0.0004077235609515134\n",
            "Iteration: 3980000, Loss: 0.000407721609845707\n",
            "Iteration: 3990000, Loss: 0.0004077196745965388\n",
            "Iteration: 4000000, Loss: 0.00040771775493753787\n",
            "Iteration: 4010000, Loss: 0.00040771585060704\n",
            "Iteration: 4020000, Loss: 0.00040771396134810093\n",
            "Iteration: 4030000, Loss: 0.00040771208690840415\n",
            "Iteration: 4040000, Loss: 0.0004077102270401804\n",
            "Iteration: 4050000, Loss: 0.00040770838150012094\n",
            "Iteration: 4060000, Loss: 0.0004077065500492943\n",
            "Iteration: 4070000, Loss: 0.0004077047324530669\n",
            "Iteration: 4080000, Loss: 0.00040770292848102315\n",
            "Iteration: 4090000, Loss: 0.00040770113790688795\n",
            "Iteration: 4100000, Loss: 0.00040769936050845005\n",
            "Iteration: 4110000, Loss: 0.00040769759606748443\n",
            "Iteration: 4120000, Loss: 0.000407695844369685\n",
            "Iteration: 4130000, Loss: 0.00040769410520458506\n",
            "Iteration: 4140000, Loss: 0.0004076923783654928\n",
            "Iteration: 4150000, Loss: 0.000407690663649417\n",
            "Iteration: 4160000, Loss: 0.00040768896085700276\n",
            "Iteration: 4170000, Loss: 0.0004076872697924608\n",
            "Iteration: 4180000, Loss: 0.0004076855902635056\n",
            "Iteration: 4190000, Loss: 0.00040768392208128735\n",
            "Iteration: 4200000, Loss: 0.0004076822650603325\n",
            "Iteration: 4210000, Loss: 0.00040768061901847916\n",
            "Iteration: 4220000, Loss: 0.0004076789837768164\n",
            "Iteration: 4230000, Loss: 0.00040767735915962555\n",
            "Iteration: 4240000, Loss: 0.00040767574499432174\n",
            "Iteration: 4250000, Loss: 0.00040767414111139564\n",
            "Iteration: 4260000, Loss: 0.00040767254734435835\n",
            "Iteration: 4270000, Loss: 0.00040767096352968297\n",
            "Iteration: 4280000, Loss: 0.00040766938950675426\n",
            "Iteration: 4290000, Loss: 0.00040766782511781415\n",
            "Iteration: 4300000, Loss: 0.00040766627020790677\n",
            "Iteration: 4310000, Loss: 0.0004076647246248312\n",
            "Iteration: 4320000, Loss: 0.00040766318821908913\n",
            "Iteration: 4330000, Loss: 0.00040766166084383427\n",
            "Iteration: 4340000, Loss: 0.00040766014235482683\n",
            "Iteration: 4350000, Loss: 0.00040765863261038306\n",
            "Iteration: 4360000, Loss: 0.0004076571314713316\n",
            "Iteration: 4370000, Loss: 0.0004076556388009641\n",
            "Iteration: 4380000, Loss: 0.0004076541544649938\n",
            "Iteration: 4390000, Loss: 0.000407652678331508\n",
            "Iteration: 4400000, Loss: 0.0004076512102709286\n",
            "Iteration: 4410000, Loss: 0.0004076497501559667\n",
            "Iteration: 4420000, Loss: 0.0004076482978615805\n",
            "Iteration: 4430000, Loss: 0.0004076468532649385\n",
            "Iteration: 4440000, Loss: 0.0004076454162453752\n",
            "Iteration: 4450000, Loss: 0.00040764398668435186\n",
            "Iteration: 4460000, Loss: 0.00040764256446542183\n",
            "Iteration: 4470000, Loss: 0.0004076411494741872\n",
            "Iteration: 4480000, Loss: 0.0004076397415982655\n",
            "Iteration: 4490000, Loss: 0.0004076383407272526\n",
            "Iteration: 4500000, Loss: 0.0004076369467526852\n",
            "Iteration: 4510000, Loss: 0.0004076355595680065\n",
            "Iteration: 4520000, Loss: 0.00040763417906853233\n",
            "Iteration: 4530000, Loss: 0.00040763280515141587\n",
            "Iteration: 4540000, Loss: 0.00040763143771561634\n",
            "Iteration: 4550000, Loss: 0.0004076300766618633\n",
            "Iteration: 4560000, Loss: 0.00040762872189262927\n",
            "Iteration: 4570000, Loss: 0.000407627373312093\n",
            "Iteration: 4580000, Loss: 0.0004076260308261122\n",
            "Iteration: 4590000, Loss: 0.00040762469434219245\n",
            "Iteration: 4600000, Loss: 0.00040762336376945577\n",
            "Iteration: 4610000, Loss: 0.00040762203901861365\n",
            "Iteration: 4620000, Loss: 0.0004076207200019378\n",
            "Iteration: 4630000, Loss: 0.0004076194066332313\n",
            "Iteration: 4640000, Loss: 0.000407618098827802\n",
            "Iteration: 4650000, Loss: 0.00040761679650243385\n",
            "Iteration: 4660000, Loss: 0.0004076154995753626\n",
            "Iteration: 4670000, Loss: 0.00040761420796624724\n",
            "Iteration: 4680000, Loss: 0.0004076129215961465\n",
            "Iteration: 4690000, Loss: 0.0004076116403874926\n",
            "Iteration: 4700000, Loss: 0.00040761036426406665\n",
            "Iteration: 4710000, Loss: 0.0004076090931509741\n",
            "Iteration: 4720000, Loss: 0.0004076078269746222\n",
            "Iteration: 4730000, Loss: 0.0004076065656626944\n",
            "Iteration: 4740000, Loss: 0.0004076053091441308\n",
            "Iteration: 4750000, Loss: 0.00040760405734910273\n",
            "Iteration: 4760000, Loss: 0.00040760281020899106\n",
            "Iteration: 4770000, Loss: 0.0004076015676563662\n",
            "Iteration: 4780000, Loss: 0.0004076003296249651\n",
            "Iteration: 4790000, Loss: 0.00040759909604967144\n",
            "Iteration: 4800000, Loss: 0.00040759786686649384\n",
            "Iteration: 4810000, Loss: 0.00040759664201254743\n",
            "Iteration: 4820000, Loss: 0.00040759542142603276\n",
            "Iteration: 4830000, Loss: 0.00040759420504621715\n",
            "Iteration: 4840000, Loss: 0.0004075929928134156\n",
            "Iteration: 4850000, Loss: 0.00040759178466897103\n",
            "Iteration: 4860000, Loss: 0.00040759058055523734\n",
            "Iteration: 4870000, Loss: 0.0004075893804155613\n",
            "Iteration: 4880000, Loss: 0.0004075881841942629\n",
            "Iteration: 4890000, Loss: 0.0004075869918366206\n",
            "Iteration: 4900000, Loss: 0.00040758580328885413\n",
            "Iteration: 4910000, Loss: 0.0004075846184981042\n",
            "Iteration: 4920000, Loss: 0.000407583437412421\n",
            "Iteration: 4930000, Loss: 0.00040758225998074416\n",
            "Iteration: 4940000, Loss: 0.00040758108615288963\n",
            "Iteration: 4950000, Loss: 0.00040757991587953224\n",
            "Iteration: 4960000, Loss: 0.0004075787491121903\n",
            "Iteration: 4970000, Loss: 0.0004075775858032149\n",
            "Iteration: 4980000, Loss: 0.000407576425905767\n",
            "Iteration: 4990000, Loss: 0.00040757526937381235\n",
            "Iteration: 5000000, Loss: 0.0004075741161620986\n",
            "Iteration: 5010000, Loss: 0.00040757296622614996\n",
            "Iteration: 5020000, Loss: 0.0004075718195222443\n",
            "Iteration: 5030000, Loss: 0.0004075706760074076\n",
            "Iteration: 5040000, Loss: 0.0004075695356393978\n",
            "Iteration: 5050000, Loss: 0.0004075683983766898\n",
            "Iteration: 5060000, Loss: 0.000407567264178466\n",
            "Iteration: 5070000, Loss: 0.00040756613300460217\n",
            "Iteration: 5080000, Loss: 0.0004075650048156561\n",
            "Iteration: 5090000, Loss: 0.00040756387957285373\n",
            "Iteration: 5100000, Loss: 0.0004075627572380806\n",
            "Iteration: 5110000, Loss: 0.0004075616377738658\n",
            "Iteration: 5120000, Loss: 0.00040756052114337466\n",
            "Iteration: 5130000, Loss: 0.0004075594073103969\n",
            "Iteration: 5140000, Loss: 0.00040755829623933274\n",
            "Iteration: 5150000, Loss: 0.00040755718789518424\n",
            "Iteration: 5160000, Loss: 0.00040755608224354634\n",
            "Iteration: 5170000, Loss: 0.000407554979250593\n",
            "Iteration: 5180000, Loss: 0.00040755387888306995\n",
            "Iteration: 5190000, Loss: 0.00040755278110828254\n",
            "Iteration: 5200000, Loss: 0.0004075516858940865\n",
            "Iteration: 5210000, Loss: 0.0004075505932088803\n",
            "Iteration: 5220000, Loss: 0.00040754950302159155\n",
            "Iteration: 5230000, Loss: 0.0004075484153016718\n",
            "Iteration: 5240000, Loss: 0.0004075473300190859\n",
            "Iteration: 5250000, Loss: 0.00040754624714430123\n",
            "Iteration: 5260000, Loss: 0.0004075451666482815\n",
            "Iteration: 5270000, Loss: 0.00040754408850247713\n",
            "Iteration: 5280000, Loss: 0.0004075430126788151\n",
            "Iteration: 5290000, Loss: 0.0004075419391496933\n",
            "Iteration: 5300000, Loss: 0.0004075408678879717\n",
            "Iteration: 5310000, Loss: 0.0004075397988669628\n",
            "Iteration: 5320000, Loss: 0.0004075387320604246\n",
            "Iteration: 5330000, Loss: 0.00040753766744255297\n",
            "Iteration: 5340000, Loss: 0.00040753660498797504\n",
            "Iteration: 5350000, Loss: 0.0004075355446717384\n",
            "Iteration: 5360000, Loss: 0.0004075344864693072\n",
            "Iteration: 5370000, Loss: 0.000407533430356554\n",
            "Iteration: 5380000, Loss: 0.0004075323763097507\n",
            "Iteration: 5390000, Loss: 0.00040753132430556513\n",
            "Iteration: 5400000, Loss: 0.00040753027432105195\n",
            "Iteration: 5410000, Loss: 0.00040752922633364324\n",
            "Iteration: 5420000, Loss: 0.00040752818032115004\n",
            "Iteration: 5430000, Loss: 0.0004075271362617456\n",
            "Iteration: 5440000, Loss: 0.0004075260941339666\n",
            "Iteration: 5450000, Loss: 0.0004075250539167052\n",
            "Iteration: 5460000, Loss: 0.0004075240155891993\n",
            "Iteration: 5470000, Loss: 0.00040752297913103255\n",
            "Iteration: 5480000, Loss: 0.0004075219445221216\n",
            "Iteration: 5490000, Loss: 0.00040752091174271667\n",
            "Iteration: 5500000, Loss: 0.00040751988077339217\n",
            "Iteration: 5510000, Loss: 0.00040751885159504063\n",
            "Iteration: 5520000, Loss: 0.0004075178241888701\n",
            "Iteration: 5530000, Loss: 0.0004075167985363958\n",
            "Iteration: 5540000, Loss: 0.0004075157746194377\n",
            "Iteration: 5550000, Loss: 0.00040751475242011063\n",
            "Iteration: 5560000, Loss: 0.0004075137319208257\n",
            "Iteration: 5570000, Loss: 0.00040751271310427974\n",
            "Iteration: 5580000, Loss: 0.00040751169595345144\n",
            "Iteration: 5590000, Loss: 0.0004075106804515993\n",
            "Iteration: 5600000, Loss: 0.0004075096665822542\n",
            "Iteration: 5610000, Loss: 0.00040750865432921484\n",
            "Iteration: 5620000, Loss: 0.00040750764367654396\n",
            "Iteration: 5630000, Loss: 0.00040750663460856397\n",
            "Iteration: 5640000, Loss: 0.0004075056271098508\n",
            "Iteration: 5650000, Loss: 0.00040750462116523274\n",
            "Iteration: 5660000, Loss: 0.00040750361675978276\n",
            "Iteration: 5670000, Loss: 0.000407502613878815\n",
            "Iteration: 5680000, Loss: 0.0004075016125078832\n",
            "Iteration: 5690000, Loss: 0.00040750061263277387\n",
            "Iteration: 5700000, Loss: 0.0004074996142395024\n",
            "Iteration: 5710000, Loss: 0.00040749861731431084\n",
            "Iteration: 5720000, Loss: 0.00040749762184366385\n",
            "Iteration: 5730000, Loss: 0.00040749662781424095\n",
            "Iteration: 5740000, Loss: 0.00040749563521293966\n",
            "Iteration: 5750000, Loss: 0.0004074946440268668\n",
            "Iteration: 5760000, Loss: 0.00040749365424333516\n",
            "Iteration: 5770000, Loss: 0.00040749266584986203\n",
            "Iteration: 5780000, Loss: 0.0004074916788341654\n",
            "Iteration: 5790000, Loss: 0.0004074906931841586\n",
            "Iteration: 5800000, Loss: 0.00040748970888794897\n",
            "Iteration: 5810000, Loss: 0.00040748872593383346\n",
            "Iteration: 5820000, Loss: 0.0004074877443102967\n",
            "Iteration: 5830000, Loss: 0.00040748676400600547\n",
            "Iteration: 5840000, Loss: 0.00040748578500980723\n",
            "Iteration: 5850000, Loss: 0.00040748480731072874\n",
            "Iteration: 5860000, Loss: 0.0004074838308979686\n",
            "Iteration: 5870000, Loss: 0.00040748285576089886\n",
            "Iteration: 5880000, Loss: 0.00040748188188905783\n",
            "Iteration: 5890000, Loss: 0.0004074809092721516\n",
            "Iteration: 5900000, Loss: 0.0004074799379000485\n",
            "Iteration: 5910000, Loss: 0.0004074789677627768\n",
            "Iteration: 5920000, Loss: 0.0004074779988505203\n",
            "Iteration: 5930000, Loss: 0.00040747703115362086\n",
            "Iteration: 5940000, Loss: 0.00040747606466257097\n",
            "Iteration: 5950000, Loss: 0.00040747509936801124\n",
            "Iteration: 5960000, Loss: 0.00040747413526073063\n",
            "Iteration: 5970000, Loss: 0.0004074731723316631\n",
            "Iteration: 5980000, Loss: 0.0004074722105718836\n",
            "Iteration: 5990000, Loss: 0.00040747124997260643\n",
            "Iteration: 6000000, Loss: 0.00040747029052518464\n",
            "Iteration: 6010000, Loss: 0.000407469332221105\n",
            "Iteration: 6020000, Loss: 0.00040746837505198813\n",
            "Iteration: 6030000, Loss: 0.0004074674190095832\n",
            "Iteration: 6040000, Loss: 0.0004074664640857698\n",
            "Iteration: 6050000, Loss: 0.0004074655102725524\n",
            "Iteration: 6060000, Loss: 0.00040746455756205936\n",
            "Iteration: 6070000, Loss: 0.00040746360594654196\n",
            "Iteration: 6080000, Loss: 0.00040746265541837055\n",
            "Iteration: 6090000, Loss: 0.00040746170597003354\n",
            "Iteration: 6100000, Loss: 0.00040746075759413446\n",
            "Iteration: 6110000, Loss: 0.000407459810283392\n",
            "Iteration: 6120000, Loss: 0.00040745886403063667\n",
            "Iteration: 6130000, Loss: 0.00040745791882880814\n",
            "Iteration: 6140000, Loss: 0.0004074569746709553\n",
            "Iteration: 6150000, Loss: 0.000407456031550233\n",
            "Iteration: 6160000, Loss: 0.00040745508945990106\n",
            "Iteration: 6170000, Loss: 0.0004074541483933224\n",
            "Iteration: 6180000, Loss: 0.0004074532083439603\n",
            "Iteration: 6190000, Loss: 0.0004074522693053793\n",
            "Iteration: 6200000, Loss: 0.0004074513312712394\n",
            "Iteration: 6210000, Loss: 0.0004074503942352988\n",
            "Iteration: 6220000, Loss: 0.0004074494581914103\n",
            "Iteration: 6230000, Loss: 0.00040744852313351793\n",
            "Iteration: 6240000, Loss: 0.0004074475890556583\n",
            "Iteration: 6250000, Loss: 0.00040744665595195963\n",
            "Iteration: 6260000, Loss: 0.0004074457238166354\n",
            "Iteration: 6270000, Loss: 0.0004074447926439888\n",
            "Iteration: 6280000, Loss: 0.00040744386242840723\n",
            "Iteration: 6290000, Loss: 0.00040744293316436283\n",
            "Iteration: 6300000, Loss: 0.0004074420048464099\n",
            "Iteration: 6310000, Loss: 0.00040744107746918426\n",
            "Iteration: 6320000, Loss: 0.00040744015102740246\n",
            "Iteration: 6330000, Loss: 0.0004074392255158585\n",
            "Iteration: 6340000, Loss: 0.00040743830092942535\n",
            "Iteration: 6350000, Loss: 0.00040743737726305014\n",
            "Iteration: 6360000, Loss: 0.0004074364545117565\n",
            "Iteration: 6370000, Loss: 0.00040743553267064093\n",
            "Iteration: 6380000, Loss: 0.0004074346117348725\n",
            "Iteration: 6390000, Loss: 0.00040743369169969135\n",
            "Iteration: 6400000, Loss: 0.00040743277256040703\n",
            "Iteration: 6410000, Loss: 0.0004074318543123996\n",
            "Iteration: 6420000, Loss: 0.0004074309369511154\n",
            "Iteration: 6430000, Loss: 0.0004074300204720677\n",
            "Iteration: 6440000, Loss: 0.0004074291048708354\n",
            "Iteration: 6450000, Loss: 0.0004074281901430618\n",
            "Iteration: 6460000, Loss: 0.00040742727628445324\n",
            "Iteration: 6470000, Loss: 0.0004074263632907799\n",
            "Iteration: 6480000, Loss: 0.0004074254511578702\n",
            "Iteration: 6490000, Loss: 0.00040742453988161666\n",
            "Iteration: 6500000, Loss: 0.00040742362945796776\n",
            "Iteration: 6510000, Loss: 0.00040742271988293186\n",
            "Iteration: 6520000, Loss: 0.00040742181115257516\n",
            "Iteration: 6530000, Loss: 0.00040742090326301844\n",
            "Iteration: 6540000, Loss: 0.00040741999621044065\n",
            "Iteration: 6550000, Loss: 0.0004074190899910731\n",
            "Iteration: 6560000, Loss: 0.0004074181846012012\n",
            "Iteration: 6570000, Loss: 0.0004074172800371643\n",
            "Iteration: 6580000, Loss: 0.0004074163762953521\n",
            "Iteration: 6590000, Loss: 0.0004074154733722067\n",
            "Iteration: 6600000, Loss: 0.0004074145712642192\n",
            "Iteration: 6610000, Loss: 0.00040741366996793256\n",
            "Iteration: 6620000, Loss: 0.0004074127694799358\n",
            "Iteration: 6630000, Loss: 0.00040741186979686647\n",
            "Iteration: 6640000, Loss: 0.0004074109709154094\n",
            "Iteration: 6650000, Loss: 0.00040741007283229556\n",
            "Iteration: 6660000, Loss: 0.00040740917554430296\n",
            "Iteration: 6670000, Loss: 0.00040740827904825174\n",
            "Iteration: 6680000, Loss: 0.00040740738334100806\n",
            "Iteration: 6690000, Loss: 0.0004074064884194812\n",
            "Iteration: 6700000, Loss: 0.00040740559428062114\n",
            "Iteration: 6710000, Loss: 0.0004074047009214239\n",
            "Iteration: 6720000, Loss: 0.0004074038083389221\n",
            "Iteration: 6730000, Loss: 0.0004074029165301923\n",
            "Iteration: 6740000, Loss: 0.00040740202549234956\n",
            "Iteration: 6750000, Loss: 0.0004074011352225483\n",
            "Iteration: 6760000, Loss: 0.0004074002457179827\n",
            "Iteration: 6770000, Loss: 0.00040739935697588285\n",
            "Iteration: 6780000, Loss: 0.00040739846899351883\n",
            "Iteration: 6790000, Loss: 0.00040739758176819524\n",
            "Iteration: 6800000, Loss: 0.0004073966952972546\n",
            "Iteration: 6810000, Loss: 0.000407395809578074\n",
            "Iteration: 6820000, Loss: 0.0004073949246080652\n",
            "Iteration: 6830000, Loss: 0.00040739404038467753\n",
            "Iteration: 6840000, Loss: 0.00040739315690538976\n",
            "Iteration: 6850000, Loss: 0.0004073922741677168\n",
            "Iteration: 6860000, Loss: 0.0004073913921692068\n",
            "Iteration: 6870000, Loss: 0.0004073905109074374\n",
            "Iteration: 6880000, Loss: 0.0004073896303800215\n",
            "Iteration: 6890000, Loss: 0.0004073887505846014\n",
            "Iteration: 6900000, Loss: 0.0004073878715188503\n",
            "Iteration: 6910000, Loss: 0.0004073869931804721\n",
            "Iteration: 6920000, Loss: 0.0004073861155671998\n",
            "Iteration: 6930000, Loss: 0.00040738523867679764\n",
            "Iteration: 6940000, Loss: 0.00040738436250705557\n",
            "Iteration: 6950000, Loss: 0.00040738348705579537\n",
            "Iteration: 6960000, Loss: 0.00040738261232086374\n",
            "Iteration: 6970000, Loss: 0.0004073817383001367\n",
            "Iteration: 6980000, Loss: 0.0004073808649915175\n",
            "Iteration: 6990000, Loss: 0.000407379992392934\n",
            "Iteration: 7000000, Loss: 0.00040737912050234343\n",
            "Iteration: 7010000, Loss: 0.00040737824931772555\n",
            "Iteration: 7020000, Loss: 0.00040737737883708806\n",
            "Iteration: 7030000, Loss: 0.0004073765090584614\n",
            "Iteration: 7040000, Loss: 0.0004073756399799027\n",
            "Iteration: 7050000, Loss: 0.00040737477159949166\n",
            "Iteration: 7060000, Loss: 0.00040737390391533293\n",
            "Iteration: 7070000, Loss: 0.00040737303692555353\n",
            "Iteration: 7080000, Loss: 0.000407372170628304\n",
            "Iteration: 7090000, Loss: 0.00040737130502175835\n",
            "Iteration: 7100000, Loss: 0.00040737044010411103\n",
            "Iteration: 7110000, Loss: 0.00040736957587358085\n",
            "Iteration: 7120000, Loss: 0.0004073687123284056\n",
            "Iteration: 7130000, Loss: 0.00040736784946684664\n",
            "Iteration: 7140000, Loss: 0.00040736698728718505\n",
            "Iteration: 7150000, Loss: 0.0004073661257877222\n",
            "Iteration: 7160000, Loss: 0.00040736526496678124\n",
            "Iteration: 7170000, Loss: 0.00040736440482270375\n",
            "Iteration: 7180000, Loss: 0.00040736354535385186\n",
            "Iteration: 7190000, Loss: 0.00040736268655860617\n",
            "Iteration: 7200000, Loss: 0.000407361828435368\n",
            "Iteration: 7210000, Loss: 0.0004073609709825553\n",
            "Iteration: 7220000, Loss: 0.0004073601141986054\n",
            "Iteration: 7230000, Loss: 0.0004073592580819743\n",
            "Iteration: 7240000, Loss: 0.00040735840263113495\n",
            "Iteration: 7250000, Loss: 0.000407357547844578\n",
            "Iteration: 7260000, Loss: 0.0004073566937208124\n",
            "Iteration: 7270000, Loss: 0.0004073558402583626\n",
            "Iteration: 7280000, Loss: 0.00040735498745577157\n",
            "Iteration: 7290000, Loss: 0.0004073541353115972\n",
            "Iteration: 7300000, Loss: 0.0004073532838244137\n",
            "Iteration: 7310000, Loss: 0.0004073524329928131\n",
            "Iteration: 7320000, Loss: 0.00040735158281540046\n",
            "Iteration: 7330000, Loss: 0.0004073507332907994\n",
            "Iteration: 7340000, Loss: 0.0004073498844176453\n",
            "Iteration: 7350000, Loss: 0.000407349036194591\n",
            "Iteration: 7360000, Loss: 0.000407348188620304\n",
            "Iteration: 7370000, Loss: 0.00040734734169346537\n",
            "Iteration: 7380000, Loss: 0.0004073464954127708\n",
            "Iteration: 7390000, Loss: 0.00040734564977693054\n",
            "Iteration: 7400000, Loss: 0.0004073448047846691\n",
            "Iteration: 7410000, Loss: 0.00040734396043472254\n",
            "Iteration: 7420000, Loss: 0.000407343116725842\n",
            "Iteration: 7430000, Loss: 0.00040734227365679253\n",
            "Iteration: 7440000, Loss: 0.0004073414312263507\n",
            "Iteration: 7450000, Loss: 0.00040734058943330676\n",
            "Iteration: 7460000, Loss: 0.0004073397482764627\n",
            "Iteration: 7470000, Loss: 0.0004073389077546348\n",
            "Iteration: 7480000, Loss: 0.0004073380678666496\n",
            "Iteration: 7490000, Loss: 0.0004073372286113461\n",
            "Iteration: 7500000, Loss: 0.0004073363899875767\n",
            "Iteration: 7510000, Loss: 0.00040733555199420316\n",
            "Iteration: 7520000, Loss: 0.00040733471463010105\n",
            "Iteration: 7530000, Loss: 0.00040733387789415555\n",
            "Iteration: 7540000, Loss: 0.0004073330417852632\n",
            "Iteration: 7550000, Loss: 0.0004073322063023321\n",
            "Iteration: 7560000, Loss: 0.00040733137144428156\n",
            "Iteration: 7570000, Loss: 0.00040733053721004047\n",
            "Iteration: 7580000, Loss: 0.00040732970359854895\n",
            "Iteration: 7590000, Loss: 0.00040732887060875754\n",
            "Iteration: 7600000, Loss: 0.0004073280382396251\n",
            "Iteration: 7610000, Loss: 0.0004073272064901232\n",
            "Iteration: 7620000, Loss: 0.00040732637535923193\n",
            "Iteration: 7630000, Loss: 0.00040732554484594093\n",
            "Iteration: 7640000, Loss: 0.00040732471494925017\n",
            "Iteration: 7650000, Loss: 0.000407323885668167\n",
            "Iteration: 7660000, Loss: 0.0004073230570017121\n",
            "Iteration: 7670000, Loss: 0.0004073222289489107\n",
            "Iteration: 7680000, Loss: 0.0004073214015087995\n",
            "Iteration: 7690000, Loss: 0.0004073205746804241\n",
            "Iteration: 7700000, Loss: 0.00040731974846283767\n",
            "Iteration: 7710000, Loss: 0.00040731892285510336\n",
            "Iteration: 7720000, Loss: 0.00040731809785629175\n",
            "Iteration: 7730000, Loss: 0.0004073172734654815\n",
            "Iteration: 7740000, Loss: 0.0004073164496817602\n",
            "Iteration: 7750000, Loss: 0.00040731562650422404\n",
            "Iteration: 7760000, Loss: 0.0004073148039319761\n",
            "Iteration: 7770000, Loss: 0.0004073139819641266\n",
            "Iteration: 7780000, Loss: 0.0004073131605997958\n",
            "Iteration: 7790000, Loss: 0.00040731233983810986\n",
            "Iteration: 7800000, Loss: 0.00040731151967820253\n",
            "Iteration: 7810000, Loss: 0.00040731070011921605\n",
            "Iteration: 7820000, Loss: 0.00040730988116029725\n",
            "Iteration: 7830000, Loss: 0.00040730906280060414\n",
            "Iteration: 7840000, Loss: 0.00040730824503929826\n",
            "Iteration: 7850000, Loss: 0.00040730742787555\n",
            "Iteration: 7860000, Loss: 0.0004073066113085353\n",
            "Iteration: 7870000, Loss: 0.00040730579533743817\n",
            "Iteration: 7880000, Loss: 0.0004073049799614488\n",
            "Iteration: 7890000, Loss: 0.0004073041651797628\n",
            "Iteration: 7900000, Loss: 0.00040730335099158386\n",
            "Iteration: 7910000, Loss: 0.0004073025373961216\n",
            "Iteration: 7920000, Loss: 0.0004073017243925906\n",
            "Iteration: 7930000, Loss: 0.0004073009119802132\n",
            "Iteration: 7940000, Loss: 0.0004073001001582168\n",
            "Iteration: 7950000, Loss: 0.00040729928892583586\n",
            "Iteration: 7960000, Loss: 0.0004072984782823082\n",
            "Iteration: 7970000, Loss: 0.00040729766822688137\n",
            "Iteration: 7980000, Loss: 0.0004072968587588055\n",
            "Iteration: 7990000, Loss: 0.0004072960498773376\n",
            "Iteration: 8000000, Loss: 0.0004072952415817393\n",
            "Iteration: 8010000, Loss: 0.000407294433871279\n",
            "Iteration: 8020000, Loss: 0.00040729362674523013\n",
            "Iteration: 8030000, Loss: 0.0004072928202028693\n",
            "Iteration: 8040000, Loss: 0.00040729201424348233\n",
            "Iteration: 8050000, Loss: 0.00040729120886635683\n",
            "Iteration: 8060000, Loss: 0.00040729040407078723\n",
            "Iteration: 8070000, Loss: 0.0004072895998560715\n",
            "Iteration: 8080000, Loss: 0.0004072887962215142\n",
            "Iteration: 8090000, Loss: 0.0004072879931664238\n",
            "Iteration: 8100000, Loss: 0.0004072871906901135\n",
            "Iteration: 8110000, Loss: 0.0004072863887919015\n",
            "Iteration: 8120000, Loss: 0.0004072855874711103\n",
            "Iteration: 8130000, Loss: 0.0004072847867270675\n",
            "Iteration: 8140000, Loss: 0.0004072839865591051\n",
            "Iteration: 8150000, Loss: 0.00040728318696655875\n",
            "Iteration: 8160000, Loss: 0.00040728238794876976\n",
            "Iteration: 8170000, Loss: 0.0004072815895050828\n",
            "Iteration: 8180000, Loss: 0.00040728079163484697\n",
            "Iteration: 8190000, Loss: 0.00040727999433741593\n",
            "Iteration: 8200000, Loss: 0.000407279197612147\n",
            "Iteration: 8210000, Loss: 0.00040727840145840164\n",
            "Iteration: 8220000, Loss: 0.0004072776058755454\n",
            "Iteration: 8230000, Loss: 0.0004072768108629481\n",
            "Iteration: 8240000, Loss: 0.00040727601641998336\n",
            "Iteration: 8250000, Loss: 0.0004072752225460283\n",
            "Iteration: 8260000, Loss: 0.0004072744292404636\n",
            "Iteration: 8270000, Loss: 0.00040727363650267483\n",
            "Iteration: 8280000, Loss: 0.00040727284433205\n",
            "Iteration: 8290000, Loss: 0.0004072720527279808\n",
            "Iteration: 8300000, Loss: 0.00040727126168986375\n",
            "Iteration: 8310000, Loss: 0.00040727047121709767\n",
            "Iteration: 8320000, Loss: 0.0004072696813090855\n",
            "Iteration: 8330000, Loss: 0.00040726889196523276\n",
            "Iteration: 8340000, Loss: 0.00040726810318494937\n",
            "Iteration: 8350000, Loss: 0.0004072673149676485\n",
            "Iteration: 8360000, Loss: 0.00040726652731274554\n",
            "Iteration: 8370000, Loss: 0.00040726574021966017\n",
            "Iteration: 8380000, Loss: 0.0004072649536878145\n",
            "Iteration: 8390000, Loss: 0.0004072641677166347\n",
            "Iteration: 8400000, Loss: 0.00040726338230554957\n",
            "Iteration: 8410000, Loss: 0.0004072625974539904\n",
            "Iteration: 8420000, Loss: 0.0004072618131613929\n",
            "Iteration: 8430000, Loss: 0.0004072610294271939\n",
            "Iteration: 8440000, Loss: 0.0004072602462508344\n",
            "Iteration: 8450000, Loss: 0.00040725946363175835\n",
            "Iteration: 8460000, Loss: 0.0004072586815694117\n",
            "Iteration: 8470000, Loss: 0.00040725790006324454\n",
            "Iteration: 8480000, Loss: 0.0004072571191127084\n",
            "Iteration: 8490000, Loss: 0.000407256338717258\n",
            "Iteration: 8500000, Loss: 0.00040725555887635126\n",
            "Iteration: 8510000, Loss: 0.0004072547795894479\n",
            "Iteration: 8520000, Loss: 0.0004072540008560104\n",
            "Iteration: 8530000, Loss: 0.00040725322267550477\n",
            "Iteration: 8540000, Loss: 0.000407252445047399\n",
            "Iteration: 8550000, Loss: 0.00040725166797116245\n",
            "Iteration: 8560000, Loss: 0.00040725089144626897\n",
            "Iteration: 8570000, Loss: 0.0004072501154721937\n",
            "Iteration: 8580000, Loss: 0.00040724934004841433\n",
            "Iteration: 8590000, Loss: 0.0004072485651744106\n",
            "Iteration: 8600000, Loss: 0.0004072477908496657\n",
            "Iteration: 8610000, Loss: 0.00040724701707366465\n",
            "Iteration: 8620000, Loss: 0.00040724624384589296\n",
            "Iteration: 8630000, Loss: 0.00040724547116584173\n",
            "Iteration: 8640000, Loss: 0.0004072446990330014\n",
            "Iteration: 8650000, Loss: 0.0004072439274468665\n",
            "Iteration: 8660000, Loss: 0.0004072431564069324\n",
            "Iteration: 8670000, Loss: 0.00040724238591269713\n",
            "Iteration: 8680000, Loss: 0.00040724161596366156\n",
            "Iteration: 8690000, Loss: 0.00040724084655932623\n",
            "Iteration: 8700000, Loss: 0.00040724007769919767\n",
            "Iteration: 8710000, Loss: 0.0004072393093827814\n",
            "Iteration: 8720000, Loss: 0.00040723854160958496\n",
            "Iteration: 8730000, Loss: 0.000407237774379119\n",
            "Iteration: 8740000, Loss: 0.00040723700769089666\n",
            "Iteration: 8750000, Loss: 0.00040723624154443105\n",
            "Iteration: 8760000, Loss: 0.0004072354759392384\n",
            "Iteration: 8770000, Loss: 0.0004072347108748367\n",
            "Iteration: 8780000, Loss: 0.0004072339463507465\n",
            "Iteration: 8790000, Loss: 0.0004072331823664879\n",
            "Iteration: 8800000, Loss: 0.00040723241892158524\n",
            "Iteration: 8810000, Loss: 0.0004072316560155633\n",
            "Iteration: 8820000, Loss: 0.00040723089364794944\n",
            "Iteration: 8830000, Loss: 0.0004072301318182726\n",
            "Iteration: 8840000, Loss: 0.00040722937052606176\n",
            "Iteration: 8850000, Loss: 0.00040722860977084985\n",
            "Iteration: 8860000, Loss: 0.00040722784955217126\n",
            "Iteration: 8870000, Loss: 0.0004072270898695604\n",
            "Iteration: 8880000, Loss: 0.00040722633072255357\n",
            "Iteration: 8890000, Loss: 0.00040722557211069036\n",
            "Iteration: 8900000, Loss: 0.0004072248140335113\n",
            "Iteration: 8910000, Loss: 0.00040722405649055695\n",
            "Iteration: 8920000, Loss: 0.0004072232994813711\n",
            "Iteration: 8930000, Loss: 0.00040722254300549864\n",
            "Iteration: 8940000, Loss: 0.0004072217870624862\n",
            "Iteration: 8950000, Loss: 0.0004072210316518796\n",
            "Iteration: 8960000, Loss: 0.0004072202767732303\n",
            "Iteration: 8970000, Loss: 0.0004072195224260881\n",
            "Iteration: 8980000, Loss: 0.0004072187686100048\n",
            "Iteration: 8990000, Loss: 0.0004072180153245341\n",
            "Iteration: 9000000, Loss: 0.0004072172625692314\n",
            "Iteration: 9010000, Loss: 0.00040721651034365206\n",
            "Iteration: 9020000, Loss: 0.0004072157586473546\n",
            "Iteration: 9030000, Loss: 0.000407215007479897\n",
            "Iteration: 9040000, Loss: 0.00040721425684084057\n",
            "Iteration: 9050000, Loss: 0.00040721350672974597\n",
            "Iteration: 9060000, Loss: 0.00040721275714617643\n",
            "Iteration: 9070000, Loss: 0.00040721200808969634\n",
            "Iteration: 9080000, Loss: 0.00040721125955987147\n",
            "Iteration: 9090000, Loss: 0.00040721051155626753\n",
            "Iteration: 9100000, Loss: 0.00040720976407845265\n",
            "Iteration: 9110000, Loss: 0.0004072090171259964\n",
            "Iteration: 9120000, Loss: 0.0004072082706984691\n",
            "Iteration: 9130000, Loss: 0.00040720752479544227\n",
            "Iteration: 9140000, Loss: 0.000407206779416488\n",
            "Iteration: 9150000, Loss: 0.00040720603456118087\n",
            "Iteration: 9160000, Loss: 0.00040720529022909553\n",
            "Iteration: 9170000, Loss: 0.00040720454641980864\n",
            "Iteration: 9180000, Loss: 0.00040720380313289653\n",
            "Iteration: 9190000, Loss: 0.0004072030603679379\n",
            "Iteration: 9200000, Loss: 0.000407202318124513\n",
            "Iteration: 9210000, Loss: 0.00040720157640220135\n",
            "Iteration: 9220000, Loss: 0.0004072008352005855\n",
            "Iteration: 9230000, Loss: 0.0004072000945192466\n",
            "Iteration: 9240000, Loss: 0.00040719935435776976\n",
            "Iteration: 9250000, Loss: 0.0004071986147157393\n",
            "Iteration: 9260000, Loss: 0.0004071978755927411\n",
            "Iteration: 9270000, Loss: 0.0004071971369883623\n",
            "Iteration: 9280000, Loss: 0.00040719639890218946\n",
            "Iteration: 9290000, Loss: 0.00040719566133381275\n",
            "Iteration: 9300000, Loss: 0.0004071949242828207\n",
            "Iteration: 9310000, Loss: 0.000407194187748805\n",
            "Iteration: 9320000, Loss: 0.00040719345173135694\n",
            "Iteration: 9330000, Loss: 0.0004071927162300689\n",
            "Iteration: 9340000, Loss: 0.0004071919812445347\n",
            "Iteration: 9350000, Loss: 0.0004071912467743488\n",
            "Iteration: 9360000, Loss: 0.0004071905128191062\n",
            "Iteration: 9370000, Loss: 0.0004071897793784037\n",
            "Iteration: 9380000, Loss: 0.00040718904645183844\n",
            "Iteration: 9390000, Loss: 0.0004071883140390086\n",
            "Iteration: 9400000, Loss: 0.00040718758213951226\n",
            "Iteration: 9410000, Loss: 0.00040718685075295016\n",
            "Iteration: 9420000, Loss: 0.0004071861198789222\n",
            "Iteration: 9430000, Loss: 0.0004071853895170307\n",
            "Iteration: 9440000, Loss: 0.0004071846596668774\n",
            "Iteration: 9450000, Loss: 0.00040718393032806543\n",
            "Iteration: 9460000, Loss: 0.0004071832015001995\n",
            "Iteration: 9470000, Loss: 0.0004071824731828833\n",
            "Iteration: 9480000, Loss: 0.00040718174537572333\n",
            "Iteration: 9490000, Loss: 0.0004071810180783261\n",
            "Iteration: 9500000, Loss: 0.00040718029129029797\n",
            "Iteration: 9510000, Loss: 0.00040717956501124745\n",
            "Iteration: 9520000, Loss: 0.0004071788392407831\n",
            "Iteration: 9530000, Loss: 0.00040717811397851473\n",
            "Iteration: 9540000, Loss: 0.00040717738922405234\n",
            "Iteration: 9550000, Loss: 0.0004071766649770072\n",
            "Iteration: 9560000, Loss: 0.00040717594123699\n",
            "Iteration: 9570000, Loss: 0.00040717521800361496\n",
            "Iteration: 9580000, Loss: 0.0004071744952764939\n",
            "Iteration: 9590000, Loss: 0.0004071737730552412\n",
            "Iteration: 9600000, Loss: 0.0004071730513394712\n",
            "Iteration: 9610000, Loss: 0.00040717233012879976\n",
            "Iteration: 9620000, Loss: 0.0004071716094228424\n",
            "Iteration: 9630000, Loss: 0.0004071708892212167\n",
            "Iteration: 9640000, Loss: 0.0004071701695235399\n",
            "Iteration: 9650000, Loss: 0.00040716945032942846\n",
            "Iteration: 9660000, Loss: 0.00040716873163850327\n",
            "Iteration: 9670000, Loss: 0.0004071680134503822\n",
            "Iteration: 9680000, Loss: 0.00040716729576468645\n",
            "Iteration: 9690000, Loss: 0.0004071665785810359\n",
            "Iteration: 9700000, Loss: 0.0004071658618990525\n",
            "Iteration: 9710000, Loss: 0.0004071651457183582\n",
            "Iteration: 9720000, Loss: 0.00040716443003857464\n",
            "Iteration: 9730000, Loss: 0.00040716371485932635\n",
            "Iteration: 9740000, Loss: 0.00040716300018023743\n",
            "Iteration: 9750000, Loss: 0.0004071622860009312\n",
            "Iteration: 9760000, Loss: 0.0004071615723210337\n",
            "Iteration: 9770000, Loss: 0.00040716085914017014\n",
            "Iteration: 9780000, Loss: 0.00040716014645796755\n",
            "Iteration: 9790000, Loss: 0.0004071594342740522\n",
            "Iteration: 9800000, Loss: 0.00040715872258805197\n",
            "Iteration: 9810000, Loss: 0.00040715801139959407\n",
            "Iteration: 9820000, Loss: 0.00040715730070830863\n",
            "Iteration: 9830000, Loss: 0.00040715659051382376\n",
            "Iteration: 9840000, Loss: 0.0004071558808157702\n",
            "Iteration: 9850000, Loss: 0.0004071551716137775\n",
            "Iteration: 9860000, Loss: 0.00040715446290747685\n",
            "Iteration: 9870000, Loss: 0.00040715375469650055\n",
            "Iteration: 9880000, Loss: 0.0004071530469804793\n",
            "Iteration: 9890000, Loss: 0.00040715233975904683\n",
            "Iteration: 9900000, Loss: 0.00040715163303183574\n",
            "Iteration: 9910000, Loss: 0.00040715092679847987\n",
            "Iteration: 9920000, Loss: 0.00040715022105861337\n",
            "Iteration: 9930000, Loss: 0.00040714951581187096\n",
            "Iteration: 9940000, Loss: 0.0004071488110578881\n",
            "Iteration: 9950000, Loss: 0.00040714810679630045\n",
            "Iteration: 9960000, Loss: 0.0004071474030267442\n",
            "Iteration: 9970000, Loss: 0.0004071466997488562\n",
            "Iteration: 9980000, Loss: 0.0004071459969622737\n",
            "Iteration: 9990000, Loss: 0.000407145294666635\n",
            "Iteration: 10000000, Loss: 0.00040714459286157756\n",
            "Iteration: 10010000, Loss: 0.0004071438915467416\n",
            "Iteration: 10020000, Loss: 0.00040714319072176477\n",
            "Iteration: 10030000, Loss: 0.0004071424903862879\n",
            "Iteration: 10040000, Loss: 0.0004071417905399513\n",
            "Iteration: 10050000, Loss: 0.00040714109118239456\n",
            "Iteration: 10060000, Loss: 0.0004071403923132607\n",
            "Iteration: 10070000, Loss: 0.0004071396939321897\n",
            "Iteration: 10080000, Loss: 0.0004071389960388248\n",
            "Iteration: 10090000, Loss: 0.00040713829863280845\n",
            "Iteration: 10100000, Loss: 0.0004071376017137837\n",
            "Iteration: 10110000, Loss: 0.0004071369052813942\n",
            "Iteration: 10120000, Loss: 0.00040713620933528386\n",
            "Iteration: 10130000, Loss: 0.0004071355138750975\n",
            "Iteration: 10140000, Loss: 0.000407134818900479\n",
            "Iteration: 10150000, Loss: 0.00040713412441107483\n",
            "Iteration: 10160000, Loss: 0.00040713343040653036\n",
            "Iteration: 10170000, Loss: 0.00040713273688649187\n",
            "Iteration: 10180000, Loss: 0.0004071320438506061\n",
            "Iteration: 10190000, Loss: 0.0004071313512985208\n",
            "Iteration: 10200000, Loss: 0.00040713065922988196\n",
            "Iteration: 10210000, Loss: 0.0004071299676443381\n",
            "Iteration: 10220000, Loss: 0.00040712927654153853\n",
            "Iteration: 10230000, Loss: 0.0004071285859211319\n",
            "Iteration: 10240000, Loss: 0.0004071278957827671\n",
            "Iteration: 10250000, Loss: 0.0004071272061260932\n",
            "Iteration: 10260000, Loss: 0.00040712651695076134\n",
            "Iteration: 10270000, Loss: 0.0004071258282564216\n",
            "Iteration: 10280000, Loss: 0.0004071251400427247\n",
            "Iteration: 10290000, Loss: 0.00040712445230932235\n",
            "Iteration: 10300000, Loss: 0.0004071237650558652\n",
            "Iteration: 10310000, Loss: 0.00040712307828200687\n",
            "Iteration: 10320000, Loss: 0.00040712239198739865\n",
            "Iteration: 10330000, Loss: 0.0004071217061716949\n",
            "Iteration: 10340000, Loss: 0.00040712102083454696\n",
            "Iteration: 10350000, Loss: 0.00040712033597561025\n",
            "Iteration: 10360000, Loss: 0.00040711965159453793\n",
            "Iteration: 10370000, Loss: 0.00040711896769098435\n",
            "Iteration: 10380000, Loss: 0.00040711828426460484\n",
            "Iteration: 10390000, Loss: 0.0004071176013150545\n",
            "Iteration: 10400000, Loss: 0.00040711691884198824\n",
            "Iteration: 10410000, Loss: 0.0004071162368450642\n",
            "Iteration: 10420000, Loss: 0.000407115555323936\n",
            "Iteration: 10430000, Loss: 0.00040711487427826245\n",
            "Iteration: 10440000, Loss: 0.00040711419370769933\n",
            "Iteration: 10450000, Loss: 0.00040711351361190487\n",
            "Iteration: 10460000, Loss: 0.00040711283399053646\n",
            "Iteration: 10470000, Loss: 0.0004071121548432526\n",
            "Iteration: 10480000, Loss: 0.00040711147616971194\n",
            "Iteration: 10490000, Loss: 0.0004071107979695734\n",
            "Iteration: 10500000, Loss: 0.00040711012024249567\n",
            "Iteration: 10510000, Loss: 0.0004071094429881392\n",
            "Iteration: 10520000, Loss: 0.00040710876620616307\n",
            "Iteration: 10530000, Loss: 0.00040710808989622896\n",
            "Iteration: 10540000, Loss: 0.0004071074140579964\n",
            "Iteration: 10550000, Loss: 0.000407106738691127\n",
            "Iteration: 10560000, Loss: 0.00040710606379528217\n",
            "Iteration: 10570000, Loss: 0.00040710538937012365\n",
            "Iteration: 10580000, Loss: 0.0004071047154153127\n",
            "Iteration: 10590000, Loss: 0.0004071040419305131\n",
            "Iteration: 10600000, Loss: 0.0004071033689153868\n",
            "Iteration: 10610000, Loss: 0.000407102696369597\n",
            "Iteration: 10620000, Loss: 0.0004071020242928071\n",
            "Iteration: 10630000, Loss: 0.00040710135268468174\n",
            "Iteration: 10640000, Loss: 0.00040710068154488425\n",
            "Iteration: 10650000, Loss: 0.00040710001087307883\n",
            "Iteration: 10660000, Loss: 0.0004070993406689307\n",
            "Iteration: 10670000, Loss: 0.0004070986709321045\n",
            "Iteration: 10680000, Loss: 0.0004070980016622666\n",
            "Iteration: 10690000, Loss: 0.0004070973328590826\n",
            "Iteration: 10700000, Loss: 0.0004070966645222179\n",
            "Iteration: 10710000, Loss: 0.00040709599665133905\n",
            "Iteration: 10720000, Loss: 0.0004070953292461133\n",
            "Iteration: 10730000, Loss: 0.0004070946623062072\n",
            "Iteration: 10740000, Loss: 0.0004070939958312886\n",
            "Iteration: 10750000, Loss: 0.00040709332982102507\n",
            "Iteration: 10760000, Loss: 0.00040709266427508384\n",
            "Iteration: 10770000, Loss: 0.00040709199919313475\n",
            "Iteration: 10780000, Loss: 0.0004070913345748448\n",
            "Iteration: 10790000, Loss: 0.00040709067041988403\n",
            "Iteration: 10800000, Loss: 0.00040709000672792164\n",
            "Iteration: 10810000, Loss: 0.0004070893434986267\n",
            "Iteration: 10820000, Loss: 0.00040708868073166917\n",
            "Iteration: 10830000, Loss: 0.00040708801842671984\n",
            "Iteration: 10840000, Loss: 0.0004070873565834488\n",
            "Iteration: 10850000, Loss: 0.00040708669520152696\n",
            "Iteration: 10860000, Loss: 0.00040708603428062556\n",
            "Iteration: 10870000, Loss: 0.00040708537382041436\n",
            "Iteration: 10880000, Loss: 0.0004070847138205684\n",
            "Iteration: 10890000, Loss: 0.00040708405428075637\n",
            "Iteration: 10900000, Loss: 0.00040708339520065267\n",
            "Iteration: 10910000, Loss: 0.00040708273657992847\n",
            "Iteration: 10920000, Loss: 0.0004070820784182579\n",
            "Iteration: 10930000, Loss: 0.00040708142071531404\n",
            "Iteration: 10940000, Loss: 0.00040708076347076955\n",
            "Iteration: 10950000, Loss: 0.00040708010668429794\n",
            "Iteration: 10960000, Loss: 0.0004070794503555751\n",
            "Iteration: 10970000, Loss: 0.0004070787944842736\n",
            "Iteration: 10980000, Loss: 0.0004070781390700697\n",
            "Iteration: 10990000, Loss: 0.00040707748411263647\n",
            "Iteration: 11000000, Loss: 0.00040707682961165073\n",
            "Iteration: 11010000, Loss: 0.0004070761755667871\n",
            "Iteration: 11020000, Loss: 0.0004070755219777216\n",
            "Iteration: 11030000, Loss: 0.0004070748688441301\n",
            "Iteration: 11040000, Loss: 0.00040707421616569006\n",
            "Iteration: 11050000, Loss: 0.0004070735639420761\n",
            "Iteration: 11060000, Loss: 0.00040707291217296723\n",
            "Iteration: 11070000, Loss: 0.00040707226085803983\n",
            "Iteration: 11080000, Loss: 0.00040707160999697124\n",
            "Iteration: 11090000, Loss: 0.0004070709595894394\n",
            "Iteration: 11100000, Loss: 0.0004070703096351223\n",
            "Iteration: 11110000, Loss: 0.00040706966013369833\n",
            "Iteration: 11120000, Loss: 0.00040706901108484585\n",
            "Iteration: 11130000, Loss: 0.00040706836248824484\n",
            "Iteration: 11140000, Loss: 0.00040706771434357295\n",
            "Iteration: 11150000, Loss: 0.00040706706665051\n",
            "Iteration: 11160000, Loss: 0.00040706641940873635\n",
            "Iteration: 11170000, Loss: 0.0004070657726179318\n",
            "Iteration: 11180000, Loss: 0.00040706512627777634\n",
            "Iteration: 11190000, Loss: 0.0004070644803879502\n",
            "Iteration: 11200000, Loss: 0.00040706383494813503\n",
            "Iteration: 11210000, Loss: 0.00040706318995801074\n",
            "Iteration: 11220000, Loss: 0.00040706254541726027\n",
            "Iteration: 11230000, Loss: 0.0004070619013255638\n",
            "Iteration: 11240000, Loss: 0.00040706125768260346\n",
            "Iteration: 11250000, Loss: 0.00040706061448806145\n",
            "Iteration: 11260000, Loss: 0.00040705997174162085\n",
            "Iteration: 11270000, Loss: 0.00040705932944296345\n",
            "Iteration: 11280000, Loss: 0.0004070586875917726\n",
            "Iteration: 11290000, Loss: 0.0004070580461877307\n",
            "Iteration: 11300000, Loss: 0.00040705740523052275\n",
            "Iteration: 11310000, Loss: 0.0004070567647198318\n",
            "Iteration: 11320000, Loss: 0.0004070561246553411\n",
            "Iteration: 11330000, Loss: 0.00040705548503673574\n",
            "Iteration: 11340000, Loss: 0.0004070548458636992\n",
            "Iteration: 11350000, Loss: 0.00040705420713591753\n",
            "Iteration: 11360000, Loss: 0.00040705356885307483\n",
            "Iteration: 11370000, Loss: 0.00040705293101485715\n",
            "Iteration: 11380000, Loss: 0.00040705229362094855\n",
            "Iteration: 11390000, Loss: 0.00040705165667103625\n",
            "Iteration: 11400000, Loss: 0.0004070510201648062\n",
            "Iteration: 11410000, Loss: 0.00040705038410194475\n",
            "Iteration: 11420000, Loss: 0.0004070497484821365\n",
            "Iteration: 11430000, Loss: 0.0004070491133050707\n",
            "Iteration: 11440000, Loss: 0.0004070484785704334\n",
            "Iteration: 11450000, Loss: 0.00040704784427791175\n",
            "Iteration: 11460000, Loss: 0.0004070472104271941\n",
            "Iteration: 11470000, Loss: 0.00040704657701796714\n",
            "Iteration: 11480000, Loss: 0.00040704594404991954\n",
            "Iteration: 11490000, Loss: 0.0004070453115227398\n",
            "Iteration: 11500000, Loss: 0.0004070446794361159\n",
            "Iteration: 11510000, Loss: 0.0004070440477897372\n",
            "Iteration: 11520000, Loss: 0.00040704341658329276\n",
            "Iteration: 11530000, Loss: 0.00040704278581647085\n",
            "Iteration: 11540000, Loss: 0.00040704215548896256\n",
            "Iteration: 11550000, Loss: 0.000407041525600457\n",
            "Iteration: 11560000, Loss: 0.00040704089615064377\n",
            "Iteration: 11570000, Loss: 0.00040704026713921353\n",
            "Iteration: 11580000, Loss: 0.00040703963856585746\n",
            "Iteration: 11590000, Loss: 0.00040703901043026515\n",
            "Iteration: 11600000, Loss: 0.0004070383827321285\n",
            "Iteration: 11610000, Loss: 0.00040703775547113895\n",
            "Iteration: 11620000, Loss: 0.0004070371286469871\n",
            "Iteration: 11630000, Loss: 0.00040703650225936506\n",
            "Iteration: 11640000, Loss: 0.0004070358763079652\n",
            "Iteration: 11650000, Loss: 0.0004070352507924794\n",
            "Iteration: 11660000, Loss: 0.0004070346257126\n",
            "Iteration: 11670000, Loss: 0.00040703400106802015\n",
            "Iteration: 11680000, Loss: 0.00040703337685843324\n",
            "Iteration: 11690000, Loss: 0.00040703275308353134\n",
            "Iteration: 11700000, Loss: 0.00040703212974300853\n",
            "Iteration: 11710000, Loss: 0.00040703150683655826\n",
            "Iteration: 11720000, Loss: 0.0004070308843638751\n",
            "Iteration: 11730000, Loss: 0.0004070302623246522\n",
            "Iteration: 11740000, Loss: 0.0004070296407185848\n",
            "Iteration: 11750000, Loss: 0.00040702901954536657\n",
            "Iteration: 11760000, Loss: 0.0004070283988046937\n",
            "Iteration: 11770000, Loss: 0.0004070277784962602\n",
            "Iteration: 11780000, Loss: 0.00040702715861976204\n",
            "Iteration: 11790000, Loss: 0.00040702653917489435\n",
            "Iteration: 11800000, Loss: 0.00040702592016135346\n",
            "Iteration: 11810000, Loss: 0.0004070253015788352\n",
            "Iteration: 11820000, Loss: 0.00040702468342703504\n",
            "Iteration: 11830000, Loss: 0.0004070240657056514\n",
            "Iteration: 11840000, Loss: 0.0004070234484143791\n",
            "Iteration: 11850000, Loss: 0.00040702283155291615\n",
            "Iteration: 11860000, Loss: 0.00040702221512095934\n",
            "Iteration: 11870000, Loss: 0.00040702159911820636\n",
            "Iteration: 11880000, Loss: 0.00040702098354435475\n",
            "Iteration: 11890000, Loss: 0.00040702036839910247\n",
            "Iteration: 11900000, Loss: 0.00040701975368214816\n",
            "Iteration: 11910000, Loss: 0.00040701913939318916\n",
            "Iteration: 11920000, Loss: 0.0004070185255319246\n",
            "Iteration: 11930000, Loss: 0.0004070179120980538\n",
            "Iteration: 11940000, Loss: 0.0004070172990912751\n",
            "Iteration: 11950000, Loss: 0.00040701668651128777\n",
            "Iteration: 11960000, Loss: 0.00040701607435779245\n",
            "Iteration: 11970000, Loss: 0.00040701546263048697\n",
            "Iteration: 11980000, Loss: 0.00040701485132907335\n",
            "Iteration: 11990000, Loss: 0.00040701424045325055\n",
            "Iteration: 12000000, Loss: 0.00040701363000271863\n",
            "Iteration: 12010000, Loss: 0.0004070130199771793\n",
            "Iteration: 12020000, Loss: 0.00040701241037633307\n",
            "Iteration: 12030000, Loss: 0.0004070118011998818\n",
            "Iteration: 12040000, Loss: 0.0004070111924475251\n",
            "Iteration: 12050000, Loss: 0.0004070105841189659\n",
            "Iteration: 12060000, Loss: 0.00040700997621390535\n",
            "Iteration: 12070000, Loss: 0.0004070093687320458\n",
            "Iteration: 12080000, Loss: 0.00040700876167308944\n",
            "Iteration: 12090000, Loss: 0.0004070081550367386\n",
            "Iteration: 12100000, Loss: 0.000407007548822696\n",
            "Iteration: 12110000, Loss: 0.00040700694303066485\n",
            "Iteration: 12120000, Loss: 0.00040700633766034794\n",
            "Iteration: 12130000, Loss: 0.0004070057327114484\n",
            "Iteration: 12140000, Loss: 0.0004070051281836704\n",
            "Iteration: 12150000, Loss: 0.00040700452407671733\n",
            "Iteration: 12160000, Loss: 0.0004070039203902932\n",
            "Iteration: 12170000, Loss: 0.000407003317124103\n",
            "Iteration: 12180000, Loss: 0.00040700271427785025\n",
            "Iteration: 12190000, Loss: 0.00040700211185124013\n",
            "Iteration: 12200000, Loss: 0.00040700150984397725\n",
            "Iteration: 12210000, Loss: 0.00040700090825576685\n",
            "Iteration: 12220000, Loss: 0.00040700030708631436\n",
            "Iteration: 12230000, Loss: 0.0004069997063353248\n",
            "Iteration: 12240000, Loss: 0.0004069991060025055\n",
            "Iteration: 12250000, Loss: 0.00040699850608756063\n",
            "Iteration: 12260000, Loss: 0.00040699790659019753\n",
            "Iteration: 12270000, Loss: 0.00040699730751012243\n",
            "Iteration: 12280000, Loss: 0.00040699670884704174\n",
            "Iteration: 12290000, Loss: 0.00040699611060066254\n",
            "Iteration: 12300000, Loss: 0.00040699551277069223\n",
            "Iteration: 12310000, Loss: 0.0004069949153568373\n",
            "Iteration: 12320000, Loss: 0.00040699431835880637\n",
            "Iteration: 12330000, Loss: 0.0004069937217763058\n",
            "Iteration: 12340000, Loss: 0.00040699312560904495\n",
            "Iteration: 12350000, Loss: 0.00040699252985673147\n",
            "Iteration: 12360000, Loss: 0.0004069919345190732\n",
            "Iteration: 12370000, Loss: 0.0004069913395957796\n",
            "Iteration: 12380000, Loss: 0.0004069907450865593\n",
            "Iteration: 12390000, Loss: 0.00040699015099112095\n",
            "Iteration: 12400000, Loss: 0.00040698955730917447\n",
            "Iteration: 12410000, Loss: 0.0004069889640404284\n",
            "Iteration: 12420000, Loss: 0.00040698837118459375\n",
            "Iteration: 12430000, Loss: 0.0004069877787413792\n",
            "Iteration: 12440000, Loss: 0.0004069871867104955\n",
            "Iteration: 12450000, Loss: 0.0004069865950916524\n",
            "Iteration: 12460000, Loss: 0.0004069860038845612\n",
            "Iteration: 12470000, Loss: 0.0004069854130889322\n",
            "Iteration: 12480000, Loss: 0.000406984822704477\n",
            "Iteration: 12490000, Loss: 0.0004069842327309061\n",
            "Iteration: 12500000, Loss: 0.00040698364316793094\n",
            "Iteration: 12510000, Loss: 0.0004069830540152632\n",
            "Iteration: 12520000, Loss: 0.0004069824652726149\n",
            "Iteration: 12530000, Loss: 0.0004069818769396982\n",
            "Iteration: 12540000, Loss: 0.0004069812890162249\n",
            "Iteration: 12550000, Loss: 0.0004069807015019077\n",
            "Iteration: 12560000, Loss: 0.00040698011439645946\n",
            "Iteration: 12570000, Loss: 0.00040697952769959303\n",
            "Iteration: 12580000, Loss: 0.0004069789414110211\n",
            "Iteration: 12590000, Loss: 0.0004069783555304573\n",
            "Iteration: 12600000, Loss: 0.0004069777700576152\n",
            "Iteration: 12610000, Loss: 0.000406977184992208\n",
            "Iteration: 12620000, Loss: 0.0004069766003339505\n",
            "Iteration: 12630000, Loss: 0.00040697601608255583\n",
            "Iteration: 12640000, Loss: 0.0004069754322377398\n",
            "Iteration: 12650000, Loss: 0.00040697484879921537\n",
            "Iteration: 12660000, Loss: 0.0004069742657666978\n",
            "Iteration: 12670000, Loss: 0.0004069736831399029\n",
            "Iteration: 12680000, Loss: 0.00040697310091854493\n",
            "Iteration: 12690000, Loss: 0.0004069725191023397\n",
            "Iteration: 12700000, Loss: 0.0004069719376910026\n",
            "Iteration: 12710000, Loss: 0.0004069713566842497\n",
            "Iteration: 12720000, Loss: 0.00040697077608179663\n",
            "Iteration: 12730000, Loss: 0.0004069701958833597\n",
            "Iteration: 12740000, Loss: 0.0004069696160886563\n",
            "Iteration: 12750000, Loss: 0.0004069690366974017\n",
            "Iteration: 12760000, Loss: 0.0004069684577093136\n",
            "Iteration: 12770000, Loss: 0.0004069678791241087\n",
            "Iteration: 12780000, Loss: 0.00040696730094150424\n",
            "Iteration: 12790000, Loss: 0.0004069667231612176\n",
            "Iteration: 12800000, Loss: 0.00040696614578296673\n",
            "Iteration: 12810000, Loss: 0.00040696556880647004\n",
            "Iteration: 12820000, Loss: 0.0004069649922314446\n",
            "Iteration: 12830000, Loss: 0.00040696441605760867\n",
            "Iteration: 12840000, Loss: 0.0004069638402846818\n",
            "Iteration: 12850000, Loss: 0.0004069632649123817\n",
            "Iteration: 12860000, Loss: 0.0004069626899404279\n",
            "Iteration: 12870000, Loss: 0.00040696211536853897\n",
            "Iteration: 12880000, Loss: 0.00040696154119643446\n",
            "Iteration: 12890000, Loss: 0.0004069609674238342\n",
            "Iteration: 12900000, Loss: 0.00040696039405045746\n",
            "Iteration: 12910000, Loss: 0.00040695982107602464\n",
            "Iteration: 12920000, Loss: 0.00040695924850025513\n",
            "Iteration: 12930000, Loss: 0.0004069586763228696\n",
            "Iteration: 12940000, Loss: 0.0004069581045435895\n",
            "Iteration: 12950000, Loss: 0.0004069575331621335\n",
            "Iteration: 12960000, Loss: 0.0004069569621782246\n",
            "Iteration: 12970000, Loss: 0.00040695639159158277\n",
            "Iteration: 12980000, Loss: 0.0004069558214019302\n",
            "Iteration: 12990000, Loss: 0.0004069552516089875\n",
            "Iteration: 13000000, Loss: 0.00040695468221247695\n",
            "Iteration: 13010000, Loss: 0.00040695411321212084\n",
            "Iteration: 13020000, Loss: 0.00040695354460764044\n",
            "Iteration: 13030000, Loss: 0.0004069529763987585\n",
            "Iteration: 13040000, Loss: 0.00040695240858519777\n",
            "Iteration: 13050000, Loss: 0.00040695184116668065\n",
            "Iteration: 13060000, Loss: 0.00040695127414293043\n",
            "Iteration: 13070000, Loss: 0.0004069507075136699\n",
            "Iteration: 13080000, Loss: 0.0004069501412786225\n",
            "Iteration: 13090000, Loss: 0.00040694957543751224\n",
            "Iteration: 13100000, Loss: 0.00040694900999006296\n",
            "Iteration: 13110000, Loss: 0.00040694844493599746\n",
            "Iteration: 13120000, Loss: 0.00040694788027504134\n",
            "Iteration: 13130000, Loss: 0.0004069473160069176\n",
            "Iteration: 13140000, Loss: 0.0004069467521313516\n",
            "Iteration: 13150000, Loss: 0.0004069461886480678\n",
            "Iteration: 13160000, Loss: 0.0004069456255567919\n",
            "Iteration: 13170000, Loss: 0.00040694506285724813\n",
            "Iteration: 13180000, Loss: 0.00040694450054916186\n",
            "Iteration: 13190000, Loss: 0.0004069439386322591\n",
            "Iteration: 13200000, Loss: 0.0004069433771062653\n",
            "Iteration: 13210000, Loss: 0.00040694281597090655\n",
            "Iteration: 13220000, Loss: 0.0004069422552259087\n",
            "Iteration: 13230000, Loss: 0.0004069416948709987\n",
            "Iteration: 13240000, Loss: 0.0004069411349059028\n",
            "Iteration: 13250000, Loss: 0.0004069405753303472\n",
            "Iteration: 13260000, Loss: 0.00040694001614405983\n",
            "Iteration: 13270000, Loss: 0.0004069394573467668\n",
            "Iteration: 13280000, Loss: 0.0004069388989381961\n",
            "Iteration: 13290000, Loss: 0.0004069383409180751\n",
            "Iteration: 13300000, Loss: 0.00040693778328613106\n",
            "Iteration: 13310000, Loss: 0.00040693722604209255\n",
            "Iteration: 13320000, Loss: 0.0004069366691856872\n",
            "Iteration: 13330000, Loss: 0.000406936112716644\n",
            "Iteration: 13340000, Loss: 0.00040693555663469047\n",
            "Iteration: 13350000, Loss: 0.00040693500093955565\n",
            "Iteration: 13360000, Loss: 0.00040693444563096916\n",
            "Iteration: 13370000, Loss: 0.00040693389070865885\n",
            "Iteration: 13380000, Loss: 0.0004069333361723554\n",
            "Iteration: 13390000, Loss: 0.00040693278202178694\n",
            "Iteration: 13400000, Loss: 0.0004069322282566836\n",
            "Iteration: 13410000, Loss: 0.0004069316748767755\n",
            "Iteration: 13420000, Loss: 0.0004069311218817928\n",
            "Iteration: 13430000, Loss: 0.00040693056927146537\n",
            "Iteration: 13440000, Loss: 0.00040693001704552386\n",
            "Iteration: 13450000, Loss: 0.00040692946520369885\n",
            "Iteration: 13460000, Loss: 0.00040692891374572067\n",
            "Iteration: 13470000, Loss: 0.00040692836267132145\n",
            "Iteration: 13480000, Loss: 0.00040692781198023155\n",
            "Iteration: 13490000, Loss: 0.0004069272616721827\n",
            "Iteration: 13500000, Loss: 0.00040692671174690653\n",
            "Iteration: 13510000, Loss: 0.00040692616220413424\n",
            "Iteration: 13520000, Loss: 0.0004069256130435986\n",
            "Iteration: 13530000, Loss: 0.0004069250642650318\n",
            "Iteration: 13540000, Loss: 0.0004069245158681654\n",
            "Iteration: 13550000, Loss: 0.000406923967852733\n",
            "Iteration: 13560000, Loss: 0.00040692342021846593\n",
            "Iteration: 13570000, Loss: 0.00040692287296509896\n",
            "Iteration: 13580000, Loss: 0.00040692232609236437\n",
            "Iteration: 13590000, Loss: 0.0004069217795999948\n",
            "Iteration: 13600000, Loss: 0.0004069212334877247\n",
            "Iteration: 13610000, Loss: 0.0004069206877552875\n",
            "Iteration: 13620000, Loss: 0.00040692014240241724\n",
            "Iteration: 13630000, Loss: 0.00040691959742884766\n",
            "Iteration: 13640000, Loss: 0.0004069190528343134\n",
            "Iteration: 13650000, Loss: 0.00040691850861854874\n",
            "Iteration: 13660000, Loss: 0.00040691796478128884\n",
            "Iteration: 13670000, Loss: 0.0004069174213222673\n",
            "Iteration: 13680000, Loss: 0.0004069168782412205\n",
            "Iteration: 13690000, Loss: 0.0004069163355378834\n",
            "Iteration: 13700000, Loss: 0.00040691579321199076\n",
            "Iteration: 13710000, Loss: 0.0004069152512632792\n",
            "Iteration: 13720000, Loss: 0.0004069147096914833\n",
            "Iteration: 13730000, Loss: 0.00040691416849634055\n",
            "Iteration: 13740000, Loss: 0.00040691362767758565\n",
            "Iteration: 13750000, Loss: 0.0004069130872349555\n",
            "Iteration: 13760000, Loss: 0.00040691254716818706\n",
            "Iteration: 13770000, Loss: 0.0004069120074770174\n",
            "Iteration: 13780000, Loss: 0.0004069114681611821\n",
            "Iteration: 13790000, Loss: 0.0004069109292204196\n",
            "Iteration: 13800000, Loss: 0.00040691039065446653\n",
            "Iteration: 13810000, Loss: 0.0004069098524630609\n",
            "Iteration: 13820000, Loss: 0.0004069093146459392\n",
            "Iteration: 13830000, Loss: 0.00040690877720284086\n",
            "Iteration: 13840000, Loss: 0.00040690824013350275\n",
            "Iteration: 13850000, Loss: 0.00040690770343766416\n",
            "Iteration: 13860000, Loss: 0.0004069071671150626\n",
            "Iteration: 13870000, Loss: 0.0004069066311654377\n",
            "Iteration: 13880000, Loss: 0.00040690609558852723\n",
            "Iteration: 13890000, Loss: 0.00040690556038407096\n",
            "Iteration: 13900000, Loss: 0.00040690502555180773\n",
            "Iteration: 13910000, Loss: 0.00040690449109147633\n",
            "Iteration: 13920000, Loss: 0.0004069039570028178\n",
            "Iteration: 13930000, Loss: 0.00040690342328557084\n",
            "Iteration: 13940000, Loss: 0.00040690288993947514\n",
            "Iteration: 13950000, Loss: 0.0004069023569642714\n",
            "Iteration: 13960000, Loss: 0.0004069018243597006\n",
            "Iteration: 13970000, Loss: 0.000406901292125502\n",
            "Iteration: 13980000, Loss: 0.00040690076026141635\n",
            "Iteration: 13990000, Loss: 0.000406900228767185\n",
            "Iteration: 14000000, Loss: 0.0004068996976425492\n",
            "Iteration: 14010000, Loss: 0.0004068991668872496\n",
            "Iteration: 14020000, Loss: 0.000406898636501028\n",
            "Iteration: 14030000, Loss: 0.000406898106483626\n",
            "Iteration: 14040000, Loss: 0.0004068975768347846\n",
            "Iteration: 14050000, Loss: 0.00040689704755424687\n",
            "Iteration: 14060000, Loss: 0.00040689651864175494\n",
            "Iteration: 14070000, Loss: 0.0004068959900970503\n",
            "Iteration: 14080000, Loss: 0.0004068954619198764\n",
            "Iteration: 14090000, Loss: 0.0004068949341099746\n",
            "Iteration: 14100000, Loss: 0.00040689440666708974\n",
            "Iteration: 14110000, Loss: 0.0004068938795909628\n",
            "Iteration: 14120000, Loss: 0.0004068933528813392\n",
            "Iteration: 14130000, Loss: 0.00040689282653796053\n",
            "Iteration: 14140000, Loss: 0.0004068923005605709\n",
            "Iteration: 14150000, Loss: 0.0004068917749489153\n",
            "Iteration: 14160000, Loss: 0.0004068912497027359\n",
            "Iteration: 14170000, Loss: 0.0004068907248217779\n",
            "Iteration: 14180000, Loss: 0.00040689020030578577\n",
            "Iteration: 14190000, Loss: 0.00040688967615450355\n",
            "Iteration: 14200000, Loss: 0.0004068891523676765\n",
            "Iteration: 14210000, Loss: 0.0004068886289450494\n",
            "Iteration: 14220000, Loss: 0.00040688810588636624\n",
            "Iteration: 14230000, Loss: 0.00040688758319137397\n",
            "Iteration: 14240000, Loss: 0.00040688706085981673\n",
            "Iteration: 14250000, Loss: 0.00040688653889144196\n",
            "Iteration: 14260000, Loss: 0.0004068860172859927\n",
            "Iteration: 14270000, Loss: 0.0004068854960432175\n",
            "Iteration: 14280000, Loss: 0.00040688497516286104\n",
            "Iteration: 14290000, Loss: 0.0004068844546446702\n",
            "Iteration: 14300000, Loss: 0.00040688393448839143\n",
            "Iteration: 14310000, Loss: 0.00040688341469377154\n",
            "Iteration: 14320000, Loss: 0.00040688289526055765\n",
            "Iteration: 14330000, Loss: 0.00040688237618849616\n",
            "Iteration: 14340000, Loss: 0.0004068818574773345\n",
            "Iteration: 14350000, Loss: 0.0004068813391268206\n",
            "Iteration: 14360000, Loss: 0.00040688082113670175\n",
            "Iteration: 14370000, Loss: 0.0004068803035067258\n",
            "Iteration: 14380000, Loss: 0.0004068797862366408\n",
            "Iteration: 14390000, Loss: 0.00040687926932619483\n",
            "Iteration: 14400000, Loss: 0.0004068787527751363\n",
            "Iteration: 14410000, Loss: 0.000406878236583214\n",
            "Iteration: 14420000, Loss: 0.000406877720750176\n",
            "Iteration: 14430000, Loss: 0.000406877205275771\n",
            "Iteration: 14440000, Loss: 0.000406876690159749\n",
            "Iteration: 14450000, Loss: 0.00040687617540185864\n",
            "Iteration: 14460000, Loss: 0.0004068756610018496\n",
            "Iteration: 14470000, Loss: 0.0004068751469594709\n",
            "Iteration: 14480000, Loss: 0.00040687463327447317\n",
            "Iteration: 14490000, Loss: 0.0004068741199466059\n",
            "Iteration: 14500000, Loss: 0.00040687360697561916\n",
            "Iteration: 14510000, Loss: 0.0004068730943612633\n",
            "Iteration: 14520000, Loss: 0.0004068725821032888\n",
            "Iteration: 14530000, Loss: 0.0004068720702014462\n",
            "Iteration: 14540000, Loss: 0.0004068715586554865\n",
            "Iteration: 14550000, Loss: 0.000406871047465161\n",
            "Iteration: 14560000, Loss: 0.0004068705366302204\n",
            "Iteration: 14570000, Loss: 0.0004068700261504162\n",
            "Iteration: 14580000, Loss: 0.00040686951602549986\n",
            "Iteration: 14590000, Loss: 0.000406869006255224\n",
            "Iteration: 14600000, Loss: 0.0004068684968393389\n",
            "Iteration: 14610000, Loss: 0.0004068679877775977\n",
            "Iteration: 14620000, Loss: 0.0004068674790697528\n",
            "Iteration: 14630000, Loss: 0.0004068669707155558\n",
            "Iteration: 14640000, Loss: 0.00040686646271476015\n",
            "Iteration: 14650000, Loss: 0.00040686595506711823\n",
            "Iteration: 14660000, Loss: 0.00040686544777238245\n",
            "Iteration: 14670000, Loss: 0.0004068649408303074\n",
            "Iteration: 14680000, Loss: 0.0004068644342406453\n",
            "Iteration: 14690000, Loss: 0.00040686392800314973\n",
            "Iteration: 14700000, Loss: 0.0004068634221175742\n",
            "Iteration: 14710000, Loss: 0.00040686291658367324\n",
            "Iteration: 14720000, Loss: 0.0004068624114011999\n",
            "Iteration: 14730000, Loss: 0.0004068619065699095\n",
            "Iteration: 14740000, Loss: 0.00040686140208955534\n",
            "Iteration: 14750000, Loss: 0.0004068608979598925\n",
            "Iteration: 14760000, Loss: 0.00040686039418067523\n",
            "Iteration: 14770000, Loss: 0.0004068598907516595\n",
            "Iteration: 14780000, Loss: 0.0004068593876725994\n",
            "Iteration: 14790000, Loss: 0.00040685888494325026\n",
            "Iteration: 14800000, Loss: 0.00040685838256336777\n",
            "Iteration: 14810000, Loss: 0.0004068578805327069\n",
            "Iteration: 14820000, Loss: 0.0004068573788510243\n",
            "Iteration: 14830000, Loss: 0.0004068568775180753\n",
            "Iteration: 14840000, Loss: 0.00040685637653361633\n",
            "Iteration: 14850000, Loss: 0.00040685587589740394\n",
            "Iteration: 14860000, Loss: 0.00040685537560919324\n",
            "Iteration: 14870000, Loss: 0.0004068548756687423\n",
            "Iteration: 14880000, Loss: 0.0004068543760758072\n",
            "Iteration: 14890000, Loss: 0.0004068538768301455\n",
            "Iteration: 14900000, Loss: 0.00040685337793151333\n",
            "Iteration: 14910000, Loss: 0.00040685287937966867\n",
            "Iteration: 14920000, Loss: 0.00040685238117436917\n",
            "Iteration: 14930000, Loss: 0.0004068518833153717\n",
            "Iteration: 14940000, Loss: 0.0004068513858024352\n",
            "Iteration: 14950000, Loss: 0.0004068508886353168\n",
            "Iteration: 14960000, Loss: 0.00040685039181377565\n",
            "Iteration: 14970000, Loss: 0.0004068498953375686\n",
            "Iteration: 14980000, Loss: 0.00040684939920645504\n",
            "Iteration: 14990000, Loss: 0.00040684890342019365\n",
            "Iteration: 15000000, Loss: 0.00040684840797854376\n",
            "Iteration: 15010000, Loss: 0.00040684791288126326\n",
            "Iteration: 15020000, Loss: 0.0004068474181281123\n",
            "Iteration: 15030000, Loss: 0.0004068469237188499\n",
            "Iteration: 15040000, Loss: 0.0004068464296532352\n",
            "Iteration: 15050000, Loss: 0.00040684593593102883\n",
            "Iteration: 15060000, Loss: 0.00040684544255198987\n",
            "Iteration: 15070000, Loss: 0.0004068449495158793\n",
            "Iteration: 15080000, Loss: 0.00040684445682245655\n",
            "Iteration: 15090000, Loss: 0.00040684396447148195\n",
            "Iteration: 15100000, Loss: 0.00040684347246271554\n",
            "Iteration: 15110000, Loss: 0.00040684298079592015\n",
            "Iteration: 15120000, Loss: 0.0004068424894708551\n",
            "Iteration: 15130000, Loss: 0.00040684199848728137\n",
            "Iteration: 15140000, Loss: 0.00040684150784496103\n",
            "Iteration: 15150000, Loss: 0.00040684101754365497\n",
            "Iteration: 15160000, Loss: 0.0004068405275831245\n",
            "Iteration: 15170000, Loss: 0.000406840037963132\n",
            "Iteration: 15180000, Loss: 0.0004068395486834389\n",
            "Iteration: 15190000, Loss: 0.00040683905974380776\n",
            "Iteration: 15200000, Loss: 0.00040683857114400066\n",
            "Iteration: 15210000, Loss: 0.0004068380828837798\n",
            "Iteration: 15220000, Loss: 0.0004068375949629082\n",
            "Iteration: 15230000, Loss: 0.00040683710738114825\n",
            "Iteration: 15240000, Loss: 0.00040683662013826327\n",
            "Iteration: 15250000, Loss: 0.00040683613323401545\n",
            "Iteration: 15260000, Loss: 0.0004068356466681693\n",
            "Iteration: 15270000, Loss: 0.0004068351604404877\n",
            "Iteration: 15280000, Loss: 0.00040683467455073375\n",
            "Iteration: 15290000, Loss: 0.00040683418899867203\n",
            "Iteration: 15300000, Loss: 0.00040683370378406656\n",
            "Iteration: 15310000, Loss: 0.00040683321890668087\n",
            "Iteration: 15320000, Loss: 0.0004068327343662789\n",
            "Iteration: 15330000, Loss: 0.0004068322501626261\n",
            "Iteration: 15340000, Loss: 0.0004068317662954866\n",
            "Iteration: 15350000, Loss: 0.0004068312827646256\n",
            "Iteration: 15360000, Loss: 0.0004068307995698073\n",
            "Iteration: 15370000, Loss: 0.0004068303167107972\n",
            "Iteration: 15380000, Loss: 0.0004068298341873603\n",
            "Iteration: 15390000, Loss: 0.0004068293519992628\n",
            "Iteration: 15400000, Loss: 0.00040682887014626947\n",
            "Iteration: 15410000, Loss: 0.00040682838862814673\n",
            "Iteration: 15420000, Loss: 0.0004068279074446593\n",
            "Iteration: 15430000, Loss: 0.00040682742659557534\n",
            "Iteration: 15440000, Loss: 0.0004068269460806596\n",
            "Iteration: 15450000, Loss: 0.0004068264658996794\n",
            "Iteration: 15460000, Loss: 0.00040682598605240003\n",
            "Iteration: 15470000, Loss: 0.00040682550653859024\n",
            "Iteration: 15480000, Loss: 0.00040682502735801465\n",
            "Iteration: 15490000, Loss: 0.0004068245485104424\n",
            "Iteration: 15500000, Loss: 0.00040682406999564006\n",
            "Iteration: 15510000, Loss: 0.00040682359181337446\n",
            "Iteration: 15520000, Loss: 0.00040682311396341374\n",
            "Iteration: 15530000, Loss: 0.0004068226364455254\n",
            "Iteration: 15540000, Loss: 0.00040682215925947837\n",
            "Iteration: 15550000, Loss: 0.0004068216824050396\n",
            "Iteration: 15560000, Loss: 0.00040682120588197783\n",
            "Iteration: 15570000, Loss: 0.000406820729690061\n",
            "Iteration: 15580000, Loss: 0.00040682025382905837\n",
            "Iteration: 15590000, Loss: 0.00040681977829873866\n",
            "Iteration: 15600000, Loss: 0.0004068193030988698\n",
            "Iteration: 15610000, Loss: 0.00040681882822922216\n",
            "Iteration: 15620000, Loss: 0.00040681835368956384\n",
            "Iteration: 15630000, Loss: 0.0004068178794796656\n",
            "Iteration: 15640000, Loss: 0.00040681740559929614\n",
            "Iteration: 15650000, Loss: 0.00040681693204822506\n",
            "Iteration: 15660000, Loss: 0.00040681645882622257\n",
            "Iteration: 15670000, Loss: 0.0004068159859330587\n",
            "Iteration: 15680000, Loss: 0.00040681551336850335\n",
            "Iteration: 15690000, Loss: 0.000406815041132327\n",
            "Iteration: 15700000, Loss: 0.0004068145692243013\n",
            "Iteration: 15710000, Loss: 0.0004068140976441958\n",
            "Iteration: 15720000, Loss: 0.00040681362639178123\n",
            "Iteration: 15730000, Loss: 0.000406813155466829\n",
            "Iteration: 15740000, Loss: 0.0004068126848691107\n",
            "Iteration: 15750000, Loss: 0.0004068122145983971\n",
            "Iteration: 15760000, Loss: 0.0004068117446544601\n",
            "Iteration: 15770000, Loss: 0.0004068112750370717\n",
            "Iteration: 15780000, Loss: 0.00040681080574600254\n",
            "Iteration: 15790000, Loss: 0.0004068103367810258\n",
            "Iteration: 15800000, Loss: 0.0004068098681419129\n",
            "Iteration: 15810000, Loss: 0.00040680939982843707\n",
            "Iteration: 15820000, Loss: 0.00040680893184036966\n",
            "Iteration: 15830000, Loss: 0.00040680846417748447\n",
            "Iteration: 15840000, Loss: 0.00040680799683955325\n",
            "Iteration: 15850000, Loss: 0.0004068075298263503\n",
            "Iteration: 15860000, Loss: 0.00040680706313764704\n",
            "Iteration: 15870000, Loss: 0.0004068065967732181\n",
            "Iteration: 15880000, Loss: 0.00040680613073283646\n",
            "Iteration: 15890000, Loss: 0.00040680566501627555\n",
            "Iteration: 15900000, Loss: 0.0004068051996233096\n",
            "Iteration: 15910000, Loss: 0.00040680473455371254\n",
            "Iteration: 15920000, Loss: 0.0004068042698072583\n",
            "Iteration: 15930000, Loss: 0.000406803805383721\n",
            "Iteration: 15940000, Loss: 0.00040680334128287513\n",
            "Iteration: 15950000, Loss: 0.0004068028775044955\n",
            "Iteration: 15960000, Loss: 0.00040680241404835604\n",
            "Iteration: 15970000, Loss: 0.00040680195091423297\n",
            "Iteration: 15980000, Loss: 0.0004068014881019007\n",
            "Iteration: 15990000, Loss: 0.0004068010256111339\n",
            "Iteration: 16000000, Loss: 0.0004068005634417091\n",
            "Iteration: 16010000, Loss: 0.0004068001015934009\n",
            "Iteration: 16020000, Loss: 0.0004067996400659853\n",
            "Iteration: 16030000, Loss: 0.0004067991788592385\n",
            "Iteration: 16040000, Loss: 0.00040679871797293576\n",
            "Iteration: 16050000, Loss: 0.0004067982574068535\n",
            "Iteration: 16060000, Loss: 0.0004067977971607684\n",
            "Iteration: 16070000, Loss: 0.0004067973372344571\n",
            "Iteration: 16080000, Loss: 0.000406796877627696\n",
            "Iteration: 16090000, Loss: 0.0004067964183402612\n",
            "Iteration: 16100000, Loss: 0.0004067959593719304\n",
            "Iteration: 16110000, Loss: 0.0004067955007224809\n",
            "Iteration: 16120000, Loss: 0.00040679504239169004\n",
            "Iteration: 16130000, Loss: 0.0004067945843793339\n",
            "Iteration: 16140000, Loss: 0.0004067941266851915\n",
            "Iteration: 16150000, Loss: 0.00040679366930904056\n",
            "Iteration: 16160000, Loss: 0.00040679321225065864\n",
            "Iteration: 16170000, Loss: 0.0004067927555098233\n",
            "Iteration: 16180000, Loss: 0.0004067922990863131\n",
            "Iteration: 16190000, Loss: 0.0004067918429799073\n",
            "Iteration: 16200000, Loss: 0.00040679138719038337\n",
            "Iteration: 16210000, Loss: 0.0004067909317175203\n",
            "Iteration: 16220000, Loss: 0.0004067904765610966\n",
            "Iteration: 16230000, Loss: 0.000406790021720892\n",
            "Iteration: 16240000, Loss: 0.00040678956719668514\n",
            "Iteration: 16250000, Loss: 0.0004067891129882561\n",
            "Iteration: 16260000, Loss: 0.00040678865909538314\n",
            "Iteration: 16270000, Loss: 0.000406788205517847\n",
            "Iteration: 16280000, Loss: 0.0004067877522554262\n",
            "Iteration: 16290000, Loss: 0.0004067872993079023\n",
            "Iteration: 16300000, Loss: 0.00040678684667505387\n",
            "Iteration: 16310000, Loss: 0.0004067863943566627\n",
            "Iteration: 16320000, Loss: 0.0004067859423525078\n",
            "Iteration: 16330000, Loss: 0.0004067854906623704\n",
            "Iteration: 16340000, Loss: 0.0004067850392860314\n",
            "Iteration: 16350000, Loss: 0.00040678458822327135\n",
            "Iteration: 16360000, Loss: 0.00040678413747387125\n",
            "Iteration: 16370000, Loss: 0.00040678368703761216\n",
            "Iteration: 16380000, Loss: 0.000406783236914276\n",
            "Iteration: 16390000, Loss: 0.00040678278710364383\n",
            "Iteration: 16400000, Loss: 0.00040678233760549755\n",
            "Iteration: 16410000, Loss: 0.0004067818884196183\n",
            "Iteration: 16420000, Loss: 0.00040678143954578865\n",
            "Iteration: 16430000, Loss: 0.0004067809909837909\n",
            "Iteration: 16440000, Loss: 0.0004067805427334073\n",
            "Iteration: 16450000, Loss: 0.00040678009479441963\n",
            "Iteration: 16460000, Loss: 0.00040677964716661106\n",
            "Iteration: 16470000, Loss: 0.0004067791998497635\n",
            "Iteration: 16480000, Loss: 0.00040677875284366095\n",
            "Iteration: 16490000, Loss: 0.0004067783061480862\n",
            "Iteration: 16500000, Loss: 0.00040677785976282136\n",
            "Iteration: 16510000, Loss: 0.0004067774136876513\n",
            "Iteration: 16520000, Loss: 0.00040677696792235877\n",
            "Iteration: 16530000, Loss: 0.00040677652246672713\n",
            "Iteration: 16540000, Loss: 0.000406776077320541\n",
            "Iteration: 16550000, Loss: 0.0004067756324835831\n",
            "Iteration: 16560000, Loss: 0.0004067751879556389\n",
            "Iteration: 16570000, Loss: 0.00040677474373649144\n",
            "Iteration: 16580000, Loss: 0.00040677429982592704\n",
            "Iteration: 16590000, Loss: 0.00040677385622372785\n",
            "Iteration: 16600000, Loss: 0.0004067734129296798\n",
            "Iteration: 16610000, Loss: 0.0004067729699435677\n",
            "Iteration: 16620000, Loss: 0.00040677252726517625\n",
            "Iteration: 16630000, Loss: 0.0004067720848942918\n",
            "Iteration: 16640000, Loss: 0.0004067716428306985\n",
            "Iteration: 16650000, Loss: 0.00040677120107418204\n",
            "Iteration: 16660000, Loss: 0.0004067707596245281\n",
            "Iteration: 16670000, Loss: 0.0004067703184815229\n",
            "Iteration: 16680000, Loss: 0.0004067698776449517\n",
            "Iteration: 16690000, Loss: 0.00040676943711460094\n",
            "Iteration: 16700000, Loss: 0.00040676899689025676\n",
            "Iteration: 16710000, Loss: 0.0004067685569717056\n",
            "Iteration: 16720000, Loss: 0.00040676811735873396\n",
            "Iteration: 16730000, Loss: 0.0004067676780511282\n",
            "Iteration: 16740000, Loss: 0.0004067672390486758\n",
            "Iteration: 16750000, Loss: 0.0004067668003511639\n",
            "Iteration: 16760000, Loss: 0.0004067663619583789\n",
            "Iteration: 16770000, Loss: 0.0004067659238701081\n",
            "Iteration: 16780000, Loss: 0.0004067654860861396\n",
            "Iteration: 16790000, Loss: 0.00040676504860626047\n",
            "Iteration: 16800000, Loss: 0.00040676461143025896\n",
            "Iteration: 16810000, Loss: 0.0004067641745579224\n",
            "Iteration: 16820000, Loss: 0.0004067637379890392\n",
            "Iteration: 16830000, Loss: 0.0004067633017233969\n",
            "Iteration: 16840000, Loss: 0.00040676286576078513\n",
            "Iteration: 16850000, Loss: 0.000406762430100991\n",
            "Iteration: 16860000, Loss: 0.0004067619947438041\n",
            "Iteration: 16870000, Loss: 0.000406761559689013\n",
            "Iteration: 16880000, Loss: 0.0004067611249364065\n",
            "Iteration: 16890000, Loss: 0.000406760690485773\n",
            "Iteration: 16900000, Loss: 0.00040676025633690324\n",
            "Iteration: 16910000, Loss: 0.0004067598224895854\n",
            "Iteration: 16920000, Loss: 0.0004067593889436099\n",
            "Iteration: 16930000, Loss: 0.0004067589556987657\n",
            "Iteration: 16940000, Loss: 0.00040675852275484295\n",
            "Iteration: 16950000, Loss: 0.0004067580901116316\n",
            "Iteration: 16960000, Loss: 0.0004067576577689215\n",
            "Iteration: 16970000, Loss: 0.0004067572257265038\n",
            "Iteration: 16980000, Loss: 0.00040675679398416794\n",
            "Iteration: 16990000, Loss: 0.00040675636254170486\n",
            "Iteration: 17000000, Loss: 0.00040675593139890556\n",
            "Iteration: 17010000, Loss: 0.00040675550055556034\n",
            "Iteration: 17020000, Loss: 0.0004067550700114609\n",
            "Iteration: 17030000, Loss: 0.00040675463976639736\n",
            "Iteration: 17040000, Loss: 0.00040675420982016233\n",
            "Iteration: 17050000, Loss: 0.00040675378017254656\n",
            "Iteration: 17060000, Loss: 0.00040675335082334177\n",
            "Iteration: 17070000, Loss: 0.00040675292177233963\n",
            "Iteration: 17080000, Loss: 0.0004067524930193325\n",
            "Iteration: 17090000, Loss: 0.00040675206456411146\n",
            "Iteration: 17100000, Loss: 0.0004067516364064697\n",
            "Iteration: 17110000, Loss: 0.0004067512085461988\n",
            "Iteration: 17120000, Loss: 0.00040675078098309205\n",
            "Iteration: 17130000, Loss: 0.0004067503537169415\n",
            "Iteration: 17140000, Loss: 0.0004067499267475403\n",
            "Iteration: 17150000, Loss: 0.0004067495000746809\n",
            "Iteration: 17160000, Loss: 0.0004067490736981567\n",
            "Iteration: 17170000, Loss: 0.00040674864761776065\n",
            "Iteration: 17180000, Loss: 0.00040674822183328646\n",
            "Iteration: 17190000, Loss: 0.0004067477963445278\n",
            "Iteration: 17200000, Loss: 0.0004067473711512779\n",
            "Iteration: 17210000, Loss: 0.0004067469462533308\n",
            "Iteration: 17220000, Loss: 0.00040674652165048\n",
            "Iteration: 17230000, Loss: 0.0004067460973425203\n",
            "Iteration: 17240000, Loss: 0.0004067456733292455\n",
            "Iteration: 17250000, Loss: 0.00040674524961045017\n",
            "Iteration: 17260000, Loss: 0.00040674482618592876\n",
            "Iteration: 17270000, Loss: 0.0004067444030554762\n",
            "Iteration: 17280000, Loss: 0.0004067439802188866\n",
            "Iteration: 17290000, Loss: 0.0004067435576759556\n",
            "Iteration: 17300000, Loss: 0.00040674313542647813\n",
            "Iteration: 17310000, Loss: 0.0004067427134702492\n",
            "Iteration: 17320000, Loss: 0.00040674229180706514\n",
            "Iteration: 17330000, Loss: 0.00040674187043672017\n",
            "Iteration: 17340000, Loss: 0.00040674144935901117\n",
            "Iteration: 17350000, Loss: 0.0004067410285737329\n",
            "Iteration: 17360000, Loss: 0.0004067406080806821\n",
            "Iteration: 17370000, Loss: 0.00040674018787965427\n",
            "Iteration: 17380000, Loss: 0.0004067397679704465\n",
            "Iteration: 17390000, Loss: 0.0004067393483528545\n",
            "Iteration: 17400000, Loss: 0.0004067389290266756\n",
            "Iteration: 17410000, Loss: 0.00040673850999170535\n",
            "Iteration: 17420000, Loss: 0.0004067380912477416\n",
            "Iteration: 17430000, Loss: 0.00040673767279458074\n",
            "Iteration: 17440000, Loss: 0.00040673725463202044\n",
            "Iteration: 17450000, Loss: 0.00040673683675985714\n",
            "Iteration: 17460000, Loss: 0.0004067364191778895\n",
            "Iteration: 17470000, Loss: 0.00040673600188591356\n",
            "Iteration: 17480000, Loss: 0.0004067355848837286\n",
            "Iteration: 17490000, Loss: 0.0004067351681711308\n",
            "Iteration: 17500000, Loss: 0.0004067347517479194\n",
            "Iteration: 17510000, Loss: 0.0004067343356138926\n",
            "Iteration: 17520000, Loss: 0.00040673391976884783\n",
            "Iteration: 17530000, Loss: 0.0004067335042125837\n",
            "Iteration: 17540000, Loss: 0.000406733088944899\n",
            "Iteration: 17550000, Loss: 0.00040673267396559284\n",
            "Iteration: 17560000, Loss: 0.000406732259274463\n",
            "Iteration: 17570000, Loss: 0.0004067318448713093\n",
            "Iteration: 17580000, Loss: 0.0004067314307559307\n",
            "Iteration: 17590000, Loss: 0.0004067310169281265\n",
            "Iteration: 17600000, Loss: 0.00040673060338769626\n",
            "Iteration: 17610000, Loss: 0.00040673019013443885\n",
            "Iteration: 17620000, Loss: 0.0004067297771681542\n",
            "Iteration: 17630000, Loss: 0.0004067293644886425\n",
            "Iteration: 17640000, Loss: 0.00040672895209570374\n",
            "Iteration: 17650000, Loss: 0.00040672853998913774\n",
            "Iteration: 17660000, Loss: 0.0004067281281687449\n",
            "Iteration: 17670000, Loss: 0.00040672771663432513\n",
            "Iteration: 17680000, Loss: 0.0004067273053856801\n",
            "Iteration: 17690000, Loss: 0.0004067268944226094\n",
            "Iteration: 17700000, Loss: 0.00040672648374491424\n",
            "Iteration: 17710000, Loss: 0.0004067260733523959\n",
            "Iteration: 17720000, Loss: 0.000406725663244855\n",
            "Iteration: 17730000, Loss: 0.00040672525342209275\n",
            "Iteration: 17740000, Loss: 0.000406724843883911\n",
            "Iteration: 17750000, Loss: 0.00040672443463011046\n",
            "Iteration: 17760000, Loss: 0.0004067240256604942\n",
            "Iteration: 17770000, Loss: 0.00040672361697486237\n",
            "Iteration: 17780000, Loss: 0.00040672320857301807\n",
            "Iteration: 17790000, Loss: 0.00040672280045476306\n",
            "Iteration: 17800000, Loss: 0.0004067223926198993\n",
            "Iteration: 17810000, Loss: 0.00040672198506822927\n",
            "Iteration: 17820000, Loss: 0.0004067215777995555\n",
            "Iteration: 17830000, Loss: 0.00040672117081368093\n",
            "Iteration: 17840000, Loss: 0.00040672076411040766\n",
            "Iteration: 17850000, Loss: 0.0004067203576895391\n",
            "Iteration: 17860000, Loss: 0.00040671995155087856\n",
            "Iteration: 17870000, Loss: 0.0004067195456942286\n",
            "Iteration: 17880000, Loss: 0.0004067191401193928\n",
            "Iteration: 17890000, Loss: 0.000406718734826175\n",
            "Iteration: 17900000, Loss: 0.00040671832981437804\n",
            "Iteration: 17910000, Loss: 0.0004067179250838065\n",
            "Iteration: 17920000, Loss: 0.00040671752063426385\n",
            "Iteration: 17930000, Loss: 0.0004067171164655539\n",
            "Iteration: 17940000, Loss: 0.0004067167125774813\n",
            "Iteration: 17950000, Loss: 0.00040671630896985\n",
            "Iteration: 17960000, Loss: 0.0004067159056424643\n",
            "Iteration: 17970000, Loss: 0.0004067155025951294\n",
            "Iteration: 17980000, Loss: 0.00040671509982764917\n",
            "Iteration: 17990000, Loss: 0.0004067146973398292\n",
            "Iteration: 18000000, Loss: 0.0004067142951314744\n",
            "Iteration: 18010000, Loss: 0.00040671389320238923\n",
            "Iteration: 18020000, Loss: 0.0004067134915523796\n",
            "Iteration: 18030000, Loss: 0.0004067130901812508\n",
            "Iteration: 18040000, Loss: 0.0004067126890888086\n",
            "Iteration: 18050000, Loss: 0.0004067122882748578\n",
            "Iteration: 18060000, Loss: 0.0004067118877392053\n",
            "Iteration: 18070000, Loss: 0.0004067114874816564\n",
            "Iteration: 18080000, Loss: 0.0004067110875020171\n",
            "Iteration: 18090000, Loss: 0.00040671068780009397\n",
            "Iteration: 18100000, Loss: 0.0004067102883756928\n",
            "Iteration: 18110000, Loss: 0.00040670988922862113\n",
            "Iteration: 18120000, Loss: 0.0004067094903586849\n",
            "Iteration: 18130000, Loss: 0.0004067090917656911\n",
            "Iteration: 18140000, Loss: 0.0004067086934494462\n",
            "Iteration: 18150000, Loss: 0.0004067082954097576\n",
            "Iteration: 18160000, Loss: 0.00040670789764643285\n",
            "Iteration: 18170000, Loss: 0.00040670750015927844\n",
            "Iteration: 18180000, Loss: 0.0004067071029481023\n",
            "Iteration: 18190000, Loss: 0.0004067067060127119\n",
            "Iteration: 18200000, Loss: 0.00040670630935291503\n",
            "Iteration: 18210000, Loss: 0.00040670591296851924\n",
            "Iteration: 18220000, Loss: 0.00040670551685933315\n",
            "Iteration: 18230000, Loss: 0.0004067051210251646\n",
            "Iteration: 18240000, Loss: 0.0004067047254658217\n",
            "Iteration: 18250000, Loss: 0.0004067043301811128\n",
            "Iteration: 18260000, Loss: 0.000406703935170847\n",
            "Iteration: 18270000, Loss: 0.00040670354043483177\n",
            "Iteration: 18280000, Loss: 0.00040670314597287703\n",
            "Iteration: 18290000, Loss: 0.0004067027517847915\n",
            "Iteration: 18300000, Loss: 0.0004067023578703839\n",
            "Iteration: 18310000, Loss: 0.0004067019642294634\n",
            "Iteration: 18320000, Loss: 0.0004067015708618403\n",
            "Iteration: 18330000, Loss: 0.0004067011777673226\n",
            "Iteration: 18340000, Loss: 0.00040670078494572123\n",
            "Iteration: 18350000, Loss: 0.00040670039239684475\n",
            "Iteration: 18360000, Loss: 0.0004067000001205042\n",
            "Iteration: 18370000, Loss: 0.00040669960811650914\n",
            "Iteration: 18380000, Loss: 0.00040669921638466925\n",
            "Iteration: 18390000, Loss: 0.00040669882492479524\n",
            "Iteration: 18400000, Loss: 0.0004066984337366977\n",
            "Iteration: 18410000, Loss: 0.0004066980428201863\n",
            "Iteration: 18420000, Loss: 0.00040669765217507325\n",
            "Iteration: 18430000, Loss: 0.0004066972618011681\n",
            "Iteration: 18440000, Loss: 0.00040669687169828187\n",
            "Iteration: 18450000, Loss: 0.00040669648186622635\n",
            "Iteration: 18460000, Loss: 0.0004066960923048115\n",
            "Iteration: 18470000, Loss: 0.0004066957030138504\n",
            "Iteration: 18480000, Loss: 0.00040669531399315325\n",
            "Iteration: 18490000, Loss: 0.000406694925242532\n",
            "Iteration: 18500000, Loss: 0.00040669453676179845\n",
            "Iteration: 18510000, Loss: 0.000406694148550765\n",
            "Iteration: 18520000, Loss: 0.0004066937606092424\n",
            "Iteration: 18530000, Loss: 0.0004066933729370438\n",
            "Iteration: 18540000, Loss: 0.000406692985533981\n",
            "Iteration: 18550000, Loss: 0.0004066925983998666\n",
            "Iteration: 18560000, Loss: 0.0004066922115345135\n",
            "Iteration: 18570000, Loss: 0.00040669182493773356\n",
            "Iteration: 18580000, Loss: 0.00040669143860933986\n",
            "Iteration: 18590000, Loss: 0.0004066910525491456\n",
            "Iteration: 18600000, Loss: 0.00040669066675696406\n",
            "Iteration: 18610000, Loss: 0.0004066902812326078\n",
            "Iteration: 18620000, Loss: 0.00040668989597589093\n",
            "Iteration: 18630000, Loss: 0.00040668951098662574\n",
            "Iteration: 18640000, Loss: 0.00040668912626462686\n",
            "Iteration: 18650000, Loss: 0.0004066887418097075\n",
            "Iteration: 18660000, Loss: 0.0004066883576216818\n",
            "Iteration: 18670000, Loss: 0.00040668797370036375\n",
            "Iteration: 18680000, Loss: 0.0004066875900455671\n",
            "Iteration: 18690000, Loss: 0.00040668720665710644\n",
            "Iteration: 18700000, Loss: 0.00040668682353479593\n",
            "Iteration: 18710000, Loss: 0.00040668644067845024\n",
            "Iteration: 18720000, Loss: 0.00040668605808788424\n",
            "Iteration: 18730000, Loss: 0.000406685675762912\n",
            "Iteration: 18740000, Loss: 0.00040668529370334864\n",
            "Iteration: 18750000, Loss: 0.0004066849119090099\n",
            "Iteration: 18760000, Loss: 0.0004066845303797104\n",
            "Iteration: 18770000, Loss: 0.00040668414911526526\n",
            "Iteration: 18780000, Loss: 0.0004066837681154902\n",
            "Iteration: 18790000, Loss: 0.0004066833873802003\n",
            "Iteration: 18800000, Loss: 0.0004066830069092118\n",
            "Iteration: 18810000, Loss: 0.00040668262670234053\n",
            "Iteration: 18820000, Loss: 0.0004066822467594018\n",
            "Iteration: 18830000, Loss: 0.00040668186708021247\n",
            "Iteration: 18840000, Loss: 0.0004066814876645884\n",
            "Iteration: 18850000, Loss: 0.0004066811085123456\n",
            "Iteration: 18860000, Loss: 0.00040668072962330066\n",
            "Iteration: 18870000, Loss: 0.0004066803509972703\n",
            "Iteration: 18880000, Loss: 0.00040667997263407133\n",
            "Iteration: 18890000, Loss: 0.00040667959453352084\n",
            "Iteration: 18900000, Loss: 0.00040667921669543494\n",
            "Iteration: 18910000, Loss: 0.0004066788391196317\n",
            "Iteration: 18920000, Loss: 0.00040667846180592764\n",
            "Iteration: 18930000, Loss: 0.00040667808475414044\n",
            "Iteration: 18940000, Loss: 0.0004066777079640878\n",
            "Iteration: 18950000, Loss: 0.00040667733143558664\n",
            "Iteration: 18960000, Loss: 0.00040667695516845547\n",
            "Iteration: 18970000, Loss: 0.00040667657916251164\n",
            "Iteration: 18980000, Loss: 0.00040667620341757317\n",
            "Iteration: 18990000, Loss: 0.00040667582793345883\n",
            "Iteration: 19000000, Loss: 0.0004066754527099858\n",
            "Iteration: 19010000, Loss: 0.00040667507774697363\n",
            "Iteration: 19020000, Loss: 0.00040667470304423995\n",
            "Iteration: 19030000, Loss: 0.0004066743286016035\n",
            "Iteration: 19040000, Loss: 0.0004066739544188837\n",
            "Iteration: 19050000, Loss: 0.0004066735804958988\n",
            "Iteration: 19060000, Loss: 0.0004066732068324682\n",
            "Iteration: 19070000, Loss: 0.00040667283342841093\n",
            "Iteration: 19080000, Loss: 0.0004066724602835456\n",
            "Iteration: 19090000, Loss: 0.00040667208739769283\n",
            "Iteration: 19100000, Loss: 0.00040667171477067174\n",
            "Iteration: 19110000, Loss: 0.00040667134240230133\n",
            "Iteration: 19120000, Loss: 0.00040667097029240196\n",
            "Iteration: 19130000, Loss: 0.0004066705984407933\n",
            "Iteration: 19140000, Loss: 0.00040667022684729576\n",
            "Iteration: 19150000, Loss: 0.0004066698555117296\n",
            "Iteration: 19160000, Loss: 0.0004066694844339145\n",
            "Iteration: 19170000, Loss: 0.0004066691136136707\n",
            "Iteration: 19180000, Loss: 0.0004066687430508201\n",
            "Iteration: 19190000, Loss: 0.00040666837274518173\n",
            "Iteration: 19200000, Loss: 0.0004066680026965775\n",
            "Iteration: 19210000, Loss: 0.0004066676329048281\n",
            "Iteration: 19220000, Loss: 0.00040666726336975416\n",
            "Iteration: 19230000, Loss: 0.00040666689409117715\n",
            "Iteration: 19240000, Loss: 0.0004066665250689184\n",
            "Iteration: 19250000, Loss: 0.0004066661563027991\n",
            "Iteration: 19260000, Loss: 0.00040666578779264173\n",
            "Iteration: 19270000, Loss: 0.00040666541953826644\n",
            "Iteration: 19280000, Loss: 0.00040666505153949615\n",
            "Iteration: 19290000, Loss: 0.000406664683796153\n",
            "Iteration: 19300000, Loss: 0.0004066643163080581\n",
            "Iteration: 19310000, Loss: 0.0004066639490750336\n",
            "Iteration: 19320000, Loss: 0.0004066635820969025\n",
            "Iteration: 19330000, Loss: 0.0004066632153734876\n",
            "Iteration: 19340000, Loss: 0.0004066628489046102\n",
            "Iteration: 19350000, Loss: 0.0004066624826900938\n",
            "Iteration: 19360000, Loss: 0.0004066621167297608\n",
            "Iteration: 19370000, Loss: 0.00040666175102343447\n",
            "Iteration: 19380000, Loss: 0.00040666138557093797\n",
            "Iteration: 19390000, Loss: 0.00040666102037209404\n",
            "Iteration: 19400000, Loss: 0.0004066606554267262\n",
            "Iteration: 19410000, Loss: 0.0004066602907346582\n",
            "Iteration: 19420000, Loss: 0.0004066599262957131\n",
            "Iteration: 19430000, Loss: 0.00040665956210971454\n",
            "Iteration: 19440000, Loss: 0.0004066591981764864\n",
            "Iteration: 19450000, Loss: 0.0004066588344958528\n",
            "Iteration: 19460000, Loss: 0.0004066584710676377\n",
            "Iteration: 19470000, Loss: 0.00040665810789166545\n",
            "Iteration: 19480000, Loss: 0.00040665774496776016\n",
            "Iteration: 19490000, Loss: 0.00040665738229574627\n",
            "Iteration: 19500000, Loss: 0.0004066570198754478\n",
            "Iteration: 19510000, Loss: 0.00040665665770668987\n",
            "Iteration: 19520000, Loss: 0.0004066562957892979\n",
            "Iteration: 19530000, Loss: 0.000406655934123096\n",
            "Iteration: 19540000, Loss: 0.0004066555727079094\n",
            "Iteration: 19550000, Loss: 0.0004066552115435635\n",
            "Iteration: 19560000, Loss: 0.00040665485062988305\n",
            "Iteration: 19570000, Loss: 0.00040665448996669363\n",
            "Iteration: 19580000, Loss: 0.0004066541295538205\n",
            "Iteration: 19590000, Loss: 0.0004066537693910905\n",
            "Iteration: 19600000, Loss: 0.00040665340947832845\n",
            "Iteration: 19610000, Loss: 0.0004066530498153601\n",
            "Iteration: 19620000, Loss: 0.000406652690402012\n",
            "Iteration: 19630000, Loss: 0.00040665233123810934\n",
            "Iteration: 19640000, Loss: 0.0004066519723234796\n",
            "Iteration: 19650000, Loss: 0.00040665161365794863\n",
            "Iteration: 19660000, Loss: 0.00040665125524134255\n",
            "Iteration: 19670000, Loss: 0.00040665089707348894\n",
            "Iteration: 19680000, Loss: 0.00040665053915421383\n",
            "Iteration: 19690000, Loss: 0.00040665018148334375\n",
            "Iteration: 19700000, Loss: 0.00040664982406070653\n",
            "Iteration: 19710000, Loss: 0.00040664946688612896\n",
            "Iteration: 19720000, Loss: 0.0004066491099594384\n",
            "Iteration: 19730000, Loss: 0.0004066487532804616\n",
            "Iteration: 19740000, Loss: 0.00040664839684902685\n",
            "Iteration: 19750000, Loss: 0.000406648040664961\n",
            "Iteration: 19760000, Loss: 0.00040664768472809226\n",
            "Iteration: 19770000, Loss: 0.0004066473290382486\n",
            "Iteration: 19780000, Loss: 0.00040664697359525746\n",
            "Iteration: 19790000, Loss: 0.0004066466183989469\n",
            "Iteration: 19800000, Loss: 0.00040664626344914654\n",
            "Iteration: 19810000, Loss: 0.00040664590874568246\n",
            "Iteration: 19820000, Loss: 0.0004066455542883846\n",
            "Iteration: 19830000, Loss: 0.00040664520007708106\n",
            "Iteration: 19840000, Loss: 0.00040664484611160066\n",
            "Iteration: 19850000, Loss: 0.00040664449239177227\n",
            "Iteration: 19860000, Loss: 0.00040664413891742444\n",
            "Iteration: 19870000, Loss: 0.00040664378568838636\n",
            "Iteration: 19880000, Loss: 0.0004066434327044876\n",
            "Iteration: 19890000, Loss: 0.00040664307996555744\n",
            "Iteration: 19900000, Loss: 0.0004066427274714245\n",
            "Iteration: 19910000, Loss: 0.00040664237522191883\n",
            "Iteration: 19920000, Loss: 0.00040664202321687013\n",
            "Iteration: 19930000, Loss: 0.00040664167145610845\n",
            "Iteration: 19940000, Loss: 0.00040664131993946274\n",
            "Iteration: 19950000, Loss: 0.00040664096866676415\n",
            "Iteration: 19960000, Loss: 0.00040664061763784175\n",
            "Iteration: 19970000, Loss: 0.0004066402668525268\n",
            "Iteration: 19980000, Loss: 0.0004066399163106484\n",
            "Iteration: 19990000, Loss: 0.0004066395660120383\n",
            "Iteration: 20000000, Loss: 0.00040663921595652597\n",
            "Iteration: 20010000, Loss: 0.0004066388661439434\n",
            "Iteration: 20020000, Loss: 0.0004066385165741205\n",
            "Iteration: 20030000, Loss: 0.00040663816724688834\n",
            "Iteration: 20040000, Loss: 0.00040663781816207824\n",
            "Iteration: 20050000, Loss: 0.0004066374693195214\n",
            "Iteration: 20060000, Loss: 0.0004066371207190486\n",
            "Iteration: 20070000, Loss: 0.00040663677236049223\n",
            "Iteration: 20080000, Loss: 0.00040663642424368276\n",
            "Iteration: 20090000, Loss: 0.0004066360763684528\n",
            "Iteration: 20100000, Loss: 0.0004066357287346336\n",
            "Iteration: 20110000, Loss: 0.00040663538134205757\n",
            "Iteration: 20120000, Loss: 0.00040663503419055563\n",
            "Iteration: 20130000, Loss: 0.0004066346872799611\n",
            "Iteration: 20140000, Loss: 0.0004066343406101059\n",
            "Iteration: 20150000, Loss: 0.00040663399418082197\n",
            "Iteration: 20160000, Loss: 0.00040663364799194254\n",
            "Iteration: 20170000, Loss: 0.0004066333020432996\n",
            "Iteration: 20180000, Loss: 0.0004066329563347258\n",
            "Iteration: 20190000, Loss: 0.0004066326108660544\n",
            "Iteration: 20200000, Loss: 0.0004066322656371183\n",
            "Iteration: 20210000, Loss: 0.00040663192064775065\n",
            "Iteration: 20220000, Loss: 0.0004066315758977846\n",
            "Iteration: 20230000, Loss: 0.0004066312313870532\n",
            "Iteration: 20240000, Loss: 0.0004066308871153897\n",
            "Iteration: 20250000, Loss: 0.00040663054308262873\n",
            "Iteration: 20260000, Loss: 0.00040663019928860304\n",
            "Iteration: 20270000, Loss: 0.0004066298557331466\n",
            "Iteration: 20280000, Loss: 0.00040662951241609327\n",
            "Iteration: 20290000, Loss: 0.00040662916933727715\n",
            "Iteration: 20300000, Loss: 0.00040662882649653253\n",
            "Iteration: 20310000, Loss: 0.0004066284838936932\n",
            "Iteration: 20320000, Loss: 0.00040662814152859415\n",
            "Iteration: 20330000, Loss: 0.0004066277994010693\n",
            "Iteration: 20340000, Loss: 0.00040662745751095307\n",
            "Iteration: 20350000, Loss: 0.00040662711585808133\n",
            "Iteration: 20360000, Loss: 0.00040662677444228764\n",
            "Iteration: 20370000, Loss: 0.0004066264332634076\n",
            "Iteration: 20380000, Loss: 0.0004066260923212765\n",
            "Iteration: 20390000, Loss: 0.00040662575161572905\n",
            "Iteration: 20400000, Loss: 0.0004066254111466005\n",
            "Iteration: 20410000, Loss: 0.00040662507091372604\n",
            "Iteration: 20420000, Loss: 0.0004066247309169419\n",
            "Iteration: 20430000, Loss: 0.00040662439115608383\n",
            "Iteration: 20440000, Loss: 0.00040662405163098667\n",
            "Iteration: 20450000, Loss: 0.000406623712341487\n",
            "Iteration: 20460000, Loss: 0.00040662337328742007\n",
            "Iteration: 20470000, Loss: 0.0004066230344686228\n",
            "Iteration: 20480000, Loss: 0.000406622695884931\n",
            "Iteration: 20490000, Loss: 0.00040662235753618147\n",
            "Iteration: 20500000, Loss: 0.00040662201942221013\n",
            "Iteration: 20510000, Loss: 0.00040662168154285364\n",
            "Iteration: 20520000, Loss: 0.0004066213438979487\n",
            "Iteration: 20530000, Loss: 0.0004066210064873324\n",
            "Iteration: 20540000, Loss: 0.0004066206693108413\n",
            "Iteration: 20550000, Loss: 0.0004066203323683122\n",
            "Iteration: 20560000, Loss: 0.00040661999565958277\n",
            "Iteration: 20570000, Loss: 0.0004066196591844899\n",
            "Iteration: 20580000, Loss: 0.0004066193229428712\n",
            "Iteration: 20590000, Loss: 0.0004066189869345642\n",
            "Iteration: 20600000, Loss: 0.0004066186511594062\n",
            "Iteration: 20610000, Loss: 0.00040661831561723463\n",
            "Iteration: 20620000, Loss: 0.0004066179803078881\n",
            "Iteration: 20630000, Loss: 0.00040661764523120436\n",
            "Iteration: 20640000, Loss: 0.0004066173103870208\n",
            "Iteration: 20650000, Loss: 0.0004066169757751763\n",
            "Iteration: 20660000, Loss: 0.00040661664139550897\n",
            "Iteration: 20670000, Loss: 0.00040661630724785666\n",
            "Iteration: 20680000, Loss: 0.0004066159733320586\n",
            "Iteration: 20690000, Loss: 0.0004066156396479533\n",
            "Iteration: 20700000, Loss: 0.00040661530619537893\n",
            "Iteration: 20710000, Loss: 0.0004066149729741749\n",
            "Iteration: 20720000, Loss: 0.0004066146399841799\n",
            "Iteration: 20730000, Loss: 0.0004066143072252328\n",
            "Iteration: 20740000, Loss: 0.0004066139746971738\n",
            "Iteration: 20750000, Loss: 0.00040661364239984117\n",
            "Iteration: 20760000, Loss: 0.0004066133103330742\n",
            "Iteration: 20770000, Loss: 0.0004066129784967127\n",
            "Iteration: 20780000, Loss: 0.00040661264689059674\n",
            "Iteration: 20790000, Loss: 0.0004066123155145654\n",
            "Iteration: 20800000, Loss: 0.0004066119843684593\n",
            "Iteration: 20810000, Loss: 0.0004066116534521178\n",
            "Iteration: 20820000, Loss: 0.00040661132276538064\n",
            "Iteration: 20830000, Loss: 0.0004066109923080893\n",
            "Iteration: 20840000, Loss: 0.0004066106620800831\n",
            "Iteration: 20850000, Loss: 0.00040661033208120234\n",
            "Iteration: 20860000, Loss: 0.0004066100023112881\n",
            "Iteration: 20870000, Loss: 0.00040660967277018065\n",
            "Iteration: 20880000, Loss: 0.0004066093434577208\n",
            "Iteration: 20890000, Loss: 0.0004066090143737497\n",
            "Iteration: 20900000, Loss: 0.00040660868551810797\n",
            "Iteration: 20910000, Loss: 0.000406608356890637\n",
            "Iteration: 20920000, Loss: 0.0004066080284911778\n",
            "Iteration: 20930000, Loss: 0.00040660770031957145\n",
            "Iteration: 20940000, Loss: 0.0004066073723756602\n",
            "Iteration: 20950000, Loss: 0.0004066070446592846\n",
            "Iteration: 20960000, Loss: 0.00040660671717028665\n",
            "Iteration: 20970000, Loss: 0.0004066063899085083\n",
            "Iteration: 20980000, Loss: 0.00040660606287379135\n",
            "Iteration: 20990000, Loss: 0.00040660573606597785\n",
            "Iteration: 21000000, Loss: 0.00040660540948490935\n",
            "Iteration: 21010000, Loss: 0.0004066050831304288\n",
            "Iteration: 21020000, Loss: 0.00040660475700237796\n",
            "Iteration: 21030000, Loss: 0.0004066044311005994\n",
            "Iteration: 21040000, Loss: 0.0004066041054249363\n",
            "Iteration: 21050000, Loss: 0.0004066037799752298\n",
            "Iteration: 21060000, Loss: 0.00040660345475132433\n",
            "Iteration: 21070000, Loss: 0.0004066031297530615\n",
            "Iteration: 21080000, Loss: 0.0004066028049802849\n",
            "Iteration: 21090000, Loss: 0.0004066024804328377\n",
            "Iteration: 21100000, Loss: 0.00040660215611056213\n",
            "Iteration: 21110000, Loss: 0.0004066018320133029\n",
            "Iteration: 21120000, Loss: 0.0004066015081409027\n",
            "Iteration: 21130000, Loss: 0.00040660118449320476\n",
            "Iteration: 21140000, Loss: 0.0004066008610700532\n",
            "Iteration: 21150000, Loss: 0.0004066005378712917\n",
            "Iteration: 21160000, Loss: 0.00040660021489676435\n",
            "Iteration: 21170000, Loss: 0.00040659989214631424\n",
            "Iteration: 21180000, Loss: 0.000406599569619786\n",
            "Iteration: 21190000, Loss: 0.0004065992473170241\n",
            "Iteration: 21200000, Loss: 0.0004065989252378722\n",
            "Iteration: 21210000, Loss: 0.0004065986033821756\n",
            "Iteration: 21220000, Loss: 0.00040659828174977763\n",
            "Iteration: 21230000, Loss: 0.00040659796034052376\n",
            "Iteration: 21240000, Loss: 0.00040659763915425846\n",
            "Iteration: 21250000, Loss: 0.00040659731819082614\n",
            "Iteration: 21260000, Loss: 0.00040659699745007247\n",
            "Iteration: 21270000, Loss: 0.0004065966769318426\n",
            "Iteration: 21280000, Loss: 0.0004065963566359809\n",
            "Iteration: 21290000, Loss: 0.0004065960365623331\n",
            "Iteration: 21300000, Loss: 0.0004065957167107445\n",
            "Iteration: 21310000, Loss: 0.00040659539708106035\n",
            "Iteration: 21320000, Loss: 0.000406595077673127\n",
            "Iteration: 21330000, Loss: 0.00040659475848678936\n",
            "Iteration: 21340000, Loss: 0.00040659443952189347\n",
            "Iteration: 21350000, Loss: 0.0004065941207782857\n",
            "Iteration: 21360000, Loss: 0.0004065938022558106\n",
            "Iteration: 21370000, Loss: 0.0004065934839543162\n",
            "Iteration: 21380000, Loss: 0.0004065931658736475\n",
            "Iteration: 21390000, Loss: 0.0004065928480136516\n",
            "Iteration: 21400000, Loss: 0.00040659253037417454\n",
            "Iteration: 21410000, Loss: 0.0004065922129550633\n",
            "Iteration: 21420000, Loss: 0.00040659189575616383\n",
            "Iteration: 21430000, Loss: 0.00040659157877732363\n",
            "Iteration: 21440000, Loss: 0.00040659126201838885\n",
            "Iteration: 21450000, Loss: 0.0004065909454792066\n",
            "Iteration: 21460000, Loss: 0.0004065906291596251\n",
            "Iteration: 21470000, Loss: 0.00040659031305949046\n",
            "Iteration: 21480000, Loss: 0.00040658999717865\n",
            "Iteration: 21490000, Loss: 0.0004065896815169515\n",
            "Iteration: 21500000, Loss: 0.00040658936607424243\n",
            "Iteration: 21510000, Loss: 0.00040658905085037047\n",
            "Iteration: 21520000, Loss: 0.00040658873584518344\n",
            "Iteration: 21530000, Loss: 0.0004065884210585288\n",
            "Iteration: 21540000, Loss: 0.0004065881064902551\n",
            "Iteration: 21550000, Loss: 0.0004065877921402094\n",
            "Iteration: 21560000, Loss: 0.00040658747800824104\n",
            "Iteration: 21570000, Loss: 0.0004065871640941978\n",
            "Iteration: 21580000, Loss: 0.000406586850397928\n",
            "Iteration: 21590000, Loss: 0.00040658653691928015\n",
            "Iteration: 21600000, Loss: 0.00040658622365810296\n",
            "Iteration: 21610000, Loss: 0.00040658591061424476\n",
            "Iteration: 21620000, Loss: 0.0004065855977875551\n",
            "Iteration: 21630000, Loss: 0.00040658528517788185\n",
            "Iteration: 21640000, Loss: 0.00040658497278507556\n",
            "Iteration: 21650000, Loss: 0.00040658466060898313\n",
            "Iteration: 21660000, Loss: 0.00040658434864945613\n",
            "Iteration: 21670000, Loss: 0.0004065840369063426\n",
            "Iteration: 21680000, Loss: 0.00040658372537949195\n",
            "Iteration: 21690000, Loss: 0.0004065834140687548\n",
            "Iteration: 21700000, Loss: 0.00040658310297397876\n",
            "Iteration: 21710000, Loss: 0.00040658279209501567\n",
            "Iteration: 21720000, Loss: 0.00040658248143171465\n",
            "Iteration: 21730000, Loss: 0.000406582170983925\n",
            "Iteration: 21740000, Loss: 0.00040658186075149784\n",
            "Iteration: 21750000, Loss: 0.00040658155073428277\n",
            "Iteration: 21760000, Loss: 0.00040658124093213003\n",
            "Iteration: 21770000, Loss: 0.0004065809313448904\n",
            "Iteration: 21780000, Loss: 0.0004065806219724143\n",
            "Iteration: 21790000, Loss: 0.0004065803128145521\n",
            "Iteration: 21800000, Loss: 0.0004065800038711543\n",
            "Iteration: 21810000, Loss: 0.0004065796951420723\n",
            "Iteration: 21820000, Loss: 0.0004065793866271565\n",
            "Iteration: 21830000, Loss: 0.00040657907832625825\n",
            "Iteration: 21840000, Loss: 0.0004065787702392288\n",
            "Iteration: 21850000, Loss: 0.00040657846236591877\n",
            "Iteration: 21860000, Loss: 0.0004065781547061797\n",
            "Iteration: 21870000, Loss: 0.0004065778472598634\n",
            "Iteration: 21880000, Loss: 0.0004065775400268213\n",
            "Iteration: 21890000, Loss: 0.00040657723300690477\n",
            "Iteration: 21900000, Loss: 0.0004065769261999654\n",
            "Iteration: 21910000, Loss: 0.0004065766196058556\n",
            "Iteration: 21920000, Loss: 0.0004065763132244273\n",
            "Iteration: 21930000, Loss: 0.00040657600705553185\n",
            "Iteration: 21940000, Loss: 0.0004065757010990225\n",
            "Iteration: 21950000, Loss: 0.0004065753953547508\n",
            "Iteration: 21960000, Loss: 0.0004065750898225686\n",
            "Iteration: 21970000, Loss: 0.00040657478450232957\n",
            "Iteration: 21980000, Loss: 0.00040657447939388536\n",
            "Iteration: 21990000, Loss: 0.0004065741744970894\n",
            "Iteration: 22000000, Loss: 0.00040657386981179363\n",
            "Iteration: 22010000, Loss: 0.0004065735653378521\n",
            "Iteration: 22020000, Loss: 0.0004065732610751162\n",
            "Iteration: 22030000, Loss: 0.0004065729570234406\n",
            "Iteration: 22040000, Loss: 0.0004065726531826774\n",
            "Iteration: 22050000, Loss: 0.00040657234955268043\n",
            "Iteration: 22060000, Loss: 0.00040657204613330297\n",
            "Iteration: 22070000, Loss: 0.00040657174292439864\n",
            "Iteration: 22080000, Loss: 0.00040657143992582076\n",
            "Iteration: 22090000, Loss: 0.000406571137137423\n",
            "Iteration: 22100000, Loss: 0.00040657083455905975\n",
            "Iteration: 22110000, Loss: 0.0004065705321905838\n",
            "Iteration: 22120000, Loss: 0.0004065702300318505\n",
            "Iteration: 22130000, Loss: 0.0004065699280827134\n",
            "Iteration: 22140000, Loss: 0.0004065696263430266\n",
            "Iteration: 22150000, Loss: 0.00040656932481264457\n",
            "Iteration: 22160000, Loss: 0.00040656902349142144\n",
            "Iteration: 22170000, Loss: 0.000406568722379212\n",
            "Iteration: 22180000, Loss: 0.00040656842147587097\n",
            "Iteration: 22190000, Loss: 0.00040656812078125295\n",
            "Iteration: 22200000, Loss: 0.00040656782029521244\n",
            "Iteration: 22210000, Loss: 0.0004065675200176051\n",
            "Iteration: 22220000, Loss: 0.00040656721994828554\n",
            "Iteration: 22230000, Loss: 0.0004065669200871087\n",
            "Iteration: 22240000, Loss: 0.0004065666204339301\n",
            "Iteration: 22250000, Loss: 0.00040656632098860546\n",
            "Iteration: 22260000, Loss: 0.0004065660217509892\n",
            "Iteration: 22270000, Loss: 0.0004065657227209376\n",
            "Iteration: 22280000, Loss: 0.00040656542389830595\n",
            "Iteration: 22290000, Loss: 0.00040656512528295036\n",
            "Iteration: 22300000, Loss: 0.00040656482687472634\n",
            "Iteration: 22310000, Loss: 0.0004065645286734905\n",
            "Iteration: 22320000, Loss: 0.00040656423067909794\n",
            "Iteration: 22330000, Loss: 0.0004065639328914055\n",
            "Iteration: 22340000, Loss: 0.00040656363531026905\n",
            "Iteration: 22350000, Loss: 0.00040656333793554465\n",
            "Iteration: 22360000, Loss: 0.00040656304076709\n",
            "Iteration: 22370000, Loss: 0.00040656274380476004\n",
            "Iteration: 22380000, Loss: 0.00040656244704841273\n",
            "Iteration: 22390000, Loss: 0.0004065621504979038\n",
            "Iteration: 22400000, Loss: 0.00040656185415309114\n",
            "Iteration: 22410000, Loss: 0.0004065615580138305\n",
            "Iteration: 22420000, Loss: 0.0004065612620799802\n",
            "Iteration: 22430000, Loss: 0.00040656096635139624\n",
            "Iteration: 22440000, Loss: 0.00040656067082793686\n",
            "Iteration: 22450000, Loss: 0.0004065603755094582\n",
            "Iteration: 22460000, Loss: 0.00040656008039581954\n",
            "Iteration: 22470000, Loss: 0.00040655978548687684\n",
            "Iteration: 22480000, Loss: 0.00040655949078248764\n",
            "Iteration: 22490000, Loss: 0.00040655919628251083\n",
            "Iteration: 22500000, Loss: 0.00040655890198680405\n",
            "Iteration: 22510000, Loss: 0.00040655860789522456\n",
            "Iteration: 22520000, Loss: 0.00040655831400763094\n",
            "Iteration: 22530000, Loss: 0.0004065580203238813\n",
            "Iteration: 22540000, Loss: 0.0004065577268438332\n",
            "Iteration: 22550000, Loss: 0.00040655743356734613\n",
            "Iteration: 22560000, Loss: 0.00040655714049427793\n",
            "Iteration: 22570000, Loss: 0.0004065568476244868\n",
            "Iteration: 22580000, Loss: 0.00040655655495783183\n",
            "Iteration: 22590000, Loss: 0.00040655626249417204\n",
            "Iteration: 22600000, Loss: 0.00040655597023336556\n",
            "Iteration: 22610000, Loss: 0.0004065556781752717\n",
            "Iteration: 22620000, Loss: 0.0004065553863197498\n",
            "Iteration: 22630000, Loss: 0.0004065550946666585\n",
            "Iteration: 22640000, Loss: 0.0004065548032158574\n",
            "Iteration: 22650000, Loss: 0.0004065545119672052\n",
            "Iteration: 22660000, Loss: 0.00040655422092056184\n",
            "Iteration: 22670000, Loss: 0.00040655393007578736\n",
            "Iteration: 22680000, Loss: 0.00040655363943274073\n",
            "Iteration: 22690000, Loss: 0.00040655334899128176\n",
            "Iteration: 22700000, Loss: 0.0004065530587512699\n",
            "Iteration: 22710000, Loss: 0.0004065527687125654\n",
            "Iteration: 22720000, Loss: 0.000406552478875029\n",
            "Iteration: 22730000, Loss: 0.00040655218923851973\n",
            "Iteration: 22740000, Loss: 0.0004065518998028984\n",
            "Iteration: 22750000, Loss: 0.00040655161056802523\n",
            "Iteration: 22760000, Loss: 0.0004065513215337604\n",
            "Iteration: 22770000, Loss: 0.00040655103269996503\n",
            "Iteration: 22780000, Loss: 0.0004065507440664989\n",
            "Iteration: 22790000, Loss: 0.00040655045563322303\n",
            "Iteration: 22800000, Loss: 0.0004065501673999985\n",
            "Iteration: 22810000, Loss: 0.00040654987936668627\n",
            "Iteration: 22820000, Loss: 0.0004065495915331469\n",
            "Iteration: 22830000, Loss: 0.0004065493038992416\n",
            "Iteration: 22840000, Loss: 0.00040654901646483164\n",
            "Iteration: 22850000, Loss: 0.00040654872922977857\n",
            "Iteration: 22860000, Loss: 0.0004065484421939433\n",
            "Iteration: 22870000, Loss: 0.0004065481553571876\n",
            "Iteration: 22880000, Loss: 0.00040654786871937323\n",
            "Iteration: 22890000, Loss: 0.0004065475822803611\n",
            "Iteration: 22900000, Loss: 0.00040654729604001384\n",
            "Iteration: 22910000, Loss: 0.000406547009998193\n",
            "Iteration: 22920000, Loss: 0.0004065467241547604\n",
            "Iteration: 22930000, Loss: 0.0004065464385095787\n",
            "Iteration: 22940000, Loss: 0.0004065461530625091\n",
            "Iteration: 22950000, Loss: 0.00040654586781341495\n",
            "Iteration: 22960000, Loss: 0.0004065455827621575\n",
            "Iteration: 22970000, Loss: 0.00040654529790859993\n",
            "Iteration: 22980000, Loss: 0.00040654501325260503\n",
            "Iteration: 22990000, Loss: 0.0004065447287940344\n",
            "Iteration: 23000000, Loss: 0.00040654444453275127\n",
            "Iteration: 23010000, Loss: 0.0004065441604686191\n",
            "Iteration: 23020000, Loss: 0.0004065438766015002\n",
            "Iteration: 23030000, Loss: 0.00040654359293125736\n",
            "Iteration: 23040000, Loss: 0.0004065433094577542\n",
            "Iteration: 23050000, Loss: 0.00040654302618085413\n",
            "Iteration: 23060000, Loss: 0.00040654274310041955\n",
            "Iteration: 23070000, Loss: 0.00040654246021631457\n",
            "Iteration: 23080000, Loss: 0.00040654217752840314\n",
            "Iteration: 23090000, Loss: 0.0004065418950365479\n",
            "Iteration: 23100000, Loss: 0.00040654161274061303\n",
            "Iteration: 23110000, Loss: 0.0004065413306404623\n",
            "Iteration: 23120000, Loss: 0.0004065410487359592\n",
            "Iteration: 23130000, Loss: 0.00040654076702696825\n",
            "Iteration: 23140000, Loss: 0.0004065404855133531\n",
            "Iteration: 23150000, Loss: 0.00040654020419497825\n",
            "Iteration: 23160000, Loss: 0.0004065399230717083\n",
            "Iteration: 23170000, Loss: 0.0004065396421434069\n",
            "Iteration: 23180000, Loss: 0.00040653936140993863\n",
            "Iteration: 23190000, Loss: 0.0004065390808711685\n",
            "Iteration: 23200000, Loss: 0.00040653880052696065\n",
            "Iteration: 23210000, Loss: 0.00040653852037718006\n",
            "Iteration: 23220000, Loss: 0.0004065382404216915\n",
            "Iteration: 23230000, Loss: 0.0004065379606603596\n",
            "Iteration: 23240000, Loss: 0.0004065376810930504\n",
            "Iteration: 23250000, Loss: 0.00040653740171962794\n",
            "Iteration: 23260000, Loss: 0.00040653712253995805\n",
            "Iteration: 23270000, Loss: 0.00040653684355390537\n",
            "Iteration: 23280000, Loss: 0.00040653656476133675\n",
            "Iteration: 23290000, Loss: 0.00040653628616211574\n",
            "Iteration: 23300000, Loss: 0.00040653600775610905\n",
            "Iteration: 23310000, Loss: 0.0004065357295431823\n",
            "Iteration: 23320000, Loss: 0.0004065354515232011\n",
            "Iteration: 23330000, Loss: 0.0004065351736960315\n",
            "Iteration: 23340000, Loss: 0.0004065348960615392\n",
            "Iteration: 23350000, Loss: 0.0004065346186195907\n",
            "Iteration: 23360000, Loss: 0.0004065343413700515\n",
            "Iteration: 23370000, Loss: 0.00040653406431278856\n",
            "Iteration: 23380000, Loss: 0.0004065337874476679\n",
            "Iteration: 23390000, Loss: 0.00040653351077455594\n",
            "Iteration: 23400000, Loss: 0.00040653323429331895\n",
            "Iteration: 23410000, Loss: 0.00040653295800382354\n",
            "Iteration: 23420000, Loss: 0.0004065326819059377\n",
            "Iteration: 23430000, Loss: 0.00040653240599952635\n",
            "Iteration: 23440000, Loss: 0.00040653213028445757\n",
            "Iteration: 23450000, Loss: 0.00040653185476059793\n",
            "Iteration: 23460000, Loss: 0.0004065315794278151\n",
            "Iteration: 23470000, Loss: 0.00040653130428597496\n",
            "Iteration: 23480000, Loss: 0.0004065310293349465\n",
            "Iteration: 23490000, Loss: 0.00040653075457459595\n",
            "Iteration: 23500000, Loss: 0.00040653048000479096\n",
            "Iteration: 23510000, Loss: 0.000406530205625399\n",
            "Iteration: 23520000, Loss: 0.00040652993143628784\n",
            "Iteration: 23530000, Loss: 0.0004065296574373254\n",
            "Iteration: 23540000, Loss: 0.0004065293836283796\n",
            "Iteration: 23550000, Loss: 0.0004065291100093175\n",
            "Iteration: 23560000, Loss: 0.0004065288365800087\n",
            "Iteration: 23570000, Loss: 0.0004065285633403192\n",
            "Iteration: 23580000, Loss: 0.00040652829029011917\n",
            "Iteration: 23590000, Loss: 0.00040652801742927576\n",
            "Iteration: 23600000, Loss: 0.0004065277447576573\n",
            "Iteration: 23610000, Loss: 0.00040652747227513323\n",
            "Iteration: 23620000, Loss: 0.00040652719998157124\n",
            "Iteration: 23630000, Loss: 0.00040652692787684056\n",
            "Iteration: 23640000, Loss: 0.00040652665596080915\n",
            "Iteration: 23650000, Loss: 0.0004065263842333464\n",
            "Iteration: 23660000, Loss: 0.0004065261126943216\n",
            "Iteration: 23670000, Loss: 0.000406525841343603\n",
            "Iteration: 23680000, Loss: 0.00040652557018106027\n",
            "Iteration: 23690000, Loss: 0.00040652529920656217\n",
            "Iteration: 23700000, Loss: 0.0004065250284199786\n",
            "Iteration: 23710000, Loss: 0.00040652475782117844\n",
            "Iteration: 23720000, Loss: 0.00040652448741003146\n",
            "Iteration: 23730000, Loss: 0.00040652421718640695\n",
            "Iteration: 23740000, Loss: 0.00040652394715017475\n",
            "Iteration: 23750000, Loss: 0.0004065236773012045\n",
            "Iteration: 23760000, Loss: 0.00040652340763936643\n",
            "Iteration: 23770000, Loss: 0.0004065231381645302\n",
            "Iteration: 23780000, Loss: 0.0004065228688765654\n",
            "Iteration: 23790000, Loss: 0.00040652259977534336\n",
            "Iteration: 23800000, Loss: 0.00040652233086073273\n",
            "Iteration: 23810000, Loss: 0.00040652206213260503\n",
            "Iteration: 23820000, Loss: 0.0004065217935908305\n",
            "Iteration: 23830000, Loss: 0.0004065215252352784\n",
            "Iteration: 23840000, Loss: 0.00040652125706582123\n",
            "Iteration: 23850000, Loss: 0.00040652098908232836\n",
            "Iteration: 23860000, Loss: 0.000406520721284671\n",
            "Iteration: 23870000, Loss: 0.0004065204536727197\n",
            "Iteration: 23880000, Loss: 0.00040652018624634544\n",
            "Iteration: 23890000, Loss: 0.0004065199190054193\n",
            "Iteration: 23900000, Loss: 0.0004065196519498123\n",
            "Iteration: 23910000, Loss: 0.00040651938507939615\n",
            "Iteration: 23920000, Loss: 0.00040651911839404147\n",
            "Iteration: 23930000, Loss: 0.0004065188518936205\n",
            "Iteration: 23940000, Loss: 0.0004065185855780039\n",
            "Iteration: 23950000, Loss: 0.0004065183194470634\n",
            "Iteration: 23960000, Loss: 0.00040651805350067104\n",
            "Iteration: 23970000, Loss: 0.000406517787738698\n",
            "Iteration: 23980000, Loss: 0.00040651752216101686\n",
            "Iteration: 23990000, Loss: 0.0004065172567674983\n",
            "Iteration: 24000000, Loss: 0.0004065169915580159\n",
            "Iteration: 24010000, Loss: 0.0004065167265324409\n",
            "Iteration: 24020000, Loss: 0.00040651646169064524\n",
            "Iteration: 24030000, Loss: 0.0004065161970325014\n",
            "Iteration: 24040000, Loss: 0.0004065159325578825\n",
            "Iteration: 24050000, Loss: 0.00040651566826666\n",
            "Iteration: 24060000, Loss: 0.0004065154041587068\n",
            "Iteration: 24070000, Loss: 0.00040651514023389587\n",
            "Iteration: 24080000, Loss: 0.00040651487649209957\n",
            "Iteration: 24090000, Loss: 0.00040651461293319033\n",
            "Iteration: 24100000, Loss: 0.00040651434955704235\n",
            "Iteration: 24110000, Loss: 0.0004065140863635273\n",
            "Iteration: 24120000, Loss: 0.00040651382335251903\n",
            "Iteration: 24130000, Loss: 0.00040651356052389016\n",
            "Iteration: 24140000, Loss: 0.0004065132978775141\n",
            "Iteration: 24150000, Loss: 0.00040651303541326466\n",
            "Iteration: 24160000, Loss: 0.00040651277313101487\n",
            "Iteration: 24170000, Loss: 0.00040651251103063804\n",
            "Iteration: 24180000, Loss: 0.00040651224911200813\n",
            "Iteration: 24190000, Loss: 0.0004065119873749994\n",
            "Iteration: 24200000, Loss: 0.0004065117258194844\n",
            "Iteration: 24210000, Loss: 0.00040651146444533806\n",
            "Iteration: 24220000, Loss: 0.00040651120325243325\n",
            "Iteration: 24230000, Loss: 0.00040651094224064543\n",
            "Iteration: 24240000, Loss: 0.00040651068140984794\n",
            "Iteration: 24250000, Loss: 0.000406510420759915\n",
            "Iteration: 24260000, Loss: 0.0004065101602907204\n",
            "Iteration: 24270000, Loss: 0.00040650990000214\n",
            "Iteration: 24280000, Loss: 0.00040650963989404714\n",
            "Iteration: 24290000, Loss: 0.0004065093799663164\n",
            "Iteration: 24300000, Loss: 0.00040650912021882295\n",
            "Iteration: 24310000, Loss: 0.00040650886065144153\n",
            "Iteration: 24320000, Loss: 0.00040650860126404656\n",
            "Iteration: 24330000, Loss: 0.0004065083420565132\n",
            "Iteration: 24340000, Loss: 0.00040650808302871675\n",
            "Iteration: 24350000, Loss: 0.000406507824180532\n",
            "Iteration: 24360000, Loss: 0.0004065075655118344\n",
            "Iteration: 24370000, Loss: 0.00040650730702249897\n",
            "Iteration: 24380000, Loss: 0.00040650704871240105\n",
            "Iteration: 24390000, Loss: 0.00040650679058141565\n",
            "Iteration: 24400000, Loss: 0.00040650653262941936\n",
            "Iteration: 24410000, Loss: 0.0004065062748562876\n",
            "Iteration: 24420000, Loss: 0.0004065060172618949\n",
            "Iteration: 24430000, Loss: 0.0004065057598461187\n",
            "Iteration: 24440000, Loss: 0.00040650550260883415\n",
            "Iteration: 24450000, Loss: 0.00040650524554991686\n",
            "Iteration: 24460000, Loss: 0.00040650498866924334\n",
            "Iteration: 24470000, Loss: 0.0004065047319666899\n",
            "Iteration: 24480000, Loss: 0.00040650447544213246\n",
            "Iteration: 24490000, Loss: 0.0004065042190954467\n",
            "Iteration: 24500000, Loss: 0.00040650396292651045\n",
            "Iteration: 24510000, Loss: 0.0004065037069351995\n",
            "Iteration: 24520000, Loss: 0.0004065034511213907\n",
            "Iteration: 24530000, Loss: 0.0004065031954849599\n",
            "Iteration: 24540000, Loss: 0.00040650294002578436\n",
            "Iteration: 24550000, Loss: 0.0004065026847437411\n",
            "Iteration: 24560000, Loss: 0.0004065024296387069\n",
            "Iteration: 24570000, Loss: 0.0004065021747105589\n",
            "Iteration: 24580000, Loss: 0.00040650191995917387\n",
            "Iteration: 24590000, Loss: 0.0004065016653844295\n",
            "Iteration: 24600000, Loss: 0.0004065014109862021\n",
            "Iteration: 24610000, Loss: 0.0004065011567643701\n",
            "Iteration: 24620000, Loss: 0.00040650090271881107\n",
            "Iteration: 24630000, Loss: 0.0004065006488494014\n",
            "Iteration: 24640000, Loss: 0.0004065003951560193\n",
            "Iteration: 24650000, Loss: 0.0004065001416385425\n",
            "Iteration: 24660000, Loss: 0.000406499888296849\n",
            "Iteration: 24670000, Loss: 0.00040649963513081616\n",
            "Iteration: 24680000, Loss: 0.0004064993821403224\n",
            "Iteration: 24690000, Loss: 0.000406499129325245\n",
            "Iteration: 24700000, Loss: 0.00040649887668546325\n",
            "Iteration: 24710000, Loss: 0.00040649862422085435\n",
            "Iteration: 24720000, Loss: 0.00040649837193129754\n",
            "Iteration: 24730000, Loss: 0.0004064981198166702\n",
            "Iteration: 24740000, Loss: 0.00040649786787685124\n",
            "Iteration: 24750000, Loss: 0.0004064976161117189\n",
            "Iteration: 24760000, Loss: 0.00040649736452115265\n",
            "Iteration: 24770000, Loss: 0.00040649711310503057\n",
            "Iteration: 24780000, Loss: 0.0004064968618632315\n",
            "Iteration: 24790000, Loss: 0.0004064966107956344\n",
            "Iteration: 24800000, Loss: 0.0004064963599021183\n",
            "Iteration: 24810000, Loss: 0.00040649610918256236\n",
            "Iteration: 24820000, Loss: 0.0004064958586368452\n",
            "Iteration: 24830000, Loss: 0.00040649560826484663\n",
            "Iteration: 24840000, Loss: 0.00040649535806644584\n",
            "Iteration: 24850000, Loss: 0.0004064951080415218\n",
            "Iteration: 24860000, Loss: 0.0004064948581899547\n",
            "Iteration: 24870000, Loss: 0.00040649460851162355\n",
            "Iteration: 24880000, Loss: 0.00040649435900640796\n",
            "Iteration: 24890000, Loss: 0.00040649410967418816\n",
            "Iteration: 24900000, Loss: 0.0004064938605148435\n",
            "Iteration: 24910000, Loss: 0.00040649361152825437\n",
            "Iteration: 24920000, Loss: 0.0004064933627143\n",
            "Iteration: 24930000, Loss: 0.0004064931140728609\n",
            "Iteration: 24940000, Loss: 0.00040649286560381757\n",
            "Iteration: 24950000, Loss: 0.0004064926173070497\n",
            "Iteration: 24960000, Loss: 0.0004064923691824375\n",
            "Iteration: 24970000, Loss: 0.0004064921212298621\n",
            "Iteration: 24980000, Loss: 0.0004064918734492033\n",
            "Iteration: 24990000, Loss: 0.00040649162584034193\n",
            "Iteration: 25000000, Loss: 0.00040649137840315905\n",
            "Iteration: 25010000, Loss: 0.00040649113113753446\n",
            "Iteration: 25020000, Loss: 0.0004064908840433498\n",
            "Iteration: 25030000, Loss: 0.0004064906371204857\n",
            "Iteration: 25040000, Loss: 0.00040649039036882295\n",
            "Iteration: 25050000, Loss: 0.0004064901437882426\n",
            "Iteration: 25060000, Loss: 0.00040648989737862616\n",
            "Iteration: 25070000, Loss: 0.00040648965113985525\n",
            "Iteration: 25080000, Loss: 0.00040648940507180954\n",
            "Iteration: 25090000, Loss: 0.0004064891591743725\n",
            "Iteration: 25100000, Loss: 0.0004064889134474237\n",
            "Iteration: 25110000, Loss: 0.0004064886678908464\n",
            "Iteration: 25120000, Loss: 0.0004064884225045213\n",
            "Iteration: 25130000, Loss: 0.00040648817728832995\n",
            "Iteration: 25140000, Loss: 0.00040648793224215513\n",
            "Iteration: 25150000, Loss: 0.0004064876873658777\n",
            "Iteration: 25160000, Loss: 0.00040648744265938037\n",
            "Iteration: 25170000, Loss: 0.0004064871981225442\n",
            "Iteration: 25180000, Loss: 0.0004064869537552526\n",
            "Iteration: 25190000, Loss: 0.0004064867095573867\n",
            "Iteration: 25200000, Loss: 0.00040648646552883007\n",
            "Iteration: 25210000, Loss: 0.0004064862216694642\n",
            "Iteration: 25220000, Loss: 0.0004064859779791718\n",
            "Iteration: 25230000, Loss: 0.0004064857344578353\n",
            "Iteration: 25240000, Loss: 0.0004064854911053369\n",
            "Iteration: 25250000, Loss: 0.0004064852479215601\n",
            "Iteration: 25260000, Loss: 0.0004064850049063874\n",
            "Iteration: 25270000, Loss: 0.00040648476205970145\n",
            "Iteration: 25280000, Loss: 0.0004064845193813862\n",
            "Iteration: 25290000, Loss: 0.0004064842768713232\n",
            "Iteration: 25300000, Loss: 0.0004064840345293966\n",
            "Iteration: 25310000, Loss: 0.00040648379235548924\n",
            "Iteration: 25320000, Loss: 0.00040648355034948475\n",
            "Iteration: 25330000, Loss: 0.0004064833085112661\n",
            "Iteration: 25340000, Loss: 0.0004064830668407166\n",
            "Iteration: 25350000, Loss: 0.0004064828253377203\n"
          ]
        }
      ],
      "source": [
        "w = np.array([0] * 302, dtype='float')\n",
        "b = gradient_descent(X_train, Y, w, 0, 0.01, 100000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFEgKEr_beIj",
        "outputId": "d7670226-59aa-4f9b-df32-d406cd7daad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.020616425613333184, -0.019436495560088342, 0.057238817465220374, 0.09682168571950414, 0.050971289256004124, 0.01442395309866415, 0.006622463185966146, 0.037947344103421494, 0.03876450559473981, 0.015517155383109478, 0.009188992318057929, 0.0431966505313144, 0.0860348262540955, 0.09188489007182257, -0.0034281926414083948, 0.11222805365930799, 0.025574454911627322, 0.0017408500294780133, 0.052399886208865244, 0.011502485088038354, -0.013627118596858629, -0.029433124887636823, 0.0639650513776584, 0.03680980011816021, -0.013190384490354786, 0.06237405139345157, 0.02288841316014696, 0.038888348667432925, 0.0038352375947737446, 0.001764464535079337, 0.024997457363060048, 0.028724685774413755, 0.026195754621889236, -0.0016449856727396297, -0.005863979712146897, -0.003858692956208466, -0.03503750210878714, 0.014268869658591303, 0.004876111171303101, 0.005813056003488412, 0.0027160461566798693, -0.013155785742386229, 0.0057923666236608965, -0.0030427045402522408, -0.004726204056587326, 0.00040548947811423644, -0.002264362616454094, 0.009890410547746763, -0.01452590180828038, -0.000463565241737583, -0.014464742481282357, 0.008000756104840794, -0.005582144628863975, 0.004682711886580038, 0.006573097665521729, -0.013936516784247073, 0.0022439535982194977, 0.01746063213671552, -0.011599046664650645, -0.015439109109549449, -2.9849079460419542e-05, -0.0072724354996689215, 0.004864664149761507, -0.004955647768817743, -0.00219050161568938, -0.005015988579629077, 0.003109960804660949, -0.0057160271469060405, -0.011575641972114515, -0.007243840553366209, 0.022316480841983444, -0.029184353393250848, -0.012104465339704969, -0.018766004934700625, -0.011055533712154576, -0.024194046783141788, -0.01986042368239214, 0.005207331602816562, -0.01987681079292862, 0.06120205653329509, 0.03941873292924428, -0.02336323111208185, -0.012452407698166012, -0.012898588725326135, 0.0007840620037805372, 0.00744259977322557, 0.06526442909312269, -0.006379712613463444, 0.009768505954159566, -0.0038600754577929365, -0.004445652195204256, 0.013331682823396033, 0.009124957636506826, -0.004714055279875981, -0.021207851599180632, 0.009754357117708739, -0.004664724608606748, -0.0006820575556767543, 0.006435170883184989, 0.020882146244256244, 0.019169586291178937, 0.02070890438272688, -0.08850826741516134, -0.004518987487727179, 0.00558520341383528, 0.01288282456897945, 0.01260139713987546, 0.00977466936613094, -0.0032235446654725343, -0.015974327619946424, -0.010541613339313112, -0.0017233249500817965, 0.012165668550733392, 0.011633291611046688, -0.013724378194784524, -0.008394230162252842, -0.013672181126764228, 0.002341891194268961, 0.004009843959108688, -0.0020394914834447222, -0.010645949642994423, -0.003768093488235036, -0.006889438463305268, 0.008008183076644165, 0.00797137088260995, -0.12273868979891822, 0.009304540594280823, 0.007689803234568092, -0.0031207520690682317, -0.0015074362119199911, -0.007503057562470176, 0.00987846131719115, 0.10063371137761193, 0.0021764562150526695, -0.0013633441323552288, -0.0009364795618801061, 0.022657661976544227, -0.0018774041220153696, 0.008732112594899408, -0.010319386173012006, -0.009451445970688754, 0.0009085036840722023, -0.0028283953620687466, 0.0086320492943145, -0.004965724892816893, -0.006698180896049781, -0.006251995790628827, -0.0057778459820919574, -0.0029648134054841356, 0.0025158616153093047, -0.00199811575000334, 0.0010219255359060716, -0.0018774041220153696, -0.005432960563660004, 0.0045722028018918065, 0.028195313728591333, 0.0002460834788219856, -0.0040333647688535895, 0.0006374685391233637, -0.016169934213801355, -0.017721973050556665, 0.008954279229887938, 0.0038070198404693903, -0.007115008014351028, -0.00936748296918799, -0.0028771101628793355, 0.0012108469628995316, 0.003670327050442424, 0.013508888640029665, -0.0022524495556616193, -0.008208681439623396, -0.010411176763469787, 0.012729282695709858, -0.002819943799242995, -0.0071693415012516635, -0.005424427975906153, -0.004678988538034516, -0.005349465261038516, 0.004291726204116134, 0.0030147924700518764, -0.006041331305044646, 0.004100531643682844, -0.007379672870493147, 0.021877085451829332, -0.005543197970442317, -0.009977521693105966, -0.0042831348180255805, -0.00943665008898084, -0.005084780528181703, -0.0033520269265964724, -0.0042831348180255805, 0.0046227838222716155, 0.000733739331806936, -0.0022660605302527444, 0.021831444563428812, -0.006363730523524062, -0.008723001415520786, -0.011842071212856532, 0.0008157208245639554, 0.0023951338797286365, 0.007138634311901141, -0.0066430330723475685, -0.0042831348180255805, -5.2169783456961295e-05, -0.0067345704610890554, 0.004808411670816879, -0.007482185692544564, 0.0043318126965431, -0.006416065524544731, 0.000806288502466102, -0.003762949232036984, 0.0003512684605751197, -0.0014592644160400072, -0.0010773519610667453, 0.012212316873309675, -0.0035427008292851377, -0.01726899656702954, 0.003772577781386026, 0.0020961802789956673, 0.0013746005736574255, -0.004127950762380048, -0.004397947813015371, -0.0023083013959829825, -0.004934036936215983, -0.002429382182509423, -0.0027695379782547136, -0.0026730277960914915, 0.0027042295602427062, 0.002337919769412386, -0.006963002674034138, 0.026054461274580793, -0.010404775136283514, -0.011086614575316178, -0.011926490681706862, -0.00399561328441985, -0.013111374941809719, 0.00036780081261330585, 0.0029240005377249665, 0.0006583822122200618, -0.010319275496400397, 0.016112661041346527, 0.005114781082288037, -0.007330437855558227, -0.0038261748795112823, 0.0006011742936262549, -8.555880935929086e-05, -0.001837202950210743, -0.0255003378050969, 0.0025410129575490436, 0.0039475211585017845, 0.00228888004313044, 0.0052462588311562326, 0.002405623033222928, 0.0017076226628117699, -0.0008190390134769628, 0.0017076226628117699, -0.005358490672652251, -0.002893512095407754, 0.026212201850802717, -0.020216297843316237, 0.005811822971487687, 0.0017076226628117699, -0.008336479826385305, -0.012542288934125978, -0.008518779630689578, 0.001050653170244356, -0.00018164221352626428, 0.0017076226628117699, -0.007980947237630199, 0.006559674130064446, -0.002670046767465504, -0.0040758147815888185, -0.0006175575696709626, 0.08553319648059633, -0.010227341258491202, -0.06798599089698446, -0.014683283443846224, -0.004627748108862721, 0.000573967664944763, 0.0019578962004783438, -0.0054748201731886215, 0.00020728529790280028, -0.00408151784757246, 0.0027517848679845026, 0.0024456043307028224, 0.0028728526040012895, -0.011352143073841471, -0.015024400035949872, 0.00826675170971673, 0.011510917020485364, 0.006066606248979664, -0.002065913583336407, -0.007900391651917197, 0.010284162280883693, -0.0010219868227971747, -0.017479164284790523, -0.008918780188895567, 0.004895815935590598, 0.012311461368366212, -0.00856879788244616, 0.0018950859492198645, -0.00897820430056026] -0.007363419118725377\n"
          ]
        }
      ],
      "source": [
        "print(list(w), b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry1wQVfS6MXs"
      },
      "outputs": [],
      "source": [
        "def sse(X, Y):\n",
        "  return ((X - Y) ** 2).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imQNZhgb6uXp",
        "outputId": "0499e045-8b99-43b5-8813-90971eb59d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9123021843622661\n"
          ]
        }
      ],
      "source": [
        "model_sse = sse(linear_regression(X_train, w, b), Y)\n",
        "sst = sse(np.ones(len(Y)) * Y.mean(), Y)\n",
        "print(1 - model_sse / sst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyIL781x7r5n",
        "outputId": "5a199202-1cc1-4ecf-ac40-627b955cfdce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9332152454506968"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y)\n",
        "model.score(X_train, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgWajfF7J8wm"
      },
      "outputs": [],
      "source": [
        "sklearn_predictions = model.predict(test_df.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BOEjArC0BT3"
      },
      "outputs": [],
      "source": [
        "predictions = linear_regression(test_df.to_numpy(), w, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s9OEcbz27DC",
        "outputId": "d69a35d3-3284-4b95-d55b-50a24c99eeab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([108403.69764999, 146039.1664962 , 173878.95959025, ...,\n",
              "       163117.27916203, 101996.17643232, 219999.73304765])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = predictions.reshape((predictions.size, 1))\n",
        "predictions = target_scaler.inverse_transform(predictions)\n",
        "predictions = predictions.reshape(predictions.size)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "buIWiCZ564oC",
        "outputId": "3805607a-ec80-4da1-d4cd-f59e6a2e4e01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e364c6f7-2dfe-41ca-8855-8cfc04fb6fc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>108403.697650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>146039.166496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>173878.959590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>189123.720377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>211815.708261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e364c6f7-2dfe-41ca-8855-8cfc04fb6fc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e364c6f7-2dfe-41ca-8855-8cfc04fb6fc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e364c6f7-2dfe-41ca-8855-8cfc04fb6fc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     id      SalePrice\n",
              "0  1461  108403.697650\n",
              "1  1462  146039.166496\n",
              "2  1463  173878.959590\n",
              "3  1464  189123.720377\n",
              "4  1465  211815.708261"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = pd.DataFrame({\"id\":range(1461,2920),\"SalePrice\":predictions})\n",
        "prediction.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3_XiOqg7BUm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "pd.DataFrame(prediction).to_csv(\"prediction_file.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Gradient_Descent_House_Prices (1).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}