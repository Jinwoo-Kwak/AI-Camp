{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scratch_LogisticReg.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4h1PkPjMN7TFZIu6Wcw0+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conuwoo/AI-Camp-Summer-2022/blob/main/ML_Activity/Scratch_LogisticReg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "H9wQffxP3UP9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"titanic_train.csv\")\n",
        "test_data = pd.read_csv(\"titanic_test.csv\")"
      ],
      "metadata": {
        "id": "d2DZ_E983O0o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data PreProcessing"
      ],
      "metadata": {
        "id": "Uw6xBeqvEHwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.drop(['Ticket'], axis=1)\n",
        "test_data = test_data.drop(['Ticket'], axis=1)"
      ],
      "metadata": {
        "id": "fk0vSiw46Bp1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.drop(['Name'], axis=1)\n",
        "test_data = test_data.drop(['Name'], axis=1)"
      ],
      "metadata": {
        "id": "7akXsN6n6DaC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill na values"
      ],
      "metadata": {
        "id": "kN1Wo3KoEMjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for na's\n",
        "train_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8ItwtCN6GSx",
        "outputId": "74bc8a4e-054c-47a8-bd95-c9cbf5ae9b37"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_130bO96GtR",
        "outputId": "d8565f6b-25c3-46ed-9e42-5d35f23944a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Pclass           0\n",
              "Sex              0\n",
              "Age             86\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Fare             1\n",
              "Cabin          327\n",
              "Embarked         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Age'] = train_data['Age'].replace(np.nan,train_data['Age'].mean())\n",
        "test_data['Age'] = test_data['Age'].replace(np.nan, test_data['Age'].mean())"
      ],
      "metadata": {
        "id": "GhPP5fHq6Jaf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Shows there is more than half of NA's for the column so we should drop it\n",
        "train_data = train_data.drop(['Cabin'], axis=1)\n",
        "test_data = test_data.drop(['Cabin'], axis=1)"
      ],
      "metadata": {
        "id": "JcCAQ_tV6Lfl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Embarked'] = train_data['Embarked'].replace(np.nan,'Q')"
      ],
      "metadata": {
        "id": "55P5UmG46NQp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['Fare'] = test_data['Fare'].replace(np.nan, test_data['Fare'].mean())"
      ],
      "metadata": {
        "id": "pxFzOWfC6QBU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for na's\n",
        "train_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7TYU8mg6SW_",
        "outputId": "26bd6549-a015-4102-e4ce-be661b5e1f54"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "Pclass         0\n",
              "Sex            0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Fare           0\n",
              "Embarked       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gadF4mbJ6Ury",
        "outputId": "1d3587f0-f01e-44ce-cc3b-1869df46ad50"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Pclass         0\n",
              "Sex            0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Fare           0\n",
              "Embarked       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode categorical variables"
      ],
      "metadata": {
        "id": "V-C18cyREOhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#initialize label endoce as first step.\n",
        "le = LabelEncoder()\n",
        "\n",
        "train_data[\"Sex\"] = le.fit_transform(train_data[\"Sex\"].values)\n",
        "test_data[\"Sex\"] = le.fit_transform(test_data[\"Sex\"].values)\n",
        "\n",
        "train_data[\"Embarked\"] = le.fit_transform(train_data[\"Embarked\"].values)\n",
        "test_data[\"Embarked\"] = le.fit_transform(test_data[\"Embarked\"].values)"
      ],
      "metadata": {
        "id": "4bv7Lbi-6XyC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "features = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Fare\"]\n",
        "X = train_data[features]\n",
        "y = train_data['Survived']\n",
        "\n",
        "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "min_max = MinMaxScaler()\n",
        "X_train = min_max.fit_transform(X_train)\n",
        "X_test = min_max.transform(X_test)"
      ],
      "metadata": {
        "id": "qiXX8cU86flY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "Apifhq258f5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z): # takes linear functinon \"z\" as an input\n",
        "\n",
        "    g_function = 1/(1+np.exp(-z))\n",
        "   \n",
        "    return g_function"
      ],
      "metadata": {
        "id": "0wZxolS13eHJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SJjGy-GK3D3m"
      },
      "outputs": [],
      "source": [
        "def cost(X, y, w, b):\n",
        "\n",
        "    m = X.shape[0] # 0 to m-1\n",
        "    cost = 0 # starts with 0\n",
        "    for i in range(m): # sigma\n",
        "        current_z = np.dot(X[i],w) + b # linear function \"z\"\n",
        "        current_f = sigmoid(current_z) # input \"z\" into sigmoid function\n",
        "        cost +=  -y[i]*np.log(current_f) - (1-y[i])*np.log(1-current_f) # logloss formula\n",
        "             \n",
        "    cost = cost / m # divide by m iterations\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbISuIu37XDK",
        "outputId": "e8662417-62f6-46ea-eae9-00e595462842"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.2963056 , 0.375     , 0.51334181],\n",
              "       [1.        , 1.        , 0.24604172, 0.        , 0.01921772],\n",
              "       [0.5       , 1.        , 0.42196532, 0.125     , 0.04098927],\n",
              "       ...,\n",
              "       [1.        , 0.        , 0.01985423, 0.        , 0.0239836 ],\n",
              "       [1.        , 1.        , 0.59788892, 0.        , 0.01533038],\n",
              "       [0.        , 1.        , 0.560191  , 0.125     , 0.16293235]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros((5,), dtype=int)\n",
        "print(w.shape)\n",
        "b = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g3Bt-KK7Hfg",
        "outputId": "0e74f341-7cf7-48d2-95ca-d02b6270f75a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.to_numpy()"
      ],
      "metadata": {
        "id": "JdbVieoB7llE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cost(X_train,y_train,w,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j22X7a0B7gVm",
        "outputId": "8231372a-2c44-47ef-faaa-93263bb4e486"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.693147180559947"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient(X, y, w, b): \n",
        "    m = X.shape[0]\n",
        "    n = X.shape[1]\n",
        "    grad_w = np.zeros((n,)) # gradient for w                          \n",
        "    grad_b = 0 # gradient for b\n",
        "\n",
        "    for i in range(m):\n",
        "        current_f = sigmoid(np.dot(X[i],w) + b)       #g(z)\n",
        "        loss  = current_f  - y[i]                       #loss\n",
        "        for j in range(n): # sigma\n",
        "            grad_w[j] = grad_w[j] + loss * X[i,j]      #gradient for current w\n",
        "        grad_b = grad_b + loss # graident for current b\n",
        "    grad_w = grad_w/m      # sigma/m\n",
        "    grad_b = grad_b/m      # sigma/m\n",
        "        \n",
        "    return grad_b, grad_w  "
      ],
      "metadata": {
        "id": "GSg2Dh7E3mHQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient(X_train,y_train,w,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh-3nXAN8kKa",
        "outputId": "369d4081-252f-42c3-ceb5-b6e6ba48d4ff"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.10533707865168539,\n",
              " array([ 0.13588483,  0.20014045,  0.0454676 ,  0.00851475, -0.00450982]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w, b, alpha, num_iters): \n",
        "    for i in range(num_iters):\n",
        "        # Calculate the gradient and update the parameters\n",
        "        grad_b, grad_w = gradient(X, y, w, b)   \n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w = w - alpha * grad_w               \n",
        "        b = b - alpha * grad_b              \n",
        "\n",
        "        if i% 100 == 0:\n",
        "          print('Iteration: ' + str(i) + ', Loss: ' + str(cost(X,y,w,b)))\n",
        "        \n",
        "    return w, b  #return w and b"
      ],
      "metadata": {
        "id": "CulXg0163ms4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(X_train,y_train,w,b,0.01,10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zoWX4tY8pWF",
        "outputId": "399a4b3a-ccf9-4334-b56e-68793033fe44"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0, Loss: 0.6924310277023202\n",
            "Iteration: 100, Loss: 0.6445228360554707\n",
            "Iteration: 200, Loss: 0.6214712261815585\n",
            "Iteration: 300, Loss: 0.607533188989344\n",
            "Iteration: 400, Loss: 0.5972728631751179\n",
            "Iteration: 500, Loss: 0.5887304744781059\n",
            "Iteration: 600, Loss: 0.5811577741817543\n",
            "Iteration: 700, Loss: 0.5742478320124913\n",
            "Iteration: 800, Loss: 0.5678609524634668\n",
            "Iteration: 900, Loss: 0.5619231989605004\n",
            "Iteration: 1000, Loss: 0.556387671662148\n",
            "Iteration: 1100, Loss: 0.5512193898234734\n",
            "Iteration: 1200, Loss: 0.5463892720346941\n",
            "Iteration: 1300, Loss: 0.5418716819384012\n",
            "Iteration: 1400, Loss: 0.5376433865349867\n",
            "Iteration: 1500, Loss: 0.5336830780175502\n",
            "Iteration: 1600, Loss: 0.5299711216866183\n",
            "Iteration: 1700, Loss: 0.5264893955152085\n",
            "Iteration: 1800, Loss: 0.5232211680207065\n",
            "Iteration: 1900, Loss: 0.5201509935372726\n",
            "Iteration: 2000, Loss: 0.5172646168978146\n",
            "Iteration: 2100, Loss: 0.5145488846018199\n",
            "Iteration: 2200, Loss: 0.5119916614679568\n",
            "Iteration: 2300, Loss: 0.5095817524477708\n",
            "Iteration: 2400, Loss: 0.507308829474084\n",
            "Iteration: 2500, Loss: 0.5051633632411183\n",
            "Iteration: 2600, Loss: 0.5031365597825704\n",
            "Iteration: 2700, Loss: 0.5012203016741296\n",
            "Iteration: 2800, Loss: 0.499407093653352\n",
            "Iteration: 2900, Loss: 0.497690012426189\n",
            "Iteration: 3000, Loss: 0.4960626604155886\n",
            "Iteration: 3100, Loss: 0.49451912320167746\n",
            "Iteration: 3200, Loss: 0.4930539304033225\n",
            "Iteration: 3300, Loss: 0.49166201975586304\n",
            "Iteration: 3400, Loss: 0.4903387041479958\n",
            "Iteration: 3500, Loss: 0.489079641391294\n",
            "Iteration: 3600, Loss: 0.48788080650771015\n",
            "Iteration: 3700, Loss: 0.4867384663331077\n",
            "Iteration: 3800, Loss: 0.4856491562478993\n",
            "Iteration: 3900, Loss: 0.4846096588588407\n",
            "Iteration: 4000, Loss: 0.48361698446881135\n",
            "Iteration: 4100, Loss: 0.482668353183709\n",
            "Iteration: 4200, Loss: 0.4817611785173203\n",
            "Iteration: 4300, Loss: 0.480893052366193\n",
            "Iteration: 4400, Loss: 0.4800617312369474\n",
            "Iteration: 4500, Loss: 0.47926512361829077\n",
            "Iteration: 4600, Loss: 0.4785012783990238\n",
            "Iteration: 4700, Loss: 0.47776837424179996\n",
            "Iteration: 4800, Loss: 0.4770647098301378\n",
            "Iteration: 4900, Loss: 0.4763886949133534\n",
            "Iteration: 5000, Loss: 0.47573884208065725\n",
            "Iteration: 5100, Loss: 0.4751137592016912\n",
            "Iteration: 5200, Loss: 0.4745121424762718\n",
            "Iteration: 5300, Loss: 0.4739327700412034\n",
            "Iteration: 5400, Loss: 0.47337449608658255\n",
            "Iteration: 5500, Loss: 0.4728362454382404\n",
            "Iteration: 5600, Loss: 0.4723170085668007\n",
            "Iteration: 5700, Loss: 0.4718158369873296\n",
            "Iteration: 5800, Loss: 0.47133183901670345\n",
            "Iteration: 5900, Loss: 0.4708641758587688\n",
            "Iteration: 6000, Loss: 0.47041205798994234\n",
            "Iteration: 6100, Loss: 0.4699747418203331\n",
            "Iteration: 6200, Loss: 0.46955152660765537\n",
            "Iteration: 6300, Loss: 0.4691417516031573\n",
            "Iteration: 6400, Loss: 0.4687447934106067\n",
            "Iteration: 6500, Loss: 0.4683600635410432\n",
            "Iteration: 6600, Loss: 0.46798700614745076\n",
            "Iteration: 6700, Loss: 0.46762509592491674\n",
            "Iteration: 6800, Loss: 0.46727383616304047\n",
            "Iteration: 6900, Loss: 0.46693275693851544\n",
            "Iteration: 7000, Loss: 0.46660141343680517\n",
            "Iteration: 7100, Loss: 0.4662793843927933\n",
            "Iteration: 7200, Loss: 0.46596627064112706\n",
            "Iteration: 7300, Loss: 0.4656616937677511\n",
            "Iteration: 7400, Loss: 0.4653652948548412\n",
            "Iteration: 7500, Loss: 0.4650767333119971\n",
            "Iteration: 7600, Loss: 0.4647956857871229\n",
            "Iteration: 7700, Loss: 0.46452184515098854\n",
            "Iteration: 7800, Loss: 0.46425491954994735\n",
            "Iteration: 7900, Loss: 0.46399463152171266\n",
            "Iteration: 8000, Loss: 0.4637407171695437\n",
            "Iteration: 8100, Loss: 0.4634929253905376\n",
            "Iteration: 8200, Loss: 0.46325101715407957\n",
            "Iteration: 8300, Loss: 0.4630147648268092\n",
            "Iteration: 8400, Loss: 0.46278395154075797\n",
            "Iteration: 8500, Loss: 0.46255837060156757\n",
            "Iteration: 8600, Loss: 0.46233782493394704\n",
            "Iteration: 8700, Loss: 0.46212212656173485\n",
            "Iteration: 8800, Loss: 0.46191109612015496\n",
            "Iteration: 8900, Loss: 0.4617045623980156\n",
            "Iteration: 9000, Loss: 0.4615023619077979\n",
            "Iteration: 9100, Loss: 0.4613043384817167\n",
            "Iteration: 9200, Loss: 0.46111034289198033\n",
            "Iteration: 9300, Loss: 0.4609202324936394\n",
            "Iteration: 9400, Loss: 0.46073387088847545\n",
            "Iteration: 9500, Loss: 0.46055112760856565\n",
            "Iteration: 9600, Loss: 0.46037187781820005\n",
            "Iteration: 9700, Loss: 0.4601960020329586\n",
            "Iteration: 9800, Loss: 0.4600233858548221\n",
            "Iteration: 9900, Loss: 0.4598539197223055\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-1.3629786 , -2.43172339, -0.11372335, -0.215576  ,  0.50271047]),\n",
              " 1.8934886014151175)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}